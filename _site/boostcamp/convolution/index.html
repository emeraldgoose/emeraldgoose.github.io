<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="ko" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Convolution 정리 - gooooooooooose</title>
<meta name="title" content="Convolution 정리">
<meta name="description" content="Convolution    신호처리에서 정말 많이 등장하는 컨볼루션 연산입니다. 기계학습에서도 컨볼루션을 사용하여 학습을 하게 됩니다.   아래 식은 각 뉴련들이 선형모델과 활성함수로 모두 연결된(fully connected) 구조를 가졌습니다.            $h_i = \sigma(\sum_{j=1}^{p}W_{i,j}x_j)$, $\sigma$는 활성함수, $W_{i,j}$는 가중치 행렬입니다.       각 성분 $h_i$에 대응하는 가중치 행 $W_i$이 필요합니다.           컨볼루션 연산은 커널(kernel)을 입력벡터 상에서 움직여가면서 선형모델과 합성함수가 적용되는 구조입니다.            $h_i = \sigma(\sum_{j=1}^{k}V_jx_{i+j-1})$, $\sigma$는 활성함수, $V_j$는 가중치 행렬입니다.       모든 $i$에 대해 적용되는 커널은 $V$로 같고 커널의 사이즈만큼 $x$상에서 이동하면서 적용됩니다.       또한, 활성화 함수를 제외한 컨볼루션 연산도 선형변환에 속합니다.           컨볼루션 연산의 수학적인 의미는 신호(signal)를 커널을 이용해 국소적으로 증폭 또는 감소시켠서 정보의 추출을 필터링하는 것입니다.            Continuous : $[f*g](x) = \int_{R^d}f(z)g(x-z)dz = \int_{R^d}f(x-z)g(z)dz = [g*f](x)$       discrete : $[f*g](i) = \sum_{a \in Z^d}f(a)g(i-a) = \sum_{a \in Z^d}f(i-a)g(a) = [g*f](i)$       CNN에서 사용하는 연산은 Convolution이 아니고 cross-correlatoin이라 한다.           커널은 정의역 내에서 움직여도 변하지 않고(translation invariant) 주어진 신호에 국소적(local)으로 적용한다.   또한, Convolution 연산은 1차원 뿐만 아니라 다양한 차원에서 계산 가능하다.            데이터의 성격에 따라 사용하는 커널이 달라진다.       2D-conv $[f*g](i,j) = \sum_{p,q}f(p,q)g(i+p,j+q)$       3D-conv $[f*g](i,j,k) = \sum_{p,q,r}f(p,q,r)g(i+p,j+q,k+r)$           2D Convolution    2D-Conv 연산은 커널(kernel)을 입력벡터 상에서 움직여가면서 선형모델과 합성함수가 적용되는 구조이다.   입력크기를 (H,W), 커널 크기를 ($K_H,K_W$), 출력크기를 ($O_H,O_W$)라 하면 출력 크기는 다음과 같이 계산한다.            $O_H = H-K_H+1$       $O_W = W-K_W+1$           채널이 여러개인 2차원 입력의 경우 커널의 채널 수와 입력의 채널 수가 같아야 한다.            커널($K_H,K_W,C$) * 입력($H,W,C$) -&gt; 출력($O_H,O_W,1$)       만약 커널을 $O_C$개 사용하면 출력도 $O_C$개가 된다. -&gt; 출력이 텐서가 된다.           Convolution연산의 역전파    Conv 연산은 커널이 모든 입력데이터에 공통으로 적용되기 때문에 역전파를 계산할 때도 conv 연산이 나오게 된다.            $\frac{\partial}{\partial x}[f*g](x) = \frac{\partial}{\partial x}\int_{R^d}f(y)g(x-y)dy = \int_{R^d}f(y)\frac{\partial g}{\partial x}(x-y)dy = [f*g’](x)$       Discrete 일 때도 성립한다.">


  <meta name="author" content="goooose">
  
  <meta property="article:author" content="goooose">
  


<!-- open-graph tags -->
<meta property="og:type" content="article">
<meta property="og:locale" content="ko_KR">
<meta property="og:site_name" content="gooooooooooose">
<meta property="og:title" content="Convolution 정리">
<meta property="og:url" content="http://localhost:4000/boostcamp/convolution/">


  <meta property="og:description" content="Convolution    신호처리에서 정말 많이 등장하는 컨볼루션 연산입니다. 기계학습에서도 컨볼루션을 사용하여 학습을 하게 됩니다.   아래 식은 각 뉴련들이 선형모델과 활성함수로 모두 연결된(fully connected) 구조를 가졌습니다.            $h_i = \sigma(\sum_{j=1}^{p}W_{i,j}x_j)$, $\sigma$는 활성함수, $W_{i,j}$는 가중치 행렬입니다.       각 성분 $h_i$에 대응하는 가중치 행 $W_i$이 필요합니다.           컨볼루션 연산은 커널(kernel)을 입력벡터 상에서 움직여가면서 선형모델과 합성함수가 적용되는 구조입니다.            $h_i = \sigma(\sum_{j=1}^{k}V_jx_{i+j-1})$, $\sigma$는 활성함수, $V_j$는 가중치 행렬입니다.       모든 $i$에 대해 적용되는 커널은 $V$로 같고 커널의 사이즈만큼 $x$상에서 이동하면서 적용됩니다.       또한, 활성화 함수를 제외한 컨볼루션 연산도 선형변환에 속합니다.           컨볼루션 연산의 수학적인 의미는 신호(signal)를 커널을 이용해 국소적으로 증폭 또는 감소시켠서 정보의 추출을 필터링하는 것입니다.            Continuous : $[f*g](x) = \int_{R^d}f(z)g(x-z)dz = \int_{R^d}f(x-z)g(z)dz = [g*f](x)$       discrete : $[f*g](i) = \sum_{a \in Z^d}f(a)g(i-a) = \sum_{a \in Z^d}f(i-a)g(a) = [g*f](i)$       CNN에서 사용하는 연산은 Convolution이 아니고 cross-correlatoin이라 한다.           커널은 정의역 내에서 움직여도 변하지 않고(translation invariant) 주어진 신호에 국소적(local)으로 적용한다.   또한, Convolution 연산은 1차원 뿐만 아니라 다양한 차원에서 계산 가능하다.            데이터의 성격에 따라 사용하는 커널이 달라진다.       2D-conv $[f*g](i,j) = \sum_{p,q}f(p,q)g(i+p,j+q)$       3D-conv $[f*g](i,j,k) = \sum_{p,q,r}f(p,q,r)g(i+p,j+q,k+r)$           2D Convolution    2D-Conv 연산은 커널(kernel)을 입력벡터 상에서 움직여가면서 선형모델과 합성함수가 적용되는 구조이다.   입력크기를 (H,W), 커널 크기를 ($K_H,K_W$), 출력크기를 ($O_H,O_W$)라 하면 출력 크기는 다음과 같이 계산한다.            $O_H = H-K_H+1$       $O_W = W-K_W+1$           채널이 여러개인 2차원 입력의 경우 커널의 채널 수와 입력의 채널 수가 같아야 한다.            커널($K_H,K_W,C$) * 입력($H,W,C$) -&gt; 출력($O_H,O_W,1$)       만약 커널을 $O_C$개 사용하면 출력도 $O_C$개가 된다. -&gt; 출력이 텐서가 된다.           Convolution연산의 역전파    Conv 연산은 커널이 모든 입력데이터에 공통으로 적용되기 때문에 역전파를 계산할 때도 conv 연산이 나오게 된다.            $\frac{\partial}{\partial x}[f*g](x) = \frac{\partial}{\partial x}\int_{R^d}f(y)g(x-y)dy = \int_{R^d}f(y)\frac{\partial g}{\partial x}(x-y)dy = [f*g’](x)$       Discrete 일 때도 성립한다.">







  <meta property="article:published_time" content="2021-08-06T00:00:00+09:00">





  

  


<link rel="canonical" href="http://localhost:4000/boostcamp/convolution/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "emeraldgoose",
      "url": "http://localhost:4000/"
    
  }
</script>


  <meta name="google-site-verification" content="googleb34ce5276ba6573e" />





  <meta name="naver-site-verification" content="naver93cdc79a5629ab3736d7cf8ff7b51d80">


<!-- end _includes/seo.html -->




<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single wide">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about/">About</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/">Categories</a>
            </li><li class="masthead__menu-item">
              <a href="/tags/">Tags</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      


  
    



<nav class="breadcrumbs">
  <ol itemscope itemtype="https://schema.org/BreadcrumbList">
    
    
    
      
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/" itemprop="item"><span itemprop="name">Home</span></a>

          <meta itemprop="position" content="1" />
        </li>
        <span class="sep">/</span>
      
      
        
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/categories/#boostcamp" itemprop="item"><span itemprop="name">Boostcamp</span></a>
          <meta itemprop="position" content="2" />
        </li>
        <span class="sep">/</span>
      
    
      
      
        <li class="current">Convolution 정리</li>
      
    
  </ol>
</nav>

  


<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://localhost:4000/">
        <img src="/assets/images/bio-photo.png" alt="goooose" itemprop="image" class="u-photo" width="110px" height="110px">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">goooose</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>Interested in ML/DL, Data Engineering.</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">South Korea</span>
        </li>
      

      
        
          
            <li><a href="mailto:smk6221@naver.com" rel="nofollow noopener noreferrer me"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span></a></li>
          
        
          
        
          
        
          
        
          
            <li><a href="https://github.com/emeraldgoose" rel="nofollow noopener noreferrer me"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
        
          
            <li><a href="https://www.linkedin.com/in/minseong-kim-84428b231/" rel="nofollow noopener noreferrer me"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span class="label">LinkedIn</span></a></li>
          
        
          
            <li><a href="https://gooooooooooose.tistory.com/" rel="nofollow noopener noreferrer me"><i class="fas fa-fw fa-link" aria-hidden="true"></i><span class="label">Problem Solving OJ (KOR)</span></a></li>
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Convolution 정리">
    <meta itemprop="description" content="Convolution  신호처리에서 정말 많이 등장하는 컨볼루션 연산입니다. 기계학습에서도 컨볼루션을 사용하여 학습을 하게 됩니다.  아래 식은 각 뉴련들이 선형모델과 활성함수로 모두 연결된(fully connected) 구조를 가졌습니다.          $h_i = \sigma(\sum_{j=1}^{p}W_{i,j}x_j)$, $\sigma$는 활성함수, $W_{i,j}$는 가중치 행렬입니다.      각 성분 $h_i$에 대응하는 가중치 행 $W_i$이 필요합니다.        컨볼루션 연산은 커널(kernel)을 입력벡터 상에서 움직여가면서 선형모델과 합성함수가 적용되는 구조입니다.          $h_i = \sigma(\sum_{j=1}^{k}V_jx_{i+j-1})$, $\sigma$는 활성함수, $V_j$는 가중치 행렬입니다.      모든 $i$에 대해 적용되는 커널은 $V$로 같고 커널의 사이즈만큼 $x$상에서 이동하면서 적용됩니다.      또한, 활성화 함수를 제외한 컨볼루션 연산도 선형변환에 속합니다.        컨볼루션 연산의 수학적인 의미는 신호(signal)를 커널을 이용해 국소적으로 증폭 또는 감소시켠서 정보의 추출을 필터링하는 것입니다.          Continuous : $[f*g](x) = \int_{R^d}f(z)g(x-z)dz = \int_{R^d}f(x-z)g(z)dz = [g*f](x)$      discrete : $[f*g](i) = \sum_{a \in Z^d}f(a)g(i-a) = \sum_{a \in Z^d}f(i-a)g(a) = [g*f](i)$      CNN에서 사용하는 연산은 Convolution이 아니고 cross-correlatoin이라 한다.        커널은 정의역 내에서 움직여도 변하지 않고(translation invariant) 주어진 신호에 국소적(local)으로 적용한다.  또한, Convolution 연산은 1차원 뿐만 아니라 다양한 차원에서 계산 가능하다.          데이터의 성격에 따라 사용하는 커널이 달라진다.      2D-conv $[f*g](i,j) = \sum_{p,q}f(p,q)g(i+p,j+q)$      3D-conv $[f*g](i,j,k) = \sum_{p,q,r}f(p,q,r)g(i+p,j+q,k+r)$      2D Convolution  2D-Conv 연산은 커널(kernel)을 입력벡터 상에서 움직여가면서 선형모델과 합성함수가 적용되는 구조이다.  입력크기를 (H,W), 커널 크기를 ($K_H,K_W$), 출력크기를 ($O_H,O_W$)라 하면 출력 크기는 다음과 같이 계산한다.          $O_H = H-K_H+1$      $O_W = W-K_W+1$        채널이 여러개인 2차원 입력의 경우 커널의 채널 수와 입력의 채널 수가 같아야 한다.          커널($K_H,K_W,C$) * 입력($H,W,C$) -&gt; 출력($O_H,O_W,1$)      만약 커널을 $O_C$개 사용하면 출력도 $O_C$개가 된다. -&gt; 출력이 텐서가 된다.      Convolution연산의 역전파  Conv 연산은 커널이 모든 입력데이터에 공통으로 적용되기 때문에 역전파를 계산할 때도 conv 연산이 나오게 된다.          $\frac{\partial}{\partial x}[f*g](x) = \frac{\partial}{\partial x}\int_{R^d}f(y)g(x-y)dy = \int_{R^d}f(y)\frac{\partial g}{\partial x}(x-y)dy = [f*g’](x)$      Discrete 일 때도 성립한다.      ">
    <meta itemprop="datePublished" content="2021-08-06T00:00:00+09:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Convolution 정리
</h1>
          
<!--
            <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  0 minute read
</p>
            devinlife comments :
                싱글 페이지(포스트)에 제목 밑에 Updated 시간 표기
                기존에는 read_time이 표기. read_time -> date 변경
-->
            <p class="page__date"><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated: <time datetime="2021-08-06T00:00:00+09:00">August 06, 2021</time></p>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
        <h2 id="convolution">Convolution</h2>
<ul>
  <li>신호처리에서 정말 많이 등장하는 컨볼루션 연산입니다. 기계학습에서도 컨볼루션을 사용하여 학습을 하게 됩니다.</li>
  <li>아래 식은 각 뉴련들이 선형모델과 활성함수로 모두 연결된(fully connected) 구조를 가졌습니다.
    <ul>
      <li>$h_i = \sigma(\sum_{j=1}^{p}W_{i,j}x_j)$, $\sigma$는 활성함수, $W_{i,j}$는 가중치 행렬입니다.</li>
      <li>각 성분 $h_i$에 대응하는 가중치 행 $W_i$이 필요합니다.</li>
    </ul>
  </li>
  <li>컨볼루션 연산은 커널(kernel)을 입력벡터 상에서 움직여가면서 선형모델과 합성함수가 적용되는 구조입니다.
    <ul>
      <li>$h_i = \sigma(\sum_{j=1}^{k}V_jx_{i+j-1})$, $\sigma$는 활성함수, $V_j$는 가중치 행렬입니다.</li>
      <li>모든 $i$에 대해 적용되는 커널은 $V$로 같고 커널의 사이즈만큼 $x$상에서 이동하면서 적용됩니다.</li>
      <li>또한, 활성화 함수를 제외한 컨볼루션 연산도 선형변환에 속합니다.</li>
    </ul>
  </li>
  <li>컨볼루션 연산의 수학적인 의미는 신호(signal)를 커널을 이용해 국소적으로 증폭 또는 감소시켠서 정보의 추출을 필터링하는 것입니다.
    <ul>
      <li>Continuous : $[f*g](x) = \int_{R^d}f(z)g(x-z)dz = \int_{R^d}f(x-z)g(z)dz = [g*f](x)$</li>
      <li>discrete : $[f*g](i) = \sum_{a \in Z^d}f(a)g(i-a) = \sum_{a \in Z^d}f(i-a)g(a) = [g*f](i)$</li>
      <li>CNN에서 사용하는 연산은 Convolution이 아니고 cross-correlatoin이라 한다.</li>
    </ul>
  </li>
  <li>커널은 정의역 내에서 움직여도 변하지 않고(translation invariant) 주어진 신호에 국소적(local)으로 적용한다.</li>
  <li>또한, Convolution 연산은 1차원 뿐만 아니라 다양한 차원에서 계산 가능하다.
    <ul>
      <li>데이터의 성격에 따라 사용하는 커널이 달라진다.</li>
      <li>2D-conv $[f*g](i,j) = \sum_{p,q}f(p,q)g(i+p,j+q)$</li>
      <li>3D-conv $[f*g](i,j,k) = \sum_{p,q,r}f(p,q,r)g(i+p,j+q,k+r)$</li>
    </ul>
  </li>
</ul>

<h2 id="2d-convolution">2D Convolution</h2>
<ul>
  <li>2D-Conv 연산은 커널(kernel)을 입력벡터 상에서 움직여가면서 선형모델과 합성함수가 적용되는 구조이다.</li>
  <li>입력크기를 (H,W), 커널 크기를 ($K_H,K_W$), 출력크기를 ($O_H,O_W$)라 하면 출력 크기는 다음과 같이 계산한다.
    <ul>
      <li>$O_H = H-K_H+1$</li>
      <li>$O_W = W-K_W+1$</li>
    </ul>
  </li>
  <li>채널이 여러개인 2차원 입력의 경우 커널의 채널 수와 입력의 채널 수가 같아야 한다.
    <ul>
      <li>커널($K_H,K_W,C$) * 입력($H,W,C$) -&gt; 출력($O_H,O_W,1$)</li>
      <li>만약 커널을 $O_C$개 사용하면 출력도 $O_C$개가 된다. -&gt; 출력이 텐서가 된다.</li>
    </ul>
  </li>
</ul>

<h2 id="convolution연산의-역전파">Convolution연산의 역전파</h2>
<ul>
  <li>Conv 연산은 커널이 모든 입력데이터에 공통으로 적용되기 때문에 역전파를 계산할 때도 conv 연산이 나오게 된다.
    <ul>
      <li>$\frac{\partial}{\partial x}[f*g](x) = \frac{\partial}{\partial x}\int_{R^d}f(y)g(x-y)dy = \int_{R^d}f(y)\frac{\partial g}{\partial x}(x-y)dy = [f*g’](x)$</li>
      <li>Discrete 일 때도 성립한다.</li>
    </ul>
  </li>
</ul>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#convolution" class="page__taxonomy-item p-category" rel="tag">convolution</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#boostcamp" class="page__taxonomy-item p-category" rel="tag">BoostCamp</a>
    
    </span>
  </p>


        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2021-08-06T00:00:00+09:00">August 6, 2021</time></p>
        
      </footer>

      

      
  <nav class="pagination">
    
      <a href="/atcoder/abc205/" class="pagination--pager" title="AtCoder Beginner Contest 205
">Previous</a>
    
    
      <a href="/boostcamp/gradient-descent/" class="pagination--pager" title="경사하강법 정리
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You May Also Enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/data-engineer/kafka-pipeline/" rel="permalink">ksqlDB: 실시간 데이터 처리 후 시각화까지
</a>
      
    </h2>
    


    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> September 03 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">ksqlDB
ksqlDB는 Kafka Streams에 기반하는 SQL 엔진입니다. ksqlDB는 Kafka topic에 이벤트 스트리밍 애플리케이션을 구축할 수 있는 쿼리 계층을 제공합니다. Kafka Streams와 달리 ksqlDB는 SQL로 새로운 스트림을 생성하거나 Mate...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/pytorch/transformer-scratch-implementation-2/" rel="permalink">python으로 Transformer 바닥부터 구현하기[2] (Transformer)
</a>
      
    </h2>
    


    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> August 01 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">Objective
앞에서 구현한 LayerNorm, MultiHeadAttention, GELU를 사용하고 이전에 구현해둔 Linear, Dropout, Softmax 클래스를 사용하여 Transformer 클래스를 구현하여 테스트해봅니다.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/pytorch/transformer-scratch-implementation-1/" rel="permalink">python으로 Transformer 바닥부터 구현하기[1] (MultiHead-Attention, LayerNorm, GELU)
</a>
      
    </h2>
    


    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> July 31 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">Transformer
트랜스포머(Transformer)는 2017년에 등장한 모델입니다. Attention is all you need 논문은 트랜스포머 모델에 대해 설명하고 있으며 이후 BERT, GPT라는 새로운 모델을 탄생시키는 배경이 됩니다.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/paper/1-bit-llm/" rel="permalink">The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits
</a>
      
    </h2>
    


    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> March 03 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">Abstract
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2024 emeraldgoose. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




    <script>
  'use strict';

  (function() {
    var commentContainer = document.querySelector('#utterances-comments');

    if (!commentContainer) {
      return;
    }

    var script = document.createElement('script');
    script.setAttribute('src', 'https://utteranc.es/client.js');
    script.setAttribute('repo', 'emeraldgoose/emeraldgoose.github.io');
    script.setAttribute('issue-term', 'pathname');
    
    script.setAttribute('theme', 'github-light');
    script.setAttribute('crossorigin', 'anonymous');

    commentContainer.appendChild(script);
  })();
</script>

  




<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
  inlineMath: [['$','$']],
  displayMath: [['$$','$$']],
  processEscapes: true
  },
  "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>

  </body>
</html>
