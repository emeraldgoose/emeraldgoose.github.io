<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Generative models 정리 - gooooooooooose</title>
<meta name="description" content="Generative Models">


  <meta name="author" content="goooose">
  
  <meta property="article:author" content="goooose">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="gooooooooooose">
<meta property="og:title" content="Generative models 정리">
<meta property="og:url" content="http://localhost:4000/boostcamp/generative-model/">


  <meta property="og:description" content="Generative Models">







  <meta property="article:published_time" content="2021-08-13T00:00:00+09:00">





  

  


<link rel="canonical" href="http://localhost:4000/boostcamp/generative-model/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "emeraldgoose",
      "url": "http://localhost:4000/"
    
  }
</script>


  <meta name="google-site-verification" content="googleb34ce5276ba6573e" />





  <meta name="naver-site-verification" content="naver93cdc79a5629ab3736d7cf8ff7b51d80">


<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="gooooooooooose Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          gooooooooooose
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about/">About</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/">Categories</a>
            </li><li class="masthead__menu-item">
              <a href="/tags/">Tags</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://localhost:4000/">
        <img src="/assets/images/bio-photo.png" alt="goooose" itemprop="image" class="u-photo" width="110px" height="110px">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">goooose</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>Dev blog.</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">South Korea</span>
        </li>
      

      
        
          
            <li><a href="mailto:smk6221@naver.com" rel="nofollow noopener noreferrer me"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span></a></li>
          
        
          
        
          
        
          
        
          
            <li><a href="https://github.com/emeraldgoose" rel="nofollow noopener noreferrer me"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Generative models 정리">
    <meta itemprop="description" content="Generative Models">
    <meta itemprop="datePublished" content="2021-08-13T00:00:00+09:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Generative models 정리
</h1>
          
<!--
            <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  0 minute read
</p>
            devinlife comments :
                싱글 페이지(포스트)에 제목 밑에 Updated 시간 표기
                기존에는 read_time이 표기. read_time -> date 변경
-->
            <p class="page__date"><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated: <time datetime="2021-08-13T00:00:00+09:00">August 13, 2021</time></p>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              
                <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
                <ul class="toc__menu"><li><a href="#generative-models">Generative Models</a><ul><li><a href="#learning-a-generative-model">Learning a Generative Model</a></li><li><a href="#basic-discrete-distributions">Basic Discrete Distributions</a></li><li><a href="#example">Example</a></li><li><a href="#structure-through-independence">Structure Through Independence</a></li><li><a href="#conditional-independence">Conditional Independence</a></li><li><a href="#auto-regressive-model">Auto-regressive Model</a></li><li><a href="#nade-neural-autoregressive-density-estimator">NADE: Neural Autoregressive Density Estimator</a></li><li><a href="#pixel-rnn">Pixel RNN</a></li></ul></li><li><a href="#latent-variable-models">Latent Variable Models</a><ul><li><a href="#variational-auto-encoder-va">Variational Auto-encoder (VA)</a></li><li><a href="#adversarial-auto-encoder-aa">Adversarial Auto-encoder (AA)</a></li><li><a href="#generative-adversarial-network-gan">Generative Adversarial Network (GAN)</a></li><li><a href="#gan-vs-vae">GAN vs. VAE</a></li><li><a href="#gan-objective">GAN Objective</a></li></ul></li><li><a href="#dcgan">DCGAN</a><ul><li><a href="#info-gan">Info-GAN</a></li><li><a href="#text2image">Text2Image</a></li><li><a href="#puzzle-gan">Puzzle-GAN</a></li><li><a href="#cyclegan">CycleGAN</a></li><li><a href="#star-gan">Star-GAN</a></li><li><a href="#progressive-gan">Progressive-GAN</a></li></ul></li></ul>

              
            </nav>
            <!-- devinlife comment : right-sidebar ads -->
            <nav class="toc-custom">
              
            </nav>
          </aside>
        
        <h2 id="generative-models">Generative Models</h2>

<h3 id="learning-a-generative-model">Learning a Generative Model</h3>
<ul>
  <li>개의 이미지가 있다고 가정하면 개의 이미지에 대한 확률분포 $p(x)$를 알 수 있다.
    <ul>
      <li>Generation : 만약 $p(x)$에서 $x_{new}$를 sample할 수 있다면 $x_{new}$ 또한 개의 이미지이다. (샘플링, sampling)</li>
      <li>Density estimation : $x$가 개인지 고양인지 알아 낼 수 있다. (이상 탐지, anomaly detection)
        <ul>
          <li>입력이 주어졌을 때 입력에 대한 확률 값을 얻어낼 수 있는 모델을 explicit model이라 한다.
            <ul>
              <li>예를들어, 이미지를 만들어내고 그 이미지를 분류할 수 있는 모델을 말한다.</li>
            </ul>
          </li>
          <li>반대로 generation만 할 수 있는 모델을 implicit model이라 한다.</li>
        </ul>
      </li>
      <li>Unsupervised representation learning : 이미지가 가지고 있는 특징들을 학습할 수 있다. (feature learning)
        <ul>
          <li>예를들면 개의 꼬리, 귀와 같은 것들</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>how can we represent $p(x)$?</li>
</ul>

<h3 id="basic-discrete-distributions">Basic Discrete Distributions</h3>
<ul>
  <li>베르누이 분포 : (biased) coin flip -&gt; 0 or 1
    <ul>
      <li>D = {Heads, Tails}</li>
      <li>Specify $P(X=Heads) = p$. Then $P(X=Tails) = 1 - p$</li>
      <li>$X \sim Ber(p)$</li>
      <li>이 확률분포를 표현하는 숫자가 하나 필요하다.</li>
    </ul>
  </li>
  <li>카테코리 분포 : (biased) m-sided dice
    <ul>
      <li>D = {1,…,m}</li>
      <li>Specify $P(Y=i) = p_i$, such that $\sum_{i=1}^m p_i=1$</li>
      <li>$Y \sim Cat(p_1,…,p_m)$</li>
      <li>6면의 주사위를 던지는 데에는 5개의 파라미터만 있으면 된다. 왜냐하면 합계를 통해 나머지 한 면을 알 수 있기 때문</li>
    </ul>
  </li>
</ul>

<h3 id="example">Example</h3>
<ul>
  <li>RGB joint distribution을 모델링</li>
  <li>$(r,g,b) \sim p(R,G,B)$</li>
  <li>Number of case : 256 $\times$ 256 $\times$ 256</li>
  <li>이때 파라미터의 수는 256 $\times$ 256 $\times$ 256 - 1</li>
  <li>파라미터의 수가 많아질수록 학습은 어려워지기 때문에 파라미터 수를 줄이기 위한 노력이 필요하다</li>
</ul>

<h3 id="structure-through-independence">Structure Through Independence</h3>
<ul>
  <li>만약, $X_1, …, X_n$이 모두 independent하다면 $p(x_1,…,x_n)=p(x_1)p(x_2)…p(x_n)$로 표현할 수 있다.</li>
  <li>state의 수는 $2^n$개가 된다.</li>
  <li>$p(x_1,…,x_n)$을 표현하기 위한 파라미터의 수는 $n$개이다.</li>
  <li>$2^n$개의 엔트리를 단지 $n$개의 수로 표현가능하다. 그러나 independent하다는 가정이 너무 어렵다</li>
</ul>

<h3 id="conditional-independence">Conditional Independence</h3>
<ul>
  <li>3가지의 중요한 룰
    <ul>
      <li>Chain rule:
        <ul>
          <li>$p(x_1,…,x_n)=p(x_1)p(x_2|x_1)..p(x_n|x_1,…,x_{n-1})$</li>
          <li>$p(x_1)$ : 1 parameter</li>
          <li>$p(x_2|x_1)$ : 2 parameter ($p(x_2|x_1)=0$이라면 $p(x_2|x_1)=1$)</li>
          <li>$p(x_3|x_1,x_2)$ : 4 parameter</li>
          <li>따라서, $1 + 2 + 2^2 + … + 2^{n-1} = 2^n-1$이므로 이전과 같다.</li>
        </ul>
      </li>
      <li>Bayes’ rule:
        <ul>
          <li>$p(x|y) = \frac{p(x,y)}{p(y)} = \frac{p(y|x)p(x)}{p(y)}$</li>
        </ul>
      </li>
      <li>Conditional independence:
        <ul>
          <li>if $x \bot y |z$, then $p(x |y,z) = p(x|z)$</li>
          <li>$z$가 주어졌을 때 $x$와 $y$가 independent할 때, $p(x|y,z)$는 $p(x|z)$와 같기 때문에 $y$는 상관이 없다</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>이제 $X_{i+1} \bot X_1,…, X_{i-1}|X_i$ (Markov assumption)이라고 할 때
    <ul>
      <li>$p(x_1,…,x_n) = p(x_1)p(x_2|x_1)…p(x_n|x_{n-1})$</li>
      <li>이제 파라미터 수는 $2n-1$이 되었다.</li>
      <li>따라서 Markov assumption을 통해 파라미터 수를 줄일 수 있었다.</li>
    </ul>
  </li>
</ul>

<h3 id="auto-regressive-model">Auto-regressive Model</h3>
<ul>
  <li>28 x 28 바이너리 픽셀이 있다고 가정하자</li>
  <li>$p(x) = p(x_1,…,x_{784}), x \in [0,1] ^{784}$</li>
  <li>이것을 $p(x)$로 어떻게 표현할 수 있는가?
    <ul>
      <li>chain rule을 사용</li>
      <li>$p(x_{1:784})=p(x_1)p(x_2|x_1)p(x_3|x_{1:2})…$</li>
      <li>이러한 것을 autoregressive model이라 한다.
        <ul>
          <li>autoregressive model은 어떤 하나의 이전 정보가 이전 정보들에 대해 dependent한 것을 말한다.</li>
          <li>Markov assumption을 통해 i번째 픽셀이 i-1번째 픽셀에만 dependent한 것도 autoregressvie model이다.</li>
          <li>i번째 픽셀이 1부터 i-1번째 모두에 dependent한 것도 autoregressive model이다.</li>
        </ul>
      </li>
      <li>또한, 이미지 도메인과 같이 순서를 정하는 것이 필요하다.
        <ul>
          <li>순서를 매기는 것에 따라 성능과 방법이 달라질 수 있다.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>markov assumption을 주거나 어떤 임의의 conditional independence를 주는 것이 chain rule입장에서 joint distribution을 쪼개는 거에 어떤 관계가 있는 건지 잘 생각해봐야 한다.</li>
</ul>

<h3 id="nade-neural-autoregressive-density-estimator">NADE: Neural Autoregressive Density Estimator</h3>
<ul>
  <li>i번째 픽셀을 1부터 i-1에만 dependent하게 만든것</li>
  <li>$p(x_1|x_{1:i-1}) = \sigma(\alpha_ih_i+b_i)$ where $h_i = \sigma(W{&lt;i}x_{1:i-1}+c)$</li>
  <li>NADE는 explicit model이고 입력의 density를 계산한다.
    <ul>
      <li>784개의 바이너리 픽셀이 있다고 가정하면</li>
      <li>$p(x_1,..,x_{784})=p(x_1)p(x_2|x_1)…p(x_{784}|x_{1:784})$</li>
      <li>각 conditional probability $p(x_i|x_{1:i-1})$를 독립적으로 계산한다.</li>
    </ul>
  </li>
  <li>continuous random variable을 모델링하는 경우 가우시안 믹스쳐 모델을 사용한다.</li>
</ul>

<h3 id="pixel-rnn">Pixel RNN</h3>
<ul>
  <li>픽셀들을 만들어 내고 싶어하는 generative model이다.</li>
  <li>예를들어, n x n RGB 이미지를 원한다면
    <ul>
      <li>$P(x) = \Pi_{i=1}^{n^2}p(x_{i,R}|x_{&lt;i})p(x_{i,G}|x_{&lt;i},x_{i,R})p(x_{i,B}|x_{&lt;i},x_{i,R},x_{i,G})$</li>
      <li>$p(x_{i,R}|x_{&lt;i})$ : Prob. i-th Red</li>
      <li>$p(x_{i,G}|x_{&lt;i},x_{i,R})$ : Prob. i-th Green</li>
      <li>$p(x_{i,B}|x_{&lt;i},x_{i,R},x_{i,G})$ : Prob. i-th Blue</li>
    </ul>
  </li>
  <li>ordering에 따라 두 가지 모델로 나뉜다.
    <ul>
      <li>Row LSTM : 위쪽의 있는 정보를 활용하는 방법</li>
      <li>Diagonal BiLSTM : 자기 이전정보들을 모두 활용한 방법</li>
    </ul>
  </li>
</ul>

<h2 id="latent-variable-models">Latent Variable Models</h2>
<hr />
<ul>
  <li>autoencoder가 generative model인가?</li>
</ul>

<h3 id="variational-auto-encoder-va">Variational Auto-encoder (VA)</h3>
<ul>
  <li>Variational inference (VI)
    <ul>
      <li>Variational distribution을 찾는 목적은 posterior distribution을 찾기 위함이다.</li>
      <li>Posterior distribution : $p_{\theta}(z|x)$
        <ul>
          <li>Posterior distribution이란 observation이 주어졌을 때 관심있어하는 random variable의 확률분포이다.</li>
          <li>여기서 z는 Latent Variable이 된다.</li>
        </ul>
      </li>
      <li>Variational distribution : $q_{\phi}(z|x)$
        <ul>
          <li>Posterior distribution을 계산하는 것이 너무 힘들기 때문에 근사한 분포를 Variatoinal distribution이라 한다.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>따라서 관심있는 posterior사이의 KL divergence를 최소화하는(근사하는) variational distribution을 찾고 싶은 것을 Variational inference라 한다.</p>
  </li>
  <li>posterior가 뭔지도 모르는데 이것을 근사하는 variational distribution을 찾는 다는 것은 말이 안된다.</li>
  <li>그러나 target이 뭔지 모르는데 loss function을 줄일 수 있게 해주는 것이 VI의 ELBO(Evidence Lower Bound)다.
    <ul>
      <li>ELBO를 키움으로써 intractable objective를 줄이는 방법이다.</li>
      <li>In $P_{\theta}(D) = E_{q_{\phi}(z|x)} [In \frac{p_{\phi}(x,z)}{q_{\phi}(z|x)}](ELBO)+ D_{KL}(q_{\phi}(z|x)||p_{\theta}(z|x)) (Objective)$</li>
    </ul>
  </li>
  <li>다시 ELBO를 나누게 되면
    <ul>
      <li>$E_{q_{\phi}(z|x)} [In \frac{p_{\phi}(x,z)}{q_{\phi}(z|x)}] = \int In\frac{p_{\theta}(x|z)p(z)}{q_{\phi}(z|x)}q_{\phi}(z|x)dz$</li>
      <li>= $E_{q_{\phi}(z|x)}[p_{\theta}(x|z)] - D_{KL}(q_{\theta}(z|x)||p(z))$</li>
      <li>= Reconstruction Term - Prior Fitting Term
        <ul>
          <li>인코터를 통해서 x라는 입력을 latent space로 보냈다가 다시 디코더로 돌아오는 reconstruction loss를 줄이는 것이 reconstruction term이다.</li>
          <li>Prior Fitting Term은 이미지들을 latent space로 올리면 이미지들이 이루는 분포와 내가 가정하고 있는 latent space에서의 prior distribution을 비슷하게 만들어주는 것이 두 가지 분포를 모두 만족하는 것과 같다</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>결국 Variational Auto-encoder는 어떤 입력이 주어지고 latent space로 보내서 무언가를 찾고 다시 reconstruction하는 term으로 만들어지는데 generative model이 되기 위해서는 latent space된 prior distribution z를 샘플링 하고 디코더에 넣어서 나오는 어떤 output 도메인들의 값들이 바로 generation result라고 본다.</li>
  <li>
    <p>하지만 엄밀한 의미에서 입력을 넣어서 아웃풋이 나오는  auto-encoder는 generative model이 아니다.</p>
  </li>
  <li>Key limitation:
    <ul>
      <li>explicit 모델이 아니다. 어떤 입력이 주어졌을 때 얼마나 likelihood한지 알기 어렵다.</li>
      <li>prior fitting term에서 KL divergence는 가우시안을 제외하고 closed form이 나오는 경우가 거의 없다.</li>
      <li>일반적으로는 isotropic Gaussian을 사용한다.
        <ul>
          <li>모든 output dimension이 independent한 분포</li>
          <li>$D_{KL}(q_{\phi}(z|x)||N(0,I)) = \frac{1}{2}\sum_{i=1}^D(\sigma_{z_i}^2+\mu_{z_i}^2-ln(\sigma_{z_i}^2)-1)$</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="adversarial-auto-encoder-aa">Adversarial Auto-encoder (AA)</h3>
<ul>
  <li>auto encoder의 가장 큰 단점은 가우시안을 활용해야 한다는 점이다.
    <ul>
      <li>가우시안이 아닌 다른 분포를 활용하기 위해 adversarial auto-encoder를 사용한다.</li>
    </ul>
  </li>
  <li>VA보다 AA가 성능이 좋은 경우도 많다.</li>
</ul>

<h3 id="generative-adversarial-network-gan">Generative Adversarial Network (GAN)</h3>
<ul>
  <li>generator는 discriminator를 속이기위해 fake data를 생성한다.</li>
  <li>discriminator는 real data와 fake data를 판별한다.</li>
  <li>disciminator의 성능이 올라갈수록 generator 또한 성능이 같이 올라간다.</li>
  <li>$min_G max_D V(D,G) = E_{x\sim P_{data}(x)}[log D(x)] + E_{z \sim p_z(z)}[log(1-D(G(z)))]$</li>
  <li>implicit 모델이다.</li>
</ul>

<h3 id="gan-vs-vae">GAN vs. VAE</h3>
<ul>
  <li>VAE : x라는 이미지 혹은 입력 도메인이 들어오면 인코더를 통해 latent vector로 갔다가 z를 샘플링해서 디코더를 통해 x가 generative 결과가 된다.</li>
  <li>GAN : z를 통해서 fake가 생성된다. Discriminator는 분류기를 학습하고 generator는 discriminator 입장에서 true가 나오도록 다시 업데이트하고 discriminator는 업데이트된 generator의 생성 결과물을 분류할 수 있도록 성장한다.</li>
</ul>

<h3 id="gan-objective">GAN Objective</h3>
<ul>
  <li>generator와 discriminator 사이의 minmax 게임이다.
    <ul>
      <li>minmax 게임은 한쪽은 높이고 싶어하고 한쪽은 낮추고 싶어하는 게임</li>
    </ul>
  </li>
  <li>For discriminator
    <ul>
      <li>$max_D V(G,D) = E_{x \sim p_{data}}[log D(x)] + E_{x \sim p_G} [log(1-(D(x))$</li>
      <li>where the optimal discriminator is
        <ul>
          <li>$D_G^*(x) = \frac{P_{data}(x)}{P_{data}(x)+P_G(x)}$</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>For generator
    <ul>
      <li>$min_G V(G,D) = E_{x \sim p_{data}}[log D(x)] + E_{x \sim p_G} [log(1-(D(x))$</li>
      <li>Plugging in the optimal discriminator,
        <ul>
          <li>$V(G, D_G^*(x)) = D_{KL}[P_{data},\frac{P_{data}+P_G}{2}] + D_{KL}[P_G,\frac{P_{data}+P_G}{2}] - log 4$</li>
        </ul>
      </li>
      <li>2 x Jenson-Shannon Divergence (JSD) = $2D_{JSD}[P_{data},P_G] - log 4$</li>
      <li>GAN의 Objective가 많은 경우 true data distribution를 real data distribution에 가까워지게 하는 것
        <ul>
          <li>즉, Jenson-Shannon Divergence를 최소화하는 것이다.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="dcgan">DCGAN</h2>

<h3 id="info-gan">Info-GAN</h3>
<ul>
  <li>z와 class를 의미하는 c를 통해 한 곳에 집중시켜주는 방법</li>
</ul>

<h3 id="text2image">Text2Image</h3>
<ul>
  <li>문장이 주어지면 이미지를 생성</li>
</ul>

<h3 id="puzzle-gan">Puzzle-GAN</h3>
<ul>
  <li>이미지 안에 subpatch가 있고 subpatch를 가지고 원래 이미지로 복원</li>
</ul>

<h3 id="cyclegan">CycleGAN</h3>
<ul>
  <li>Cycle-consistency loss</li>
  <li>GAN 구조가 두 개 들어가 있는 구조</li>
</ul>

<h3 id="star-gan">Star-GAN</h3>
<ul>
  <li>이미지를 다른 도메인으로 바꾸는 것이 아닌 특정 영역을 컨트롤 할 수 있는 구조</li>
</ul>

<h3 id="progressive-gan">Progressive-GAN</h3>
<ul>
  <li>4x4에서 시작해서 1024x1024로 점차적으로 학습시키는 구조</li>
  <li>한번에 고해상도 이미지를 만드는 것은 무리가 간다.</li>
</ul>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#model" class="page__taxonomy-item p-category" rel="tag">model</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#boostcamp" class="page__taxonomy-item p-category" rel="tag">BoostCamp</a>
    
    </span>
  </p>


        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2021-08-13T00:00:00+09:00">August 13, 2021</time></p>
        
      </footer>

      

      
  <nav class="pagination">
    
      <a href="/boostcamp/cnn/" class="pagination--pager" title="CNN 정리
">Previous</a>
    
    
      <a href="/boostcamp/mlp/" class="pagination--pager" title="MLP 정리
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You may also enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/pytorch/cnn-implementation/" rel="permalink">최대한 기본 라이브러리로만 CNN 구현하기
</a>
      
    </h2>
    


    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> September 21 2022</p>
    
    <p class="archive__item-excerpt" itemprop="description">Related

  이전 포스트에서 MLP를 구현했고 이번에는 CNN을 구현하는 삽질을 진행했습니다.
여기서는 Conv2d의 구현에 대해서만 정리하려고 합니다. 밑바닥부터 구현하실때 도움이 되었으면 좋겠습니다.

</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/pytorch/dl-implement/" rel="permalink">최대한 기본 라이브러리로만 딥러닝 구현하기
</a>
      
    </h2>
    


    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> July 04 2022</p>
    
    <p class="archive__item-excerpt" itemprop="description">동기

  모기업 코딩테스트에 파이썬 기본 라이브러리로만 MLP를 구현하는 문제가 나왔던 적이 있습니다. 당시에 학습이 되지 않아 코딩테스트에서 떨어졌었고 구현하지 못했던 것이 계속 생각났었습니다.
그리고 numpy로 구현한 코드는 많았지만 numpy도 사용하지 않고 구현한 코드는...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/paper/On-the-effect-of-corpora/" rel="permalink">On the Effect of Pretraining Corpora on In-context Learning by a LLM
</a>
      
    </h2>
    


    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> June 06 2022</p>
    
    <p class="archive__item-excerpt" itemprop="description">
  모두의연구소에서 논문저자가 직접 논문을 리뷰해주는 세미나가 열렸습니다. 주제가 재밌어 보여 발표를 듣고 논문을 다시 읽어 리뷰해보려고 합니다.

</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ops/kubenetes-overview/" rel="permalink">Kubernetes
</a>
      
    </h2>
    


    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> May 15 2022</p>
    
    <p class="archive__item-excerpt" itemprop="description">컨테이너 기반 배포
애플리케이션 배포 방식은 물리적인 컴퓨터에 OS와 APP을 설치하여 서비스하던 방식에서 가상화 배포 방식으로 변화했습니다. 가상화 방식은 가상머신 성능을 각각 관리하면서 자원 상황에 따라 조절할 수 있습니다. 그러나 가상머신마다 OS를 새로 설치해야 하고 용량 ...</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2022 emeraldgoose. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




    <script>
  'use strict';

  (function() {
    var commentContainer = document.querySelector('#utterances-comments');

    if (!commentContainer) {
      return;
    }

    var script = document.createElement('script');
    script.setAttribute('src', 'https://utteranc.es/client.js');
    script.setAttribute('repo', 'emeraldgoose/emeraldgoose.github.io');
    script.setAttribute('issue-term', 'pathname');
    
    script.setAttribute('theme', 'github-light');
    script.setAttribute('crossorigin', 'anonymous');

    commentContainer.appendChild(script);
  })();
</script>

  




<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
  inlineMath: [['$','$']],
  displayMath: [['$$','$$']],
  processEscapes: true
  },
  "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>

  </body>
</html>
