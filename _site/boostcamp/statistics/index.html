<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Statistics 정리 - gooooooooooose</title>
<meta name="description" content="통계적 모델링    적절한 가정 위에서 확률분포를 추정(inference)하는 것이 목표이며, 기계학습과 통계학이 공통적으로 추구하는 목표입니다.   그러나 유한개의 데이터만 관찰해서 모집단의 분포를 정확하게 알아내는 것은 불가능하므로, 근사적으로 확률분포를 추정해야 합니다.            예측모형의 목적은 분포를 정확하게 맞추는 것보다 데이터의 추정 방법의 불확실성을 고려해서 위험(risk)을 최소화하는 것입니다.           데이터가 특정 확률분포를 따른다고 가정한 뒤 그 분포를 결정하는 모수(parameter)를 추정하는 방법을 모수적(parametric) 방법론이라 합니다.            예를들어, 정규분포에서 평균 $\mu$과 분산 $\sigma^2$이 모수라고 할 수 있습니다.           반면에, 특정 확률분포를 가정하지 않고 데이터에 따라 모델의 구조와 모수의 개수가 유연하게 바뀌면 비모수(nonparametric) 방법론이라 합니다.            비모수 방법론은 모수가 너무 많거나 데이터에 따라 모수가 자주 바뀌는 경우를 말하기 때문에 모수가 없다고 할 수 없습니다.">


  <meta name="author" content="goooose">
  
  <meta property="article:author" content="goooose">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="gooooooooooose">
<meta property="og:title" content="Statistics 정리">
<meta property="og:url" content="http://localhost:4000/boostcamp/statistics/">


  <meta property="og:description" content="통계적 모델링    적절한 가정 위에서 확률분포를 추정(inference)하는 것이 목표이며, 기계학습과 통계학이 공통적으로 추구하는 목표입니다.   그러나 유한개의 데이터만 관찰해서 모집단의 분포를 정확하게 알아내는 것은 불가능하므로, 근사적으로 확률분포를 추정해야 합니다.            예측모형의 목적은 분포를 정확하게 맞추는 것보다 데이터의 추정 방법의 불확실성을 고려해서 위험(risk)을 최소화하는 것입니다.           데이터가 특정 확률분포를 따른다고 가정한 뒤 그 분포를 결정하는 모수(parameter)를 추정하는 방법을 모수적(parametric) 방법론이라 합니다.            예를들어, 정규분포에서 평균 $\mu$과 분산 $\sigma^2$이 모수라고 할 수 있습니다.           반면에, 특정 확률분포를 가정하지 않고 데이터에 따라 모델의 구조와 모수의 개수가 유연하게 바뀌면 비모수(nonparametric) 방법론이라 합니다.            비모수 방법론은 모수가 너무 많거나 데이터에 따라 모수가 자주 바뀌는 경우를 말하기 때문에 모수가 없다고 할 수 없습니다.">







  <meta property="article:published_time" content="2021-08-06T00:00:00+09:00">





  

  


<link rel="canonical" href="http://localhost:4000/boostcamp/statistics/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "emeraldgoose",
      "url": "http://localhost:4000/"
    
  }
</script>


  <meta name="google-site-verification" content="googleb34ce5276ba6573e" />





  <meta name="naver-site-verification" content="naver93cdc79a5629ab3736d7cf8ff7b51d80">


<!-- end _includes/seo.html -->




<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single wide">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about/">About</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/">Categories</a>
            </li><li class="masthead__menu-item">
              <a href="/tags/">Tags</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      


  
    



<nav class="breadcrumbs">
  <ol itemscope itemtype="https://schema.org/BreadcrumbList">
    
    
    
      
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/" itemprop="item"><span itemprop="name">Home</span></a>

          <meta itemprop="position" content="1" />
        </li>
        <span class="sep">/</span>
      
      
        
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/categories/#boostcamp" itemprop="item"><span itemprop="name">Boostcamp</span></a>
          <meta itemprop="position" content="2" />
        </li>
        <span class="sep">/</span>
      
    
      
      
        <li class="current">Statistics 정리</li>
      
    
  </ol>
</nav>

  


<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://localhost:4000/">
        <img src="/assets/images/bio-photo.png" alt="goooose" itemprop="image" class="u-photo" width="110px" height="110px">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">goooose</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>Interested in ML/DL, Data Engineering.</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">South Korea</span>
        </li>
      

      
        
          
            <li><a href="mailto:smk6221@naver.com" rel="nofollow noopener noreferrer me"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span></a></li>
          
        
          
        
          
        
          
        
          
            <li><a href="https://github.com/emeraldgoose" rel="nofollow noopener noreferrer me"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
        
          
            <li><a href="https://www.linkedin.com/in/minseong-kim-84428b231/" rel="nofollow noopener noreferrer me"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span class="label">LinkedIn</span></a></li>
          
        
          
            <li><a href="https://gooooooooooose.tistory.com/" rel="nofollow noopener noreferrer me"><i class="fas fa-fw fa-link" aria-hidden="true"></i><span class="label">Tistory</span></a></li>
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Statistics 정리">
    <meta itemprop="description" content="통계적 모델링  적절한 가정 위에서 확률분포를 추정(inference)하는 것이 목표이며, 기계학습과 통계학이 공통적으로 추구하는 목표입니다.  그러나 유한개의 데이터만 관찰해서 모집단의 분포를 정확하게 알아내는 것은 불가능하므로, 근사적으로 확률분포를 추정해야 합니다.          예측모형의 목적은 분포를 정확하게 맞추는 것보다 데이터의 추정 방법의 불확실성을 고려해서 위험(risk)을 최소화하는 것입니다.        데이터가 특정 확률분포를 따른다고 가정한 뒤 그 분포를 결정하는 모수(parameter)를 추정하는 방법을 모수적(parametric) 방법론이라 합니다.          예를들어, 정규분포에서 평균 $\mu$과 분산 $\sigma^2$이 모수라고 할 수 있습니다.        반면에, 특정 확률분포를 가정하지 않고 데이터에 따라 모델의 구조와 모수의 개수가 유연하게 바뀌면 비모수(nonparametric) 방법론이라 합니다.          비모수 방법론은 모수가 너무 많거나 데이터에 따라 모수가 자주 바뀌는 경우를 말하기 때문에 모수가 없다고 할 수 없습니다.      ">
    <meta itemprop="datePublished" content="2021-08-06T00:00:00+09:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Statistics 정리
</h1>
          
<!--
            <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  0 minute read
</p>
            devinlife comments :
                싱글 페이지(포스트)에 제목 밑에 Updated 시간 표기
                기존에는 read_time이 표기. read_time -> date 변경
-->
            <p class="page__date"><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated: <time datetime="2021-08-06T00:00:00+09:00">August 06, 2021</time></p>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
        <h2 id="통계적-모델링">통계적 모델링</h2>
<ul>
  <li>적절한 가정 위에서 확률분포를 추정(inference)하는 것이 목표이며, 기계학습과 통계학이 공통적으로 추구하는 목표입니다.</li>
  <li>그러나 유한개의 데이터만 관찰해서 모집단의 분포를 정확하게 알아내는 것은 불가능하므로, 근사적으로 확률분포를 추정해야 합니다.
    <ul>
      <li>예측모형의 목적은 분포를 정확하게 맞추는 것보다 데이터의 추정 방법의 불확실성을 고려해서 위험(risk)을 최소화하는 것입니다.</li>
    </ul>
  </li>
  <li>데이터가 특정 확률분포를 따른다고 가정한 뒤 그 분포를 결정하는 모수(parameter)를 추정하는 방법을 모수적(parametric) 방법론이라 합니다.
    <ul>
      <li>예를들어, 정규분포에서 평균 $\mu$과 분산 $\sigma^2$이 모수라고 할 수 있습니다.</li>
    </ul>
  </li>
  <li>반면에, 특정 확률분포를 가정하지 않고 데이터에 따라 모델의 구조와 모수의 개수가 유연하게 바뀌면 비모수(nonparametric) 방법론이라 합니다.
    <ul>
      <li>비모수 방법론은 모수가 너무 많거나 데이터에 따라 모수가 자주 바뀌는 경우를 말하기 때문에 모수가 없다고 할 수 없습니다.</li>
    </ul>
  </li>
</ul>

<h2 id="확률분포-가정">확률분포 가정</h2>
<ul>
  <li>확률분포를 가정하는 방법으로 아래와 같은 예제들이 존재합니다.
    <ul>
      <li>데이터가 2개의 값(0, 1)만 가지는 경우 : 베르누이 분포</li>
      <li>데이터가 n개의 이산적인 값만 가지는 경우 : 카테고리 분포</li>
      <li>데이터가 [0,1] 사이에서 값을 가지는 경우 : 베타 분포</li>
      <li>데이터가 0이상의 값을 가지는 경우 : 감마분포, 로그정규분포 등</li>
      <li>데이터가 R 전체에서 값을 가지는 경우 -&gt; 정규 분포, 라플라스 분포 등</li>
    </ul>
  </li>
  <li>그러나, 예외가 있을 수 있으므로 데이터가 생성되는 원리를 먼저 고려하여 확률분포를 가정해야 합니다.
    <ul>
      <li>예를들어, 항상 양수인 데이터인 경우 정규분포로 모형화가 가능하다면 정규분포를 사용할 수 있습니다.</li>
    </ul>
  </li>
  <li>확률분포를 가정했다면 이제 데이터로부터 해당 확률분포의 모수의 값을 구해야 합니다.</li>
</ul>

<h2 id="모수-추정-방법론">모수 추정 방법론</h2>
<ul>
  <li>모수의 값으로 가장 가능성이 높은 하나의 숫자를 찾아내는 작업을 모수 추정(parameter estimation)이라 합니다.</li>
  <li>모수를 추정할 수 있는 방법은 다음과 같습니다.
    <ul>
      <li>모멘트 방법(Method of Moment, MM)</li>
      <li>최대가능도 추정법(Maximum likelihood estimation, MLE)</li>
      <li>베이즈 추정법(Bayesian estimation)</li>
    </ul>
  </li>
</ul>

<h2 id="모멘트-방법">모멘트 방법</h2>
<ul>
  <li>모멘트 방법은 표본자료에 대하 표본모멘트가 확률분포의 이론적 모멘트와 같다고 가정하여 모수를 구하는 방법입니다.</li>
  <li>1차 모멘트(평균) : $\mu = E[\bar{x}] = \frac{1}{N}\sum_{i=1}^{N}X_i$</li>
  <li>2차 모멘트(분산) : $\sigma^2 = E[(X - \mu)^2] = \bar{s}^2=\frac{1}{N-1}\sum_{i=1}^{N}(X_i-\bar{X})^2$
    <ul>
      <li>평균과 달리 (N-1)로 나누는 이유는 불편추정량(unbiased estimate)을 구하기 위해서입니다.</li>
      <li>불편추정량이란, 추정량의 기댓값과 실제 모수와의 차이가 없는 경우를 말합니다.</li>
      <li>베셀 보정(Bassel’s Correction)을 검색하시면 관련 내용을 보실 수 있습니다.</li>
    </ul>
  </li>
</ul>

<h2 id="표집분포-표본분포">표집분포? 표본분포?</h2>
<ul>
  <li>표집분포(sample distribution)
    <ul>
      <li>모집단의 속성을 알기 위해 모집단을 대표할 수 있게 추출된 대상군의 분포입니다.</li>
      <li>표본의 속성은 표본평균과 표준편차로 표기하며 통계치 혹은 추정치라 합니다.</li>
      <li>항상 정규분포를 따르지 않습니다.</li>
    </ul>
  </li>
  <li>표본분포(sampling distribution)
    <ul>
      <li>추리통계의 의사결정을 위한 이론적 분포</li>
      <li>이론적으로 표본의 크기가 n인 표본을 무한히 반복 추출한 후 무한개의 표본들의 평균을 가지고 그린 분포로 추정치의 분포라고도 함</li>
      <li>n이 커질수록 정규분포를 따른다.</li>
    </ul>
  </li>
  <li>중심극한정리(central limit theorem)
    <ul>
      <li>표집분포의 평균은 모집합의 평균이다.</li>
      <li>표집분포의 분산은 모집단의 분산을 표본의 크기로 나눈 것과 같다.</li>
      <li>표본의 크기가 충분히 클 때(N&gt;30) 모집단의 분포와 상관없이 정규분포가 된다.</li>
    </ul>
  </li>
</ul>

<h2 id="최대가능도-추정법">최대가능도 추정법</h2>
<ul>
  <li>표본평균이나 표본분산은 확률분포마다 사용하는 모수가 다르므로 적절한 통계량이 달라지게 된다.</li>
  <li>이론적으로 가장 가능성이 높은 모수를 추정하는 방법 중 하나가 최대가능도 추정법이다.</li>
  <li>먼저, 확률과 가능도의 차이를 알아보자.
    <ul>
      <li>10개의 동전을 던져 3번 앞면이 나왔다고 가정하자.</li>
      <li>확률 : 앞면이 나올 확률은 0.3이다. $\rightarrow$ 확률실험의 결과를 집계한 것</li>
      <li>가능도 : 10개의 동전을 던져 앞면이 나올 확률에 따라 앞면이 3번 나올 가능성을 말한다.</li>
    </ul>
  </li>
  <li>확률분포 $X$에 대한 확률밀도함수 또는 확률질량함수를 다음과 같이 대표해서 사용한다
    <ul>
      <li>$p(x;\theta)$
        <ul>
          <li>$x$는 확률분포가 가질 수 있는 실수값이며 $x$는 스칼라값일 수도 벡터값일 수도 있다.</li>
          <li>$\theta$는 확률밀도함수의 모수를 표시하는 대표기호이며 $\theta$도 스칼라일 수도 있고 벡터일 수도  있다.</li>
          <li>확률밀도함수에서는 모수 $\theta$가 이미 알고 있는 상수계수고 $x$가 변수이다.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>모수 추정 문제에서는 $x$값은 알고 있지만 모수 $\theta$를 모르기 때문에 반대로 x를 이미 알고있는 상수계수로 놓고 $\theta$를 변수로 생각한다.
    <ul>
      <li>이 함수를 가능도함수(likelihood function)이라 하고 $L(\theta;x)$ 기호로 표기하고 다음과 같이 정의한다.
        <ul>
          <li>$L(\theta;x) = P(x \vert  \theta)$</li>
          <li>가능도 값을 계산하는 함수를 가능도 함수라 한다.</li>
        </ul>
      </li>
      <li>최대가능도 추정법은 주어진 표본에 대해 가능도를 가장 크게 하는 모수 $\theta$를 찾는 방법
        <ul>
          <li>$\hat{\theta}_\text{MLE} = \text{argmax}_{\theta} L(\theta;x) = \text{argmax}_\theta p(x \vert \theta)$</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>가능도 함수와 확률밀도함수의 수식은 같다. 그러나 가능도 함수는 확률밀도함수가 아니다.
    <ul>
      <li>$\int_{-\infty}^{\infty} p(x;\theta)dx = 1$</li>
      <li>$\int_{-\infty}^{\infty}L(\theta;x)d\theta = \int_{-\infty}^{\infty}p(x;\theta)d\theta ≠ 1$ (적분하면 전체 면적이 1이 아닐 수 있다)</li>
    </ul>
  </li>
</ul>

<h3 id="복수의-표본-데이터가-있는-경우">복수의 표본 데이터가 있는 경우</h3>

<ul>
  <li>일반적으로 확률변수 표본의 수가 여러개 {$x_1, x_2, … , x_N$}이므로 가능도 함수에서 복수 표본값에 대한 결합확률밀도 $p_{x_1x_2x_3…x_N}(x_1,x_2,x_3,…,x_N;\theta)$가 된다</li>
  <li>$x_1, x_2, …, x_N$은 같은 확률분포에서 나온 독립적인 값들이므로 결합밀도함수는 다음과 같이 곱으로 표현된다.
    <ul>
      <li>$L(\theta; x_1, x_2, …, x_N) = p(x_1, x_2, …, x_N \vert  \theta) = \prod_{i=1}^{N} p(x_i\vert \theta)$</li>
    </ul>
  </li>
  <li>일반적으로 최대가능도 추정법을 사용하여 최대가 되는 $\theta$를 찾기 위해 최적화를 진행해야한다.
    <ul>
      <li>보통 로그가능도함수 $LL = log\space L$을 사용하는 경우가 많다.
        <ul>
          <li>로그 변환에 의해서는 최댓값의 위치가 변하지 않는다.</li>
          <li>복수 표본 데이터의 경우, 결합확률밀도함수가 동일한 함수의 곱으로 나타나게 되는데 로그 변환에 의해 곱셈이 덧셈이 되어 계산이 편해진다.</li>
        </ul>
      </li>
      <li>$log\space L(\theta; X) = \sum_{i=1}^{N} log\space P(x_i\vert \theta)$</li>
    </ul>
  </li>
</ul>

<h3 id="최대가능도-예제-정규분포">최대가능도 예제: 정규분포</h3>

<ul>
  <li>정규분포를 따른 확률변수 $X$로부터 독립적인 표본 $n$개를 얻었을 때, 최대가능도 추정법을 이용하여 모수를 추정하면?
    <ul>
      <li>정규분포 $p(x) = \frac{1}{\sqrt(2\pi\sigma^2)}e^{-\frac{\vert x_i-\mu\vert ^2}{2\sigma^2}}$</li>
      <li>$\begin{matrix} log L(\theta; X) &amp;=&amp; \sum_{i=1}^{n} log\space P(x_i\vert \theta) \ &amp;=&amp; \sum_{i=1}^{n}\frac{1}{\sqrt(2\pi\sigma^2)}e^{-\frac{\vert x_i-\mu\vert ^2}{2\sigma^2}} \ &amp;=&amp; -\frac{n}{2}log2\pi\sigma^2 - \sum_{i=1}^{n}\frac{\vert x_i-\mu\vert ^2}{2\sigma^2} \end{matrix}$</li>
      <li>$log\space L$에 대해 $\mu$와 $\theta$로 미분하여 0이 되는 지점을 찾으면 가능도를 최대화할 수 있다.
        <ul>
          <li>$0 = \frac{\partial log\space L}{\partial \mu}=-\sum_{i=1}^{n}\frac{x_i-\mu}{\sigma^2} \Rightarrow \hat{\mu}_{MLE}=\frac{1}{n}\sum_{i=1}^{n}x_i$</li>
          <li>$0 = \frac{\partial log\space L}{\partial \sigma}=-\frac{n}{\sigma}+\frac{1}{\sigma^3}\sum_{i=1}^{n}\vert x_i-\mu\vert ^2 \Rightarrow \hat{\sigma}_{MLE}^2 = \frac{1}{n}\sum_{i=1}^{n}(x_i-\mu)^2$</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>정규분포로부터 표본값 {1, 0, -3}을 얻었다고 가정하자.
    <ul>
      <li>$log\space L(\theta;x_1,x_2,x_3) = log\space (\frac{1}{(2\pi\sigma^2)^\frac{3}{2}})-\frac{3\mu^2+4\mu+10}{2\sigma^2} = log\space (\frac{1}{(2\pi\sigma^2)^\frac{3}{2}})-\frac{3(\mu+\frac{2}{3}) +\frac{26}{3}}{2\sigma^2}$</li>
      <li>따라서 최댓값의 위치 $\mu = -\frac{2}{3}$를 찾을 수 있다.</li>
    </ul>
  </li>
</ul>

<h3 id="최대가능도-예제-카테고리분포">최대가능도 예제: 카테고리분포</h3>

<ul>
  <li>카테고리 분포 Multinoulli$(x;p_1,…p_d)$를 따르는 확률변수 $X$로부터 독립적인 표본 {$x_1, …,x_n$}을 얻었을 때, 최대가능도 추정법을 이용하여 모수를 추정하면?</li>
  <li>모수가 $\mu=(\mu_1,…,\mu_k)$인 카테고리분포의 확률질량함수는 다음과 같다.
    <ul>
      <li>$p(x; \mu_1,…,\mu_k)=Cat(x;\mu_1,…,\mu_k)=\prod_{i=1}^{k}\mu_i^{x_i}, \space (\sum_{i=1}^{k}\mu_i=1)$</li>
      <li>이 식에서 $x$는 모두 $k$개의 원소를 가지는 원핫인코딩(one-hot-encoding) 벡터이다.</li>
      <li>표본데이터가 $x_1,x_2,…,x_n$이 있을 경우 모두 독립이므로 전체 확률밀도함수는 각각의 확률질량함수의 곱과 같다.
        <ul>
          <li>$L(\mu_1, …, \mu_k;x_1,…x_k) = \prod_{i=1}^{n}\prod_{k=1}^{d}\mu_k^{x_{i,k}}$</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>로그 변환을 한 로그가능도를 구하면 다음과 같다.
    <ul>
      <li>$\hat{\theta}_{\text{MLE}} = \text{argmax}_{p1,…,p_d} log(\prod_{i=1}^{n}\prod_{k=1}^{d}p_k^{x_{i,k}})$</li>
      <li>$log(\prod_{i=1}^{n}\prod_{k=1}^{d}p_k^{x_{i,k}})=\sum_{k=1}^d(\sum_{i=1}^nx_{i,k})log\space p_k, \space n_k=\sum_{i=1}^n x_{i,k}$
        <ul>
          <li>$n_k$는 주어진 각 데이터들에 대해서 $k$값이 1인 개수를 카운팅하는 값으로 대체할 수 있다.</li>
        </ul>
      </li>
      <li>$\sum_{k=1}^d n_k log\space p_k$와 $\sum_{k=1}^dp_k=1$의 식을 모두 만족하면서 최대가능도를 추정해야한다.</li>
      <li>라그랑주 승수법을 통해 새로운 목적식을 만들 수 있다.
        <ul>
          <li>$\sum_{k=1}^{d}n_klog\space p_k+\lambda(1-\sum_k p_k)$</li>
          <li>$0=\frac{\partial L}{\partial p_k}=\frac{n_k}{p_k}-\lambda, \space 0=\frac{\partial L}{\partial \lambda}=1-\sum_{k=1}^{d}p_k$</li>
          <li>$p_k=\frac{n_k}{\sum_{k=1}^dn_k}$</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="딥러닝에서-최대가능도-추정법">딥러닝에서 최대가능도 추정법</h2>

<ul>
  <li>딥러닝 모델의 가중치를 $\theta = (W^{(1)},…,W^{(L)})$라 표기했을 때 분류문제에서 소프트맥스 벡터는 카테고리분포의 모수 $(p_1,…,p_k)$를 모델링한다.</li>
  <li>원핫벡터로 표현한 정답레이블 $y=(y_1,…,y_k)$을 관찰데이터로 이용해 확률분포인 소프트맥스 벡터의 로그가능도를 최적화할 수 있다.
    <ul>
      <li>$ \hat{\theta}_{\text{MLE}}=\text{argmax}_{\theta}\frac{1}{n}\sum_{i=1}^n\sum_{k=1}^{K}y_{i,k}log(\text{MLP}_{\theta}(x_i)_k) $</li>
    </ul>
  </li>
</ul>

<h2 id="확률분포의-거리">확률분포의 거리</h2>

<ul>
  <li>기계학습에서 사용되는 손실함수들은 모델이 학습하는 확률분포와 데이터에서 관찰되는 확률분포의 거리를 통해 유도한다</li>
  <li>데이터공간에 두 개의 확률분포 P(x), Q(x)가 있을 경우 두 확률분포 사이의 거리(distant)를 계산할 때 다음과 같은 함수를 이용
    <ul>
      <li>총변동 거리(Total Variation Distance, TV)</li>
      <li>쿨백-라이블러 발산(Kullback-Leibler Divergence, KL)</li>
      <li>바슈타인 거리(Wasserstein Distance)</li>
    </ul>
  </li>
</ul>

<h3 id="쿨백-라이블러-발산">쿨백-라이블러 발산</h3>

<ul>
  <li>쿨백-라이블러 발산은 다음과 같이 정의한다.
    <ul>
      <li>이산확률변수 : $KL(P\Vert Q)=\sum_{x\in\chi}P(x)log(\frac{P(x)}{Q(x)})$</li>
      <li>연속확률변수 : $KL(P\Vert Q)=\int_{\chi}P(x)log(\frac{P(x)}{Q(x)})dx$</li>
    </ul>
  </li>
  <li>쿨백-라이블러 발산을 다음과 같이 분해할 수 있다.
    <ul>
      <li>$KL(P\Vert Q)=-E_{x\sim P(x)}[logQ(x)]+E_{x\sim P(x)}[logP(x)]=$ 크로스 엔트로피 + 엔트로피</li>
    </ul>
  </li>
  <li>분류 문제에서 정답레이블을 $P$, 모델 예측을 $Q$라 두면 최대가능도 추정법은 쿨백-라이블러 발산을 최소화하는 것과 같다.</li>
  <li>쿨백-라이블러 발산에서 p와 q를 바꾼 값과 원래의 값이 다르다. 즉, 비대칭(asymmetric)하다.
    <ul>
      <li>$KL(p\Vert q)=H(p,q)-H(p) ≠ H(q,p)-H(q)=KL(q\Vert p)$ $\Rightarrow$ $KL(p\Vert q) ≠ KL(q\Vert p)$</li>
      <li>만약, 두 확률분포 사이의 거리라면 p에서 q사이의 거리나 q에서 p사이의 거리나 같아야 한다. 따라서 KL-divergence는 거리 개념(distance metric)이 아니라고 한다.</li>
      <li>하지만 거리 개념처럼 사용할 수 있는 방법이 존재하는데, 바로 Jesen-Shannon divergence이다.
        <ul>
          <li>$JSD(p\Vert q) = \frac{1}{2}KL(p\Vert M)+\frac{1}{2}KL(q\Vert M) \space where, M=\frac{1}{2}(p+q)$</li>
          <li>간편하게 쓸 수 있지만 KL-divergence 처럼 자주 쓰이지 않는다.</li>
        </ul>
      </li>
      <li>관련내용 : <a href="https://hyunw.kim/blog/2017/10/27/KL_divergence.html">링크</a></li>
    </ul>
  </li>
</ul>

<h2 id="베이즈-추정법">베이즈 추정법</h2>
<ul>
  <li>베이즈 정리는 조건부확률을 이용하여 정보를 갱신하는 방법
    <ul>
      <li>$P(\theta\vert D)=P(\theta)\frac{P(D\vert \theta)}{P(D)}$</li>
      <li>$D$는 새로 관찰하는 데이터, $\theta$는 모수
        <ul>
          <li>$P(\theta\vert D)$ : 사후확률(posterior)</li>
          <li>$P(\theta)$ : 사전확률(prior)</li>
          <li>$P(D\vert \theta)$ : 가능도(likelihood)</li>
          <li>$P(D)$ : Evidence, 어떠한 데이터들을 관찰하려고 할때 데이터 자체의 분포</li>
        </ul>
      </li>
      <li>가능도와 Evidence를 가지고 사전확률을 사후확률로 갱신할 수 있다.</li>
    </ul>
  </li>
</ul>

<h3 id="베이즈-정리의-확장1">베이즈 정리의 확장1</h3>
<ul>
  <li>만약, 사건 $A_1=A$와 $A_2=A^C$가 있다고 가정하자.(Binary 분류문제)</li>
  <li>$\begin{matrix}P(A\vert B) &amp;=&amp; \frac{P(B\vert A)P(A)}{P(B)} \\&amp;=&amp;\frac{P(B\vert A)P(A)}{P(B,A)+P(B,A^C)}\\ &amp;=&amp; \frac{P(B\vert A)P(A)}{P(B\vert A)P(A)+P(B\vert A^C)P(A^C)} \\ &amp;=&amp; \frac{P(B\vert A)P(A)}{P(B\vert A)P(A)+P(B\vert A^C)(1-P(A))}\end{matrix}$</li>
</ul>

<h3 id="베이즈-정리의-확장2">베이즈 정리의 확장2</h3>

<ul>
  <li>사건 A의 확률이 사건 B에 의해 갱신(Update)된 확률을 계산할 때, 이 상태에서 또 추가적인 사건 C가 
발생했다면 베이즈정리는 다음과 같이 쓸 수 있다.
    <ul>
      <li>$P(A\vert B,C) = \frac{P(C\vert A,B)P(A\vert B)}{P(C\vert B)}$</li>
      <li>$P(A\vert B,C)$는 $B$와 $C$가 조건인 $A$인 확률이고 $P(A\vert (B\cap C))$을 뜻한다.</li>
    </ul>
  </li>
  <li>관련내용 : <a href="https://datascienceschool.net/02%20mathematics/06.06%20%EB%B2%A0%EC%9D%B4%EC%A6%88%20%EC%A0%95%EB%A6%AC.html">링크</a></li>
</ul>

<h2 id="조건부확률--인과관계">조건부확률 → 인과관계?</h2>

<ul>
  <li>조건부확률은 인과관계(causality)를 추론할 때 함부로 사용해서는 안된다. 데이터가 많아도 인과관계를 추론하는 것은 불가능하다.</li>
  <li>또한, 중첩요인(confounding factor)의 효과를 제거하고 원인에 해당하는 변수만 인과관계를 계산해야 한다.
    <ul>
      <li>제거하지 않을 시 가짜 연관성(spurious correlation)이 나온다</li>
    </ul>
  </li>
</ul>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#statistics" class="page__taxonomy-item p-category" rel="tag">statistics</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#boostcamp" class="page__taxonomy-item p-category" rel="tag">BoostCamp</a>
    
    </span>
  </p>


        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2021-08-06T00:00:00+09:00">August 6, 2021</time></p>
        
      </footer>

      

      
  <nav class="pagination">
    
      <a href="/boostcamp/rnn/" class="pagination--pager" title="RNN 정리
">Previous</a>
    
    
      <a href="/boostcamp/cnn/" class="pagination--pager" title="CNN 정리
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You may also enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/pytorch/lstm-implementation/" rel="permalink">python으로 LSTM 구현하기
</a>
      
    </h2>
    


    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> June 02 2023</p>
    
    <p class="archive__item-excerpt" itemprop="description">Related

  RNN에 이어서 LSTM을 구현했습니다.

</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/nlp/byte-pair-encoding/" rel="permalink">Byte Pair Encoding
</a>
      
    </h2>
    


    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> February 19 2023</p>
    
    <p class="archive__item-excerpt" itemprop="description">Reference

  BPE 알고리즘에 대한 설명은 링크한 곳에 잘 설명되어 있습니다. 여기서는 참고한 곳의 내용을 바탕으로 직접 구현했습니다.

</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/pytorch/rnn-impl/" rel="permalink">python으로 RNN 구현하기
</a>
      
    </h2>
    


    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> December 28 2022</p>
    
    <p class="archive__item-excerpt" itemprop="description">Related

  이전 포스트에서 CNN을 구현했고 이번에는 RNN을 구현하는 과정을 정리하려고 합니다.

</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/data-engineer/data-pipeline/" rel="permalink">데이터 파이프라인 구축해보기
</a>
      
    </h2>
    


    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> December 02 2022</p>
    
    <p class="archive__item-excerpt" itemprop="description">Motivation

  빅데이터를 지탱하는 기술을 읽다가 데이터 엔지니어링에 사용되는 플랫폼들을 전체 파이프라인으로 구축해보고 싶어서
이 사이드 프로젝트를 진행하게 되었습니다.

</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2023 emeraldgoose. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




    <script>
  'use strict';

  (function() {
    var commentContainer = document.querySelector('#utterances-comments');

    if (!commentContainer) {
      return;
    }

    var script = document.createElement('script');
    script.setAttribute('src', 'https://utteranc.es/client.js');
    script.setAttribute('repo', 'emeraldgoose/emeraldgoose.github.io');
    script.setAttribute('issue-term', 'pathname');
    
    script.setAttribute('theme', 'github-light');
    script.setAttribute('crossorigin', 'anonymous');

    commentContainer.appendChild(script);
  })();
</script>

  




<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
  inlineMath: [['$','$']],
  displayMath: [['$$','$$']],
  processEscapes: true
  },
  "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>

  </body>
</html>
