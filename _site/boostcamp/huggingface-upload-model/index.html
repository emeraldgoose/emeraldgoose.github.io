<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="ko" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Huggingface에 사전학습한 모델 업로드하기 - gooooooooooose</title>
<meta name="title" content="Huggingface에 사전학습한 모델 업로드하기">
<meta name="description" content="이번 데이터셋 구축을 진행하면서 klue/bert-base처럼 pretraining한 모델을 업로드해보는 경험이 필요하다고 생각하게 되어 실행에 옮겼습니다.">


  <meta name="author" content="goooose">
  
  <meta property="article:author" content="goooose">
  


<!-- open-graph tags -->
<meta property="og:type" content="article">
<meta property="og:locale" content="ko_KR">
<meta property="og:site_name" content="gooooooooooose">
<meta property="og:title" content="Huggingface에 사전학습한 모델 업로드하기">
<meta property="og:url" content="http://localhost:4000/boostcamp/huggingface-upload-model/">


  <meta property="og:description" content="이번 데이터셋 구축을 진행하면서 klue/bert-base처럼 pretraining한 모델을 업로드해보는 경험이 필요하다고 생각하게 되어 실행에 옮겼습니다.">







  <meta property="article:published_time" content="2021-11-19T00:00:00+09:00">





  

  


<link rel="canonical" href="http://localhost:4000/boostcamp/huggingface-upload-model/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "emeraldgoose",
      "url": "http://localhost:4000/"
    
  }
</script>


  <meta name="google-site-verification" content="googleb34ce5276ba6573e" />





  <meta name="naver-site-verification" content="naver93cdc79a5629ab3736d7cf8ff7b51d80">


<!-- end _includes/seo.html -->




<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>

<!-- Lightbox2 -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.4/css/lightbox.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.4/js/lightbox-plus-jquery.js" integrity="sha512-oaWLach/xXzklmJDBjHkXngTCAkPch9YFqOSphnw590sy86CVEnAbcpw17QjkUGppGmVJojwqHmGO/7Xxx6HCw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.4/js/lightbox-plus-jquery.min.js" integrity="sha512-U9dKDqsXAE11UA9kZ0XKFyZ2gQCj+3AwZdBMni7yXSvWqLFEj8C1s7wRmWl9iyij8d5zb4wm56j4z/JVEwS77g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single wide">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about/">About</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/">Categories</a>
            </li><li class="masthead__menu-item">
              <a href="/tags/">Tags</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      


  
    



<nav class="breadcrumbs">
  <ol itemscope itemtype="https://schema.org/BreadcrumbList">
    
    
    
      
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/" itemprop="item"><span itemprop="name">Home</span></a>

          <meta itemprop="position" content="1" />
        </li>
        <span class="sep">/</span>
      
      
        
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/categories/#boostcamp" itemprop="item"><span itemprop="name">Boostcamp</span></a>
          <meta itemprop="position" content="2" />
        </li>
        <span class="sep">/</span>
      
    
      
      
        <li class="current">Huggingface에 사전학습한 모델 업로드하기</li>
      
    
  </ol>
</nav>

  


<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://localhost:4000/">
        <img src="/assets/images/bio-photo.png" alt="goooose" itemprop="image" class="u-photo" width="110px" height="110px">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">goooose</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>Interested in ML/DL, Data Engineering.</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">South Korea</span>
        </li>
      

      
        
          
            <li><a href="mailto:smk6221@naver.com" rel="nofollow noopener noreferrer me"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span></a></li>
          
        
          
            <li><a href="https://github.com/emeraldgoose" rel="nofollow noopener noreferrer me"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
        
          
            <li><a href="https://www.linkedin.com/in/minseong-kim-84428b231/" rel="nofollow noopener noreferrer me"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span class="label">LinkedIn</span></a></li>
          
        
          
            <li><a href="https://gooooooooooose.tistory.com/" rel="nofollow noopener noreferrer me"><i class="fas fa-fw fa-link" aria-hidden="true"></i><span class="label">Problem Solving OJ (KOR)</span></a></li>
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Huggingface에 사전학습한 모델 업로드하기">
    <meta itemprop="description" content="  이번 데이터셋 구축을 진행하면서 klue/bert-base처럼 pretraining한 모델을 업로드해보는 경험이 필요하다고 생각하게 되어 실행에 옮겼습니다.">
    <meta itemprop="datePublished" content="2021-11-19T00:00:00+09:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Huggingface에 사전학습한 모델 업로드하기
</h1>
          
<!--
            <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  0 minute read
</p>
            devinlife comments :
                싱글 페이지(포스트)에 제목 밑에 Updated 시간 표기
                기존에는 read_time이 표기. read_time -> date 변경
-->
            <p class="page__date"><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated: <time datetime="2021-11-19T00:00:00+09:00">November 19, 2021</time></p>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
        <blockquote>
  <p>이번 데이터셋 구축을 진행하면서 klue/bert-base처럼 pretraining한 모델을 업로드해보는 경험이 필요하다고 생각하게 되어 실행에 옮겼습니다.</p>
</blockquote>

<h2 id="사전학습-준비">사전학습 준비</h2>
<p>먼저, 확보한 데이터는 문장단위였습니다. bert는 MLM(Masked Language Model)과 NSP(Next Sentence Prediction) task를 수행하는데 문장 단위의 데이터로 NSP를 수행할 수 없었습니다.</p>

<p>그래서 bert의 MLM만을 이용하여 pretraining을 진행하였습니다.</p>

<h2 id="tokenizer-학습">tokenizer 학습</h2>
<p>bert 뿐만 아니라 tokenizer 또한 확보한 문장에 맞춰 학습을 해야합니다. tokenizer의 학습 결과로 <code class="language-plaintext highlighter-rouge">vocab.txt</code>을 저장할 수 있기 때문입니다.</p>

<p>Wordpiece와 Sentencepiece 두 가지가 있고 저는 Wordpiece를 이용하여 문장을 분리하고 vocab을 저장하려고 했습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">tokenizer_train</span><span class="p">():</span>
  <span class="c1"># load sentences
</span>  <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertWordPieceTokenizer</span><span class="p">(</span>
    <span class="n">vocab</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">clean_text</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">handle_chinese_chars</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">strip_accents</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">lowercase</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">wordpieces_prefix</span><span class="o">=</span><span class="s">"##"</span><span class="p">,</span>
  <span class="p">)</span>

  <span class="n">limit_alphabet</span> <span class="o">=</span> <span class="mi">1000</span>
  <span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">30000</span>

  <span class="n">tokenizer</span><span class="p">.</span><span class="n">train</span><span class="p">(</span>
    <span class="n">files</span><span class="o">=</span><span class="s">'./sentence.txt'</span><span class="p">,</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span>
    <span class="n">limit_alphabet</span><span class="o">=</span><span class="n">limit_alphabet</span><span class="p">,</span>
  <span class="p">)</span>

  <span class="n">tokenizer</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="s">"./tokenizer.json"</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>  <span class="c1"># save tokenizer.json, pretty=True로 두시면 json 형식이 보기좋게 저장됩니다
</span>  <span class="n">tokenizer</span><span class="p">.</span><span class="n">save_model</span><span class="p">(</span><span class="s">'./'</span><span class="p">)</span>  <span class="c1"># save vocab.txt
</span></code></pre></div></div>

<h2 id="bert-데이터-준비">Bert 데이터 준비</h2>
<p>bert의 MLM을 수행하기 위해 먼저 필요한 데이터를 확인합니다.</p>
<ul>
  <li>input_ids, token_type_ids, attention_mask, labels</li>
</ul>

<p>input_ids 토큰들 중 랜덤으로 마스킹하는데 labels은 마스킹된 토큰들만 들어가는 것이 아닌 원래 input_ids 토큰 리스트이어야 합니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">preprocessing</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
  <span class="s">""" preprocessing(random word convert to "[MASK]") """</span>

  <span class="n">mask</span> <span class="o">=</span> <span class="mi">4</span>  <span class="c1"># [MASK] 토큰번호
</span>  <span class="n">label</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">words</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s">'input_ids'</span><span class="p">]):</span>
    <span class="n">maxlen</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">)):</span> <span class="c1"># [PAD], [SEP]을 제외한 나머지 토큰들의 범위
</span>      <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">words</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">4</span><span class="p">):</span>
        <span class="n">maxlen</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">maxlen</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>

      <span class="n">masked_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span> <span class="c1"># 간단하게 전체 중의 15%의 토큰 중 80%의 토큰만 마스킹합니다
</span>        <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="nb">int</span><span class="p">((</span><span class="n">maxlen</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="mf">0.15</span><span class="o">*</span><span class="mf">0.8</span><span class="p">),),</span> <span class="n">low</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">maxlen</span><span class="p">)</span>
      <span class="n">tmp</span> <span class="o">=</span> <span class="n">words</span><span class="p">.</span><span class="n">clone</span><span class="p">().</span><span class="n">detach</span><span class="p">()</span> <span class="c1"># label은 원래의 input_ids를 복사한 것입니다
</span>      <span class="n">label</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span>

      <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">masked_idx</span><span class="p">:</span>
        <span class="n">words</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">mask</span>
      <span class="n">dataset</span><span class="p">[</span><span class="s">'input_ids'</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">words</span>

  <span class="k">return</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">label</span>
</code></pre></div></div>

<h2 id="모델-학습">모델 학습</h2>
<p>위에서 bert가 MLM만을 수행해야 하므로 transformer에서 <code class="language-plaintext highlighter-rouge">BertForMaskedLM</code>모델을 불러옵니다. 참고로 <code class="language-plaintext highlighter-rouge">BertForPretraining</code>모델은 MLM 데이터와 NSP 데이터 모두 필요하므로 현재 가지고 있는 데이터로는 사전학습을 할 수 없었습니다.</p>

<p>또한, <code class="language-plaintext highlighter-rouge">BertConfig을</code> 불러와서 원하는 설정을 한 후 <code class="language-plaintext highlighter-rouge">BertForMaskedLM</code>에 config설정을 해줍니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1"># training 준비
</span>  <span class="n">config</span> <span class="o">=</span> <span class="n">BertConfig</span><span class="p">(</span>
      <span class="p">...</span>
  <span class="p">)</span>

  <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s">'tokenizer path'</span><span class="p">)</span> <span class="c1"># 학습한 토크나이저가 저장된 경로로 지정해줍니다
</span>
  <span class="n">model</span> <span class="o">=</span> <span class="n">BertForMaskedLM</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
  <span class="n">model</span><span class="p">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">vocab_size</span><span class="p">)</span> <span class="c1"># 기본으로 설정된 vocab size를 우리가 만든 vocab size로 임베딩 크기를 맞춰야 합니다
</span>  <span class="n">model</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></div>

<p>여기서 vocab size가 맞지 않으면 CUDA 에러가 발생합니다.<br />
아래 에러들은 발생했던 에러들입니다. 아래 에러들의 공통점은 레이어의 사이즈가 맞지 않을 때 발생합니다.</p>
<ul>
  <li>CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling ‘cublasCreate(handle)’</li>
  <li>RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling ‘cublasSgemm( handle, opa, opb, m, n, k, &amp;alpha, a, lda, b, ldb, &amp;beta, c, ldc)’</li>
  <li>CUDA error: device-side assert triggered</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">training_args</code> 를 설정한 후 <code class="language-plaintext highlighter-rouge">Trainer</code>를 통해 모델을 학습하면 됩니다.<br />
<code class="language-plaintext highlighter-rouge">trainer.save_model(output_dir='')</code>를 통해 <code class="language-plaintext highlighter-rouge">pytorch_model.bin</code>을 포함하여 여러가지 파일들이 저장이 됩니다.</p>

<h2 id="허깅페이스-업로드">허깅페이스 업로드</h2>
<p>모델 학습이 완료되면 output_dir 경로에 학습된 결과물들이 저장되어있습니다.</p>

<p>이 모델들을 허깅페이스에 업로드하기 전에 허깅페이스 가입을 완료한 후 New Model을 통해 레포지토리를 생성하고 git clone 해옵니다.</p>

<p>아까 output_dir 위치에 있는 파일들을 clone된 디렉토리에 옮긴 후에 git lfs를 활성화 해야 합니다.</p>

<blockquote>
  <p>git lfs란? 기존 git 명령은 최대 10M을 초과하는 파일을 원격 레포지토리에 업로드 할 수 없습니다. git lfs를 통해 큰 파일을 옮길 수 있게됩니다.</p>
</blockquote>

<p>git lfs는 <code class="language-plaintext highlighter-rouge">sudo apt-get install git lfs</code>를 통해 git lfs를 설치하고 아까 clone한 디렉토리에 가서 <code class="language-plaintext highlighter-rouge">git lfs install</code> 명령어를 통해 해당 디렉토리가 git lfs를 사용할 수 있도록 합니다.</p>

<p>이후에는 <code class="language-plaintext highlighter-rouge">git add .</code>, <code class="language-plaintext highlighter-rouge">git commit -m "message"</code>, <code class="language-plaintext highlighter-rouge">git push</code> 순으로 명령어를 치시면 git lfs를 통해 레포지토리로 업로드를 시작합니다.</p>

<h3 id="tokenizer_configjson">tokenizer_config.json</h3>
<p><code class="language-plaintext highlighter-rouge">tokenizer_config.json</code>은 허깅페이스의 inference api를 이용하는데 필요한 파일입니다.</p>

<p>이 파일을 보면 never_split 이후에 여러가지 항목들이 있을 텐데 나머지를 날리고 허깅페이스로 업로드 하시면 inference api를 정상적으로 사용할 수 있게 됩니다.</p>

<p>또한, inference api의 example을 바꾸고 싶다면 READEME.md에 아래와 같은 글을 상단에 넣으시면 됩니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---
language: ko
mask_token: "[MASK]"
widget:
  - text: 산악 자전거 경기는 상대적으로 새로운 [MASK] 1990년대에 활성화 되었다.
---
</code></pre></div></div>


        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#huggingface" class="page__taxonomy-item p-category" rel="tag">huggingface</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#boostcamp" class="page__taxonomy-item p-category" rel="tag">BoostCamp</a>
    
    </span>
  </p>


        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2021-11-19T00:00:00+09:00">November 19, 2021</time></p>
        
      </footer>

      

      
  <nav class="pagination">
    
      <a href="/atcoder/abc227/" class="pagination--pager" title="KEYENCE Programming Contest 2021 (AtCoder Beginner Contest 227)
">Previous</a>
    
    
      <a href="/boostcamp/lightweight-model/" class="pagination--pager" title="모델 경량화 소개
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You May Also Enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/data-engineer/reranking-opensearch/" rel="permalink">Reranking - Opensearch
</a>
      
    </h2>
    


    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> February 17 2025</p>
    
    <p class="archive__item-excerpt" itemprop="description">Reranker
문서 검색 과정에서 문서를 임베딩 벡터로 변환하는 과정과 검색 시간 단축을 위해 Approximate Nearest Neighbor search(ANNs)와 같이 근사 기법으로 인해 정보 손실이 발생합니다. 
이로 인해 필요한 문서가 누락될 가능성이 있으며, 이를 ...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/github/code-review-action/" rel="permalink">Github Action 코드리뷰 봇 만들기(Gemini-1.5-flash)
</a>
      
    </h2>
    


    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> October 16 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">Github Action 설정
Github Action은 사용자가 원하는 트리거에 따라 워크플로우를 실행할 수 있는 CI(Continuous Integration) 도구입니다. 구글의 Gemini-1.5-flash 모델을 사용하여 Pull Request시 코드 변경사항에 대해 LL...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/data-engineer/kafka-pipeline/" rel="permalink">ksqlDB: 실시간 데이터 처리 후 시각화까지
</a>
      
    </h2>
    


    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> September 03 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">ksqlDB
ksqlDB는 Kafka Streams에 기반하는 SQL 엔진입니다. ksqlDB는 Kafka topic에 이벤트 스트리밍 애플리케이션을 구축할 수 있는 쿼리 계층을 제공합니다. Kafka Streams와 달리 ksqlDB는 SQL로 새로운 스트림을 생성하거나 Mate...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/pytorch/transformer-scratch-implementation-2/" rel="permalink">python으로 Transformer 바닥부터 구현하기[2] (Transformer)
</a>
      
    </h2>
    


    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> August 01 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">Objective
앞에서 구현한 LayerNorm, MultiHeadAttention, GELU를 사용하고 이전에 구현해둔 Linear, Dropout, Softmax 클래스를 사용하여 Transformer 클래스를 구현하여 테스트해봅니다.
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2025 emeraldgoose. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




    <script>
  'use strict';

  (function() {
    var commentContainer = document.querySelector('#utterances-comments');

    if (!commentContainer) {
      return;
    }

    var script = document.createElement('script');
    script.setAttribute('src', 'https://utteranc.es/client.js');
    script.setAttribute('repo', 'emeraldgoose/emeraldgoose.github.io');
    script.setAttribute('issue-term', 'pathname');
    
    script.setAttribute('theme', 'github-light');
    script.setAttribute('crossorigin', 'anonymous');

    commentContainer.appendChild(script);
  })();
</script>

  




<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
  inlineMath: [['$','$']],
  displayMath: [['$$','$$']],
  processEscapes: true
  },
  "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>

  </body>
</html>
