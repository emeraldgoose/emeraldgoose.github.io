---
title: 데이터 제작
categories:
  - BoostCamp
tags: [dataset]
---
## 데이터 제작의 중요성

### 인공지능 서비스 개발 과정과 데이터

- 서비스 기획 = 문제 정의
- 데이터 준비(수집, 정제) - 학습(train) 데이터
- 모델 학습 - 학습(train) 데이터
- 모델 검증 → 분석 → 다시 학습 - 검증(validation) 데이터, 개발(development) 데이터
- 모델 평가 - 평가(test) 데이터
- 배포

### 데이터 구축 과정

- 원시 데이터 선정 및 확보(저작권, 태스크 적합성)
    - 처음부터 만들지 말고 기존 데이터를 가지고 분석하는 것을 추천(너무 힘들다)
- 구축 및 가공 프로세스 확립(구축 및 검수 절차, 작업자 선정)
- 구축 및 가공 지침 작성(플랫폼 소통 및 작업자 교육)
- 데이터 구축 및 가공(파일럿, 작업자 관리)
    - 파일럿을 통해 테스트 후 프로세스 수정 혹은 지침 수정 등이 다시 이루어진다.
- 데이터 검수(품질 평가 기준, 데이터 규격, 내용)

### AI 데이터 설계의 구성 요소

- 데이터 설계
    - 데이터 자체를 설계
    - 데이터 형식, 데이터 표상 영역
- 데이터 수집-가공 설계
    - 원천 데이터 수집 방식: 전산화, 스크래핑, 작업자 작성, 모델 생성
    - 주석 작업: 전문가 구축, 크라우드 소싱

### 데이터 설계

- 데이터 유형
    - 소리, 텍스트, 이미지, 영상 → 2가지 이상의 데이터가 나오는 경우 멀티모달이라 한다.
- 데이터 In/Out 형식
    - HTML, XML, CSV, JSON,...
    - JPG, PDF, ...
    - wav, mp3, pcm, script, ...
- 데이터(train/dev(validation)/test)별 규모와 구분(split) 방식
    - 규모 선정에 필요한 정보 : 확보 가능한 원시 데이터의 규모, 주석 작업 시간
    - 구분 방식 : 데이터별 비율과 기준 정하기
    - 랜덤(모든 데이터가 균등하다고 판단되는 경우) vs. 특정 조건(불균형한 경우)
- 데이터의 주석(annotation) 유형
    - 주석 유형(Annotation Type) → 주요 활용 용도
        - 클래스 라벨(단일, 다중) → 텍스트 분류(Text Classification
        - 단어(구문) 라벨 → 명명된 개체명(Entity) 인식(Named Entity Recognition)
        - 텍스트 라벨 → 문장 번역, 문장 요약
        - 단어(구문) 라벨링 및 두 단어 사이의 관계 → 관계-의존성 정의(Relation-Dependencies)
        - 기타 → 그 밖의 용도

## 데이터 구축 과정과 설계 기초

### 원시 데이터 수집 방식

- 전산화(종이 형태로 있어서 타이핑이 필요한 경우), 스크래핑, 작업자 작성(대화작성), 모델 생성(generative model)
- 적합한 데이터란 무엇인지 기준 세우기

### 작업자 선정

주석 작업의 난이도와 구축 규모에 맞는 작업자 선정 및 작업 관리

- 전문가 : 데이터의 품질이 높아질 수 있으나 단가가 높고 작업할 수 있는 양이 적음
- 크라우드 소싱 : 단순하고 직관적인 작업, 단순한 가이드라인을 보고 작업을 할 수 있는 경우

### 구축 및 검수 설계

구축 작업의 난이도와 구축 규모, 태스크 특성에 맞는 구축 및 검수 방식(전문가, IAA) 설계

- 파일럿을 통해 구축 테스트 후 본 구축으로 넘어가는 방식을 사용
- 본 구축의 경우, 나눠서 할지 or 하나의 데이터를 한 사람이 볼지 혹은 여러 사람이 볼지 정해야 함
- 파일럿은 보통 1000개에서 2000개로 테스트하고 본 구축에서는 평균 10000개 이상의 데이터를 수집해야 함
    - 보통 본 구축의 10%를 파일럿을 통해 테스트
    - 100개정도의 샘플은 직접 해보는 것을 추천

### 데이터 구축 및 가공

- 파일럿
    - 설계 시 발견하지 못한 이슈 발굴 해결
    - 가이드라인 보완 및 개정
    - 작업자 선정
- 본 구축
    - 작업 일정 관리
    - 작업자 관리 : 작업자의 구축할 수 있는 데이터 양을 관리, 작업물의 퀄리티 관리
    - 중간 검수를 통한 데이터 품질 관리
        - 본 구축을 1차, 2차, 3차로 나누어 중간 검수를 진행한다.

### 데이터 검수 및 분석

평가 지표 설정

- 전문가 평가 및 분석
    - 샘플링 검사
    - 가이드라인 적합도 분석
    - 여기서의 전문가 = 프로젝트 설계한 사람, 의뢰 에이전시의 PM, 숙련된 작업자
- 자동 평가 및 분석(기계적 검수)
    - 데이터 형식
    - 레이블 별 분포 파악
    - 일괄 수정 사항 반영

## 자연어 처리 데이터

### 자연어 vs. 인공어

- 자연어(Natural Language)
    - 일상적으로 사용하고 있는 언어 그 자체
    - 한국어, 영어, 일본어, ...
- 인공어(Artificial Language)
    - 여러 사람의 목적이나 의도에 따라 만든 언어
    - 에스페란토어, 파이썬, C언어, ...

### 자연어처리(NLP, Natural Language Processing)

> 인공지능의 한 분야, 사람의 언어를 컴퓨터가 알아듣도록 처리하는 인터페이스 역할. 자연어 이해(NLU, Natural Language Understanding)와 자연어 생성(NLG, Natural Language Generation)으로 구성
> 

- 자연어 처리의 최종 목표:
    - 컴퓨터가 사람의 언어를 이해하고 여러 가지 문제를 수행할 수 있도록 하는 것

### 데이터 분류 방식

- 원천 데이터 장르(도메인) : 문어(뉴스, 도서 등), 구어(대화 등), 웹(메신저 대화, 게시판 등)
- 과제의 유형:
    - 자연어 이해(형태 분석, 구문 분석, 문장 유사도 평가 등)
    - 자연어 생성(기계 번역, 추상 요약 등)
    - 혼합(챗봇 등)
- 자연어처리 데이터를 만들 때는 복잡한 과제도 단순화하여 단계별로 구축