---
title: AutoML 이론
categories:
  - BoostCamp
tags: [AutoML]
---
## Overview

### Conventional DL Training Pipeline

- Data Engineering
    - 일반적으로 Data Engineering은 Data Cleansing, Preprocessing, Feature Engineering, Select ML Algorihm, Set Hyperparameters 등의 일련을 거친다.
    - Model Architecture와 Hyperparamter를 선택한 후 Train & Evaluate를 진행하는데 성능이 잘 나오면 Hyperparameter tuning을 진행하고 성능이 나오지 않으면 다른 모델을 선택해서 반복한다.
    - 가장 큰 문제는 위의 과정을 사람이 한다.
    - AutoML은 이 반복적인 과정에서 사람을 빼내는 것이 목표이다.

### AutoML(HPO: Hyperparameter Optimization)의 문제 정의

- $\lambda^{*} \in \text{arg}\_{\lambda \in \Lambda}\min{L(A\_{\lambda}, D\_{train}, D\_{valid})}$
- $\lambda$는 도메인 $\Lambda$에서의 ML 알고리즘 $A$이다.
- $L()$는 하이퍼파라미터 $\lambda$를 사용한 $A$의 로스를 정의한 것이다.
- HPO는 이 로스를 줄이는 하이퍼파라미터 $\lambda^{*}$를 찾는 문제를 말한다.

### DL model Configuration(Architecture, Hyperparameter)의 특징

- 주요 타입 구분
    - Categorical : optimizer(Adam, SGD, ...), module(Conv, Bottleneck, ...)
    - Continuous : learning rate, regularizer param
    - Integer : batch_size, epochs
- Conditional : configuration에 따라 search space가 달라질 수 있음
    - Optimizer의 sampling에 따라서 optimizer parameter의 종류, search space도 달라짐
    - Module의 sample에 따라서 해당 module의 parameter의 종류, search space도 달라짐

### 주어진 모델을 경량화하자 vs. 새로운 경량 모델을 찾자

- 기존 가지고 있는 모델을 경량화 하는 기법 : Pruning, Tensor decomposition
- search를 통해서 경량 모델을 찾는 기법 : NAS(Neural Architecture Search), AutoML(Automated Machine Learning)

## Basic concept

### 일반적인 AutoML Pipeline

- Configuration $\lambda$(Backbone, Hyperparameters)
- Train with $\lambda$(Black box)
- Evaluate Objective $f(\lambda)$(Accuracy, Speed, Size, ...)
- Blackbox Optimization $arg\_\lambda \max{f(\lambda)}$

### Bayesian Optimization(with Gaussian Process Regression)

- Evaluate까지는 일반적인 AutoML pipeline과 같다.
- Update Surrogate Function($f(\lambda)$의 regression model)
- Update Accquisition Function → 다음 configuration을 찾는다.
- Gaussian Process Regression 간단 설명
    - train data $(X, Y)$가 있고 우리는 $Y \approx f(X) + e$ 처럼 $Y$를 잘 설명할 수 있는 함수 $f$를 찾는 것이 목적이다.
    - test data $(X\_\*, Y\_\*)$ 가 있을 때 우리는 $Y\_* $ 를 제외한 나머지를 알고 있다. 우리는 $Y\_\*$ 는 $X, Y, X\_\*$ 와 연관이 있을 것이라는 가정을 통해  $X, Y, X\_\*$ 로 $Y\_\*$ 를 추정해야 한다. 연관에 대한 표현은 Kernel 함수 $K$ 로 한다.
    - $f(x)$를 입력 $x$에서의 가능한 함수의 분포(Random variable)로 생각한다. 그리고 각 Random variable들이 Multivariate Gaussian distribution 관계에 있다고 가정한다.
        - 함수들의 분포가 Multivariate Gaussian distribution을 따른다고 가정
    - 함수 f가 Gaussian process를 따른다.
        
        ![](https://drive.google.com/uc?export=view&id=1q_m0cq4i2DWgudWytKe-SCxcabLP9Bmf)
        
    - Gaussian Identities(Gaussian의 marginal, conditional도 Gaussian)
        
        ![](https://drive.google.com/uc?export=view&id=1Fk6MHQKINe0fMxa8-eMrBPk4ZRcxe5YG)
        
- Surrogate Model(Function): f($\lambda$)의 Regression model
    - Objective $f(\lambda)$ 값을 예측하는 모델(지금까지 관측된 $f(\lambda)$들이 있을 때, 새로운 $\lambda^*$에 대한 objective $f(\lambda^\*)$는 얼마일까?)
    - Objective를 estimate하는 surrogate model을 학습, 다음 좋은 $\lambda$를 선택하는 기준으로 사용
    - 대표적인 Surrogate model로는 Gaussian Processing Regression(GPR) Model(Mean: 예측 f값, Var: uncertainty)
- Acquisition Function: 다음은 어디를 trial하면 좋을까?
    - Surrogate model의 output으로부터, 다음 시도해보면 좋을 $\lambda$를 계산하는 함수
    - Exploration vs. Exploitation("불확실한 지점 vs. 알고있는 가장 좋은 곳"의 trade off)
    - Acquisition function의 max지점을 다음 iteration에서 trial
        - 가장 좋은 위치에서 가장 큰 불확실성을 가진 곳을 탐색
        - Upper Confidence Bound(UCB) Aquisition function
        - $\alpha_t = \mu_{t-1} + \kappa\sigma_{t-1}$
        - $\mu$ : posterior mean(Exploitation), $\sigma$ : posterior variance(Exploration), $\kappa$ : hyperparameter(balance)

### Tree-structed Parzen Estimator(TPE)

- GP의 약점 :
    - High-dim($O(N^3)$)
    - Conditional, continuous/discrete한 파라미터들의 혼재시 적용이 어려움 → 다른 테크닉이 필요
- TPE : GPR($p(f\|\lambda)$)과 다르게 $p(\lambda\|f)$와 $p(\lambda)$를 계산
- TPE를 통한 다음 step의 $\lambda$ 계산 방법
    - 현재까지 observation들을 특정 quantile(inverse CDF)로 구분 (예를들면 전체 중 75% bad, 25% good)
    - KDE(Kernel density estimation)으로 good observations 분포(p(g)), bad observations의 분포(p(b))를 각각 추정
    - p(g)/p(b)은 EI(Expected Improvement, aquisition function 중 하나)에 비례하므로 높은 값을 가지는 $\lambda$를 다음 step으로 설정

## Further Studies

- 가장 큰 문제는 대부분의 task에 대해서, 한 iteration에도 많은 시간이 걸림
- DL에서의 AutoML은 scalability 이슈가 더욱 대두됨
- 주요 키워드
    - Hyperparameter Gradient Descent
    - Meta-learning(Auto 'AutoML')
    - Multi-fidelity optimization : Data의 subset만을 활용, 작은 epoch, RL을 활용한 적은 trial, Image Downsampling 등등