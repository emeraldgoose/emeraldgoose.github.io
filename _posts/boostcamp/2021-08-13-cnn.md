---
title: CNN 정리
categories:
  - BoostCamp
tags: [cnn]
---
## Convolution
- Continuous convolution
    - $(f * g)(t) = \int f(\tau)g(t-\tau)d\tau = \int f(t-\tau)g(t)d\tau$
- Discrete convolution
    - $(f * g)(t) = \sum_{i=-\infty}^{\infty} f(\tau)g(t-\tau)d\tau = \sum_{i=-\infty}^{\infty} f(t-\tau)g(t)d\tau$
- 2D image convolution
    - $(I * K)(i,j) = \sum_m \sum_n I(m,n)K(i-m,j-n) = \sum_m \sum_n I(i-m,i-n)K(m,n)$
    
- filter 값과 이미지의 값을 컨볼루션 연산한 값을 출력한다.
- 2D 컨볼루션 연산으로 Blur, Emboss, Outline 등의 결과를 얻을 수 있다.

## RGB Image Convolution
- 이미지에 여러가지의 필터를 적용하게 되면 feature의 개수는 필터의 개수가 된다.

## Stack of Convolultion
- (32,32,3) 이미지에 4개의 (5,5,3) 필터를 적용하여 (28,28,4)의 결과를 얻을 수 있다.
- 다시 10개의 (5,5,4) 필터를 적용하여 (24,24,10)의 결과를 얻을 수 있다.

## Convolutional Neural Networks
- 일반적인 CNN은 Convolution layer, pooling layer, fully connected layer로 구성된다.
    - convolution layer는 컨볼루션 연산을 계산하는 레이어이다.
    - convolution layer와 pooling layer는 feature의 정보를 추출하는 역할을 한다.
    - fully connected layer는 마지막에 회귀를 하거나 분류를 하여 결과를 만드는 역할을 한다.
- fully connected layer가 최근은 사라지는 추세이다. 모델을 딥하게 가져가면서 파라미터 숫자를 줄이는 방법으로 연구되고 있다.
- Convolution layer는 각 필터당 하나의 feature map이 형성되고, 그 feature map을 스택처럼 쌓아둔 것이다
- 많은 수의 필터를 사용하게 되면 그 만큼 많은 양의 feature map을 사용하게 되고 더 많은 수의 파라미터들을 필요로하게 된다. -> 오버피팅 가능성 증가
- 차원을 줄일 필요가 있고 그 역할을 하는 것이 Pooling layer이다.
- Pooling layer에는 두 가지 타입이 있는데
    - Max pooling layer : 각 feature map을 입력으로 받고 window 안에 포함된 픽셀들 중 최댓값을 뽑는 레이어이다.
    - Global average pooling layer : 각 feature map 상의 노드값들의 평균을 뽑아주는 레이어이다. 이때 global average pooling layer의 최종 output은 single value로 크기가 감소된 feature map이 된다. 이런 방식으로 이 레이어는 3D array를 input으로 하여 벡터를 리턴한다.

## Stride
- stride = 1 : 한 픽셀 옮겨서 계산하는 방법 (인풋 7, 필터 3이라면 아웃풋이 5가 나온다)
- stirde = 2 : 두 픽셀 옮겨서 계산하는 방법(인풋 7, 필터 3이라면 아웃풋이 3이 나온다)

## Padding
- 패딩을 넣어 가장자리도 conv연산을 할 수 있게 한다.

## Convolution Arithmetic
- 모델의 파라미터 수 계산을 할 줄 알아야 한다.
- (W 40,H 50,C 128)에 (3,3)커널을 적용하고 패딩 1, 스트라이드 1을 주었을 때 아웃풋이 (40,50,64)일 때 파라미터 수?
    - 3 x 3 x 128 x 64 = 73728
    
### Exercise
- AlexNet의 파라미터 수?
- 첫 번째
    - 정보
        - 인풋 (224,224,3)
        - 필터 크기 (11,11) -> 커널의 채널은 3
        - stride 4
        - 아웃풋 (55,55,28)이 2개가 있다.
    - 따라서 파라미터 수는 11 x 11 x 3 x 48 x 2 = 35K
- 두 번째
    - 정보
        - 필터 크기 (5,5)
        - 아웃풋 (27,27,128)이 2개가 있다.
    - 따라서 파라미터 수는 5 x 5 x 48 x 128 x 2 = 307K
- 세 번재
    - 정보
        - 필터 크기 (3,3)
        - 아웃풋 (13,13,192)이 2개가 있다.
        - 인풋에 필터를 통과한 결과가 현재 아웃풋 2개에 모두 계산된다.
    - 따라서 파라미터 수는 3 x 3 x 128 x 2 x 192 x 2 = 884K
- 네 번째
    - 정보
        - 필터 크기 (3,3)
        - 아웃풋 (13,13,192)
        - 인풋에 필터를 통과한 결과가 하나의 아웃풋에 계산된다.
    - 따라서 파라미터 수는 3 x 3 x 192 x 192 x 2 = 663K
- 다섯 번째
    - 정보
        - 필터 크기 (3,3)
        - 아웃풋 (13,13,128)
        - 인풋 결과가 하나의 아웃풋에 계산
    - 따라서 파라미터 수는 3 x 3 x 192 x 128 x 2 = 442K
- Dense layer
    - 이 레이어에서의 파라미터 수는 인풋의 개수와 아웃풋의 개수의 곱이다.
    - 13 x 13 x 128 x 2 x 2048 x 2 = 177M
    - 2048 x 2 x 2048 x 2 = 16M
    - 2048 x 2 x 1000 = 4M

## Modern Convolutional Neural Networks

### 1x1 Convolution
- Dimension reduction이 목표이다.
- 채널를 줄임으로써 파라미터의 수를 줄이는 방법
     - 인풋의 크기가 256x256x128일때 커널의 크기가 1x1x32로 가져가면서 아웃풋의 크기가 256x256x32가 되도록 한다.
     - 이때 파라미터 수는 1x1x128x32가 되면서 파라미터 수가 줄어든다.
- bottleneck architecture

### ILSVRC
- ImageNet Large-Scale Visual Recognition Challenge
- 1000개의 다른 카테고리
- classsfification, Dection, Localization, Segmentation
- 2015년 이후 사람보다 에러가 좋아졌다

### AlexNet
- 두 개로 나눠진 이유는 GPU의 메모리가 모자라기 때문
- ReLU activation 사용
- Local response normalizatoin, Overlapping pooling
- data augmentation
- dropout
- ReLU Activation
    - 선형모델의 좋은 성질들을 가지고 있다.
    - gradient descent로 학습하기 쉽다
    - 좋은 generalization
    - vanishing gradient problem을 해결해준다.

### Vanishing gradient problem
- 학습을 진행할 수록 기울기가 소실되는 문제
- 히든 레이어가 많은 MLP에서 레이어를 거쳐가면서 갈수록 전달되는 오차가 크게 줄어들어 더 이상 학습되지 않는 현상이 일어나는데 이를 기울기 소실 문제라 한다.
- 기울기가 0으로 소실되어 버리면 네트워크의 학습은 매우 느려지고 학습이 다 이루어지지 않은 상태에서 학습이 멈춰버린다. 이를 지역 최솟값에 도달한다고 표현한다.
    - sigmoid 함수의 경우 출력값이 1아래여서 기울기 소멸 문제가 빠르게 일어난다. 매우 작은 수 끼리 계속 곱하면서 연산하게 되면 0에 가까워지는 것을 생각하면 된다.
- 이를 해결하기 위해 사라져가는 성질을 갖지 않은 비선형 함수를 활성화함수로 선택하면 해결할 수 있다.
    - ReLU
    
### VGGNet
- 3x3 컨볼루션 필터만 사용 <- 중요
    - 3x3 필터 두번이면 5x5하나 사용하는 것과 같아진다. 그러나 파라미터의 수는 3x3이 적다
- fully connected layers에 1x1 컨볼루션을 사용

### GoogLeNet
- 비슷하게 보이는 레이어가 반복 (network-in-network, NiN 구조)
- 3x3, 5x5 conv 연산하기 전에 1x1 conv을 추가해서 파라미터 수를 줄인다
- 1x1 convoultion은 채널 방향으로 dimension을 줄이는 효과가 있다.
    - 하지만 1x1 conv는 필터의 효과가 없지만 파라미터 수를 줄이는 데 효과가 크다

#### Inception Block
- 1x1 컨볼루션을 사용하여 약 30%의 파라미터 수를 줄일 수 있다.
    - input_C=128, 3x3 filter -> output_C=128 => 3x3x128x128 = 147456
    - input_C=128, 1x1 filter -> output_C=32, 3x3 filter -> output_C=128
        => 1x1x128x32 + 3x3x32x128 = 40960

### Quiz
- AlexNet(8-layer) : 60M
- VGGNet(19-layer) : 110M
- GoogLeNet(22-layer) : 4M
- -> GoogLeNet이 AlexNet보다 3배는 깊어졌지만 파라미터 수가 많이 줄었다.

### ResNet
- 뉴럴 네트워크를 깊게 내려갈 수록 학습하기 어려워진다.
    - 파라미터 수가 많아질 수록 오버피팅의 가능성이 커진다.
    - 오버피팅이 아니어도 train 에러가 더 작은데도 불구하고 saturated 된 test 에러가 더 커진다.
- 그래서 ResNet은 identity map을 추가한다.
    - 입력을 layer의 출력에 바로 연결시키는 skip connection을 사용한다
    - 입력을 x라 하고 중간 레이어 출력을 F(x), 마지막 출력을 H(x)라 할 때 skip connection을 통해 H(x)=F(x)+x로 변경된다
        - F(x) = H(x) - x, F(x)를 학습한다는 것은 H(x)와 x의 차이을 학습한다는 것이다
        - H(x) - x인 잔차(residual)(=차이,나머지)를 학습하는 레이어이다. 그래서 이름이 ResNet이 되었다
    - 이런 방식을 통해 기존 모델들은 H(x)를 얻기 위한 학습을 한 반면에 ResNet은 F(x)가 0이 되는 방향으로 학습한다
    - 또한, x와 F(x)의 dimension의 차이가 있다면 dimension을 맞추기 위한 파라미터 w를 추가해서 학습한다
    
    
- 특이한 점은 batch norm이 컨볼루션 이후에 이루어진다.
- bottleneck 아키텍쳐

### DenseNet
- 채널의 concatenation을 진행
- 채널이 많아지면서 커널의 채널도 같이 증가하면서 파라미터 수가 증가한다.
- 채널이 많아지는 것을 막기 위해 중간에 채널을 중간에 줄여준다.
    - 채널을 줄이기 위해 1x1 conv를 추가
- 두 가지 block을 통해 연산
    - Dense block : 채널의 concatenate
    - Transitoin block : 채널의 수를 줄이는 block
    - Dense block으로 채널을 늘리고 Transition block으로 채널을 줄인다.
    
### Summary
- key takeways
    - VGG : repeated 3x3 blocks
    - GoogLeNet : 1x1 convolution
    - ResNet : skip-connection
    - DenseNet : concatenation

## Computer Vision Applications

### Semantic Segmentation
- 어떤 이미지가 있을 때 픽셀 하나하나 분리하는 것
- 모든 픽셀단위로 어떤 분류에 속하는지 찾고 싶은 것
- 자율주행에 사용

### Fully Convolutional Network(FCN)
- dense layer의 경우 conv 연산 후에 flat을 하고 dense과정을 거친다
- FCN는 conv 연산 후에 다시 conv 연산을 거친다.
- 둘의 방식 모두 파라미터 수의 변화는 없다.
- dense layer를 FCN로 바꾸는 것을 Convolutionalization이라 한다.
- FCN의 가장 큰 특징은 input dimension에 독립적인 것이다.
    - FCN는 이미지가 커지던 작아지던 상관없이 network가 돌아간다.
    - 동작의 결과는 heatmap과 같다. 찾고자 하는 object의 위치가 heatmap으로 출력된다.
    - FCN은 인풋의 어떤 사이즈에도 돌아가지만 아웃풋 dimension도 줄어들게 된다. 그래서 coarse output(spatial resolution이 떨어져있는)을 원래의 dense pixels로 바꾸는 과정이 필요하다
    
### Deconvolution(conv transpose)
- 컨볼루션의 역연산이라고 하지만 컨볼루션을 역연산할 수는 없다.
- 패딩을 많이 줘서 계산
- ?

### Detection
#### R-CNN
- 이미지 안에서 2000개의 region을 뽑고 CNN을 통해 계산
- 정확하지는 않음
- 이미지 안에서 2000개의 이미지(patch)를 모두 CNN에 넣는다 -> 오래걸림

#### SPPNet
- CNN을 한 번만 돌리는 방법
- 이미지 전체에서 Convolutional feature map을 만든 후에 뽑힌 bounding box에 해당하는 convolutional feature map의 tensor만 가져오는 방법
- 컨볼루션 내용은 한 번 돌지만 feature map의 subtensor만 뜯어오는 것을 region별로 하기 때문에 R-CNN보다 빠르다
- 그러나 feature map을 만들기 위해 여러개의 subtensor의 벡터를 만들어야 하므로 느리다

### Fast R-CNN
- SPPNet의 컨셉과 비슷하다
- RoI feature map이라는 것을 통해 bounding box regression과 classification을 한다

### Faster R-CNN
- Faster R-CNN = Region Proposal Network + Fast R-CNN
- 바운딩 박스를 뽑는 것도 네트워크로 학습하자라는 아이디어

#### Region Proposal Network
- 바운딩 박스 안에 물체가 있는지 없는지 판단하는 것. 물체의 종류는 뒷단의 네트워크가 처리
- anchor box는 미리 정해놓은 박스의 크기
- region sizes (128,256,512)와 비율(1:1,1:2,2:1)을 정해서 총 9개의 박스 중 하나를 선택
- 4개의 바운딩 박스 파라미터를 통해 바운딩 박스를 얼마나 키우고 줄일지 결정
- 해당 바운딩 박스가 쓸모있는지 분류한다

### YOLO
- Faster R-CNN보다 매우 빠르게 동작한다.
- 이미지 한장에서 아웃풋이 바로 나온다. 바운딩 박스를 뽑는 작업이 없다.
- 이미지가 들어오면 S x S 그리드로 나눈다. 각각의 그리드 셀은 B개의 바운딩 박스를 예측하게 된다.
    - 각각의 바운딩 박스는 x,y,w,h와 confidence score값을 예측하게된다.
    - confidence score는 물체가 있을 확률과 물체와 실제 물체의 바운딩 박스와 예측된 바운딩 박스가 얼마나 겹치는지에 대한 점수)
- 

