---
title: MLOps 정리
categories:
  - BoostCamp
tags: [MLOps]
---
## 모델 개발 프로세스

### Research

- 문제정의 → EDA → Feature Engineering → Train → Predict
- 위 프로세스는 보통 자신의 컴퓨터, 서버 인스턴스 등에서 실행하고 **고정(Static)된 데이터**를 사용해 학습한다.
- 학습된 모델을 앱, 웹 서비스에서 사용할 수 있도록 만드는 과정이 필요하다.
    - 이런 경우 **Real World, Production 환경에 모델을 배포**한다고 표현한다.

### Production

- 웹, 앱 서비스에서 활용할 수 있게 만드는 과정 = "**모델에게 데이터(input)을 제공하면서, (Output) 예측해주세요**"라고 **요청**
- 모델을 배포했을 때, 모델의 **결과값이 이상한 경우**가 존재한다.
    - 원인 파악 필요
    - Input 데이터가 이상한 경우가 존재
    - Research 할 땐 Outlier로 제외할 수 있지만, 실제 서비스에선 제외가 힘든 상황일 수 있다(또는 별도 처리가 필요)
- **모델의 성능이 계속 변경**
    - 모델의 성능은 어떻게 확인할 수 있는가?
    - 예측값과 실제 레이블을 알아야 함
    - 정형(Tabular) 데이터에서는 정확히 알 수 있지만, 비정형 데이터(이미지 등)는 잘 모를 수 있음
- **새로운 모델이 더 안 좋다면?**
    - 과거의 모델을 다시 사용해야 하는지 고민해야 함
    - Research 환경에선 성능이 더 좋았던 모델이 Production 환경에선 더 좋지 않을 수 있음
    - 이전 모델을 다시 사용하기 위한 작업이 필요
- 그 외에도 다양한 이슈가 존재

## MLOps란?

> MLOps = ML(Machine Learning) + Ops(Operations)  
머신러닝 모델을 운용하면서 **반복적으로 필요한 업무를 자동화**시키는 과정
> 

- 머신러닝 엔지니어링 + 데이터 엔지니어링 + 클라우드 + 인프라
- **머신런이 모델 개발(ML Dev)과 머신러닝 모델 운영(Ops)에서 사용되는 문제, 반복을 최소화하고 비즈니스 가치를 창출하는 것이 목표**
- 모델링에 집중할 수 있도록 관련된 인프라를 만들고, 자동으로 운영되도록 만드는 일
- 최근엔 비즈니스 문제에 머신러닝/딥러닝을 적용하는 케이스가 많아짐
- Production 환경에 배포하는 과정엔 **Research의 모델이 재현 가능해야 하며** 현실의 Risk 환경에서 잘 버틸 수 있어야 함
- **MLOps의 목표는 빠른 시간 내에 가장 적은 위험을 부담하며 아이디어 단계부터 Production 단계까지 ML프로젝트를 진행할 수 있도록 기술적 마찰을 줄이는 것**

### Research와 Production의 차이

- Research ML에서는 모델 성능이 중요지만 Production ML에서는 모델성능, 빠른 Inference 속도, 해석 가능함이 중요하다.
- Research에서는 더 좋은 모델을 발견하는 것이 도전과제이지만 Production에서는 안정적인 운영, 전체 시스템 구조가 도전과제이다.

### MLOps 학습 방법

- MLOps의 각 **Component에서 해결하고 싶은 문제는 무엇**이고, **그 문제를 해결하기 위한 방법으로 어떤 방식을 활용할 수 있는지**를 학습하자.

## MLOps Component

### Infra

- 고려해야할 점
    - 예상되는 트래픽이 얼마나 되는가?
    - 서버의 자원을 어느정도 할당 받을 것인가?
    - 스케일 업, 스케일 아웃이 가능한가?
    - 자체 서버 구축 or 클라우드?
- 클라우드 : AWS, GCP, Azure, NCP 등
- 온 프레미스 : 회사나 대학원의 전산실에 서버를 직접 설치

### Serving

- 정기배송처럼 **일정 주기**로 서빙하는 경우를 **Batch Serving**이라 한다
- **Online Serving**은 **실시간**으로 예측해서 서빙하는 경우를 말하고 동시에 많은 트래픽이 몰려도 **병목이 없어야** 하고, **확장 가능**하도록 구현해야 한다.

### Experiment, Model Management

- 실험시 사용한 하이퍼파라미터나 모델 정보 등을 기록할 수 있는 도구가 필요하다.
- 공통의 포맷상에서 코드로 작성하도록 하여 기록의 누락을 방지한다.
- 대표적으로 MLFlow가 있다.

### Feature Store

- 데이터를 가공하여 저장한 곳
- 데이터 전처리를 할 때 시간을 줄일 수 있다.
- 또한, Research나 Production 모두 사용가능한 곳에 저장되므로 균일한 데이터를 사용할 수 있다.
- 대표적으로 FEAST 라이브러리가 있다.

### Data Validation

- 이전에 사용한 데이터와 Feature의 분포를 비교할 수 있다.
- Data Drift, Model Drift, Concep Drift
- TFDV라는 도구나 AWS Deequ라는 도구가 있다.

### Continuous Training

- 새로운 데이터가 들어왔거나 일정 시간 혹은 Metric 기반으로 성능이 떨어졌음을 인지하게 되면 다시 학습한다.

### Monitoring

- 모델의 지표, 인프라의 성능 지표 등을 기록하여 모니터링을 한다.

### AutoML

- 모델 구조를 자동으로 만드는 기능
- NNI가 있다.

### 정리

MLOps는 회사의 비즈니스 상황과 모델 운영 상황에 따라 우선 순위가 달라진다.  

**앞선 모든 요소가 항상 존재해야 하는 것은 아니다.**

MLOps를 처음부터 진행하는 것이 오히려 비효율적일 수 있다.

처음엔 작은 단위의 MVP(Minimal Value Product)로 시작해서 점점 운영 리소스가 많이 소요될 때 하나씩 구축하는 방식을 활용