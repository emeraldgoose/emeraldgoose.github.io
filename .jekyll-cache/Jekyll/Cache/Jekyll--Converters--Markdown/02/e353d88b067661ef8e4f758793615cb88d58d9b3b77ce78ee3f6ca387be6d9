I"³2<blockquote>
  <p>ì´ë²ˆ ë°ì´í„°ì…‹ êµ¬ì¶•ì„ ì§„í–‰í•˜ë©´ì„œ klue/bert-baseì²˜ëŸ¼ pretrainingí•œ ëª¨ë¸ì„ ì—…ë¡œë“œí•´ë³´ëŠ” ê²½í—˜ì´ í•„ìš”í•˜ë‹¤ê³  ìƒê°í•˜ê²Œ ë˜ì–´ ì‹¤í–‰ì— ì˜®ê²¼ìŠµë‹ˆë‹¤.</p>
</blockquote>

<h2 id="ì‚¬ì „í•™ìŠµ-ì¤€ë¹„">ì‚¬ì „í•™ìŠµ ì¤€ë¹„</h2>
<p>ë¨¼ì €, í™•ë³´í•œ ë°ì´í„°ëŠ” ë¬¸ì¥ë‹¨ìœ„ì˜€ìŠµë‹ˆë‹¤. bertëŠ” MLM(Masked Language Model)ê³¼ NSP(Next Sentence Prediction) taskë¥¼ ìˆ˜í–‰í•˜ëŠ”ë° ë¬¸ì¥ ë‹¨ìœ„ì˜ ë°ì´í„°ë¡œ NSPë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.</p>

<p>ê·¸ë˜ì„œ bertì˜ MLMë§Œì„ ì´ìš©í•˜ì—¬ pretrainingì„ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.</p>

<h2 id="tokenizer-í•™ìŠµ">tokenizer í•™ìŠµ</h2>
<p>bert ë¿ë§Œ ì•„ë‹ˆë¼ tokenizer ë˜í•œ í™•ë³´í•œ ë¬¸ì¥ì— ë§ì¶° í•™ìŠµì„ í•´ì•¼í•©ë‹ˆë‹¤. tokenizerì˜ í•™ìŠµ ê²°ê³¼ë¡œ <code class="language-plaintext highlighter-rouge">vocab.txt</code>ì„ ì €ì¥í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.</p>

<p>Wordpieceì™€ Sentencepiece ë‘ ê°€ì§€ê°€ ìˆê³  ì €ëŠ” Wordpieceë¥¼ ì´ìš©í•˜ì—¬ ë¬¸ì¥ì„ ë¶„ë¦¬í•˜ê³  vocabì„ ì €ì¥í•˜ë ¤ê³  í–ˆìŠµë‹ˆë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">tokenizer_train</span><span class="p">():</span>
  <span class="c1"># load sentences
</span>  <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertWordPieceTokenizer</span><span class="p">(</span>
    <span class="n">vocab</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">clean_text</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">handle_chinese_chars</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">strip_accents</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">lowercase</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">wordpieces_prefix</span><span class="o">=</span><span class="s">"##"</span><span class="p">,</span>
  <span class="p">)</span>

  <span class="n">limit_alphabet</span> <span class="o">=</span> <span class="mi">1000</span>
  <span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">30000</span>

  <span class="n">tokenizer</span><span class="p">.</span><span class="n">train</span><span class="p">(</span>
    <span class="n">files</span><span class="o">=</span><span class="s">'./sentence.txt'</span><span class="p">,</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span>
    <span class="n">limit_alphabet</span><span class="o">=</span><span class="n">limit_alphabet</span><span class="p">,</span>
  <span class="p">)</span>

  <span class="n">tokenizer</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="s">"./tokenizer.json"</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>  <span class="c1"># save tokenizer.json, pretty=Trueë¡œ ë‘ì‹œë©´ json í˜•ì‹ì´ ë³´ê¸°ì¢‹ê²Œ ì €ì¥ë©ë‹ˆë‹¤
</span>  <span class="n">tokenizer</span><span class="p">.</span><span class="n">save_model</span><span class="p">(</span><span class="s">'./'</span><span class="p">)</span>  <span class="c1"># save vocab.txt
</span></code></pre></div></div>

<h2 id="bert-ë°ì´í„°-ì¤€ë¹„">Bert ë°ì´í„° ì¤€ë¹„</h2>
<p>bertì˜ MLMì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ë¨¼ì € í•„ìš”í•œ ë°ì´í„°ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.</p>
<ul>
  <li>input_ids, token_type_ids, attention_mask, labels</li>
</ul>

<p>input_ids í† í°ë“¤ ì¤‘ ëœë¤ìœ¼ë¡œ ë§ˆìŠ¤í‚¹í•˜ëŠ”ë° labelsì€ ë§ˆìŠ¤í‚¹ëœ í† í°ë“¤ë§Œ ë“¤ì–´ê°€ëŠ” ê²ƒì´ ì•„ë‹Œ ì›ë˜ input_ids í† í° ë¦¬ìŠ¤íŠ¸ì´ì–´ì•¼ í•©ë‹ˆë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">preprocessing</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
  <span class="s">""" preprocessing(random word convert to "[MASK]") """</span>

  <span class="n">mask</span> <span class="o">=</span> <span class="mi">4</span>  <span class="c1"># [MASK] í† í°ë²ˆí˜¸
</span>  <span class="n">label</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">words</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s">'input_ids'</span><span class="p">]):</span>
    <span class="n">maxlen</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">)):</span> <span class="c1"># [PAD], [SEP]ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ í† í°ë“¤ì˜ ë²”ìœ„
</span>      <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">words</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">4</span><span class="p">):</span>
        <span class="n">maxlen</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">maxlen</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>

      <span class="n">masked_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span> <span class="c1"># ê°„ë‹¨í•˜ê²Œ ì „ì²´ ì¤‘ì˜ 15%ì˜ í† í° ì¤‘ 80%ì˜ í† í°ë§Œ ë§ˆìŠ¤í‚¹í•©ë‹ˆë‹¤
</span>        <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="nb">int</span><span class="p">((</span><span class="n">maxlen</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="mf">0.15</span><span class="o">*</span><span class="mf">0.8</span><span class="p">),),</span> <span class="n">low</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">maxlen</span><span class="p">)</span>
      <span class="n">tmp</span> <span class="o">=</span> <span class="n">words</span><span class="p">.</span><span class="n">clone</span><span class="p">().</span><span class="n">detach</span><span class="p">()</span> <span class="c1"># labelì€ ì›ë˜ì˜ input_idsë¥¼ ë³µì‚¬í•œ ê²ƒì…ë‹ˆë‹¤
</span>      <span class="n">label</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span>

      <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">masked_idx</span><span class="p">:</span>
        <span class="n">words</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">mask</span>
      <span class="n">dataset</span><span class="p">[</span><span class="s">'input_ids'</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">words</span>

  <span class="k">return</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">label</span>
</code></pre></div></div>

<h2 id="ëª¨ë¸-í•™ìŠµ">ëª¨ë¸ í•™ìŠµ</h2>
<p>ìœ„ì—ì„œ bertê°€ MLMë§Œì„ ìˆ˜í–‰í•´ì•¼ í•˜ë¯€ë¡œ transformerì—ì„œ <code class="language-plaintext highlighter-rouge">BertForMaskedLM</code>ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. ì°¸ê³ ë¡œ <code class="language-plaintext highlighter-rouge">BertForPretraining</code>ëª¨ë¸ì€ MLM ë°ì´í„°ì™€ NSP ë°ì´í„° ëª¨ë‘ í•„ìš”í•˜ë¯€ë¡œ í˜„ì¬ ê°€ì§€ê³  ìˆëŠ” ë°ì´í„°ë¡œëŠ” ì‚¬ì „í•™ìŠµì„ í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.</p>

<p>ë˜í•œ, <code class="language-plaintext highlighter-rouge">BertConfigì„</code> ë¶ˆëŸ¬ì™€ì„œ ì›í•˜ëŠ” ì„¤ì •ì„ í•œ í›„ <code class="language-plaintext highlighter-rouge">BertForMaskedLM</code>ì— configì„¤ì •ì„ í•´ì¤ë‹ˆë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1"># training ì¤€ë¹„
</span>  <span class="n">config</span> <span class="o">=</span> <span class="n">BertConfig</span><span class="p">(</span>
      <span class="p">...</span>
  <span class="p">)</span>

  <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s">'tokenizer path'</span><span class="p">)</span> <span class="c1"># í•™ìŠµí•œ í† í¬ë‚˜ì´ì €ê°€ ì €ì¥ëœ ê²½ë¡œë¡œ ì§€ì •í•´ì¤ë‹ˆë‹¤
</span>
  <span class="n">model</span> <span class="o">=</span> <span class="n">BertForMaskedLM</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
  <span class="n">model</span><span class="p">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">vocab_size</span><span class="p">)</span> <span class="c1"># ê¸°ë³¸ìœ¼ë¡œ ì„¤ì •ëœ vocab sizeë¥¼ ìš°ë¦¬ê°€ ë§Œë“  vocab sizeë¡œ ì„ë² ë”© í¬ê¸°ë¥¼ ë§ì¶°ì•¼ í•©ë‹ˆë‹¤
</span>  <span class="n">model</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></div>

<p>ì—¬ê¸°ì„œ vocab sizeê°€ ë§ì§€ ì•Šìœ¼ë©´ CUDA ì—ëŸ¬ê°€ ë°œìƒí•©ë‹ˆë‹¤.<br />
ì•„ë˜ ì—ëŸ¬ë“¤ì€ ë°œìƒí–ˆë˜ ì—ëŸ¬ë“¤ì…ë‹ˆë‹¤. ì•„ë˜ ì—ëŸ¬ë“¤ì˜ ê³µí†µì ì€ ë ˆì´ì–´ì˜ ì‚¬ì´ì¦ˆê°€ ë§ì§€ ì•Šì„ ë•Œ ë°œìƒí•©ë‹ˆë‹¤.</p>
<ul>
  <li>CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling â€˜cublasCreate(handle)â€™</li>
  <li>RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling â€˜cublasSgemm( handle, opa, opb, m, n, k, &amp;alpha, a, lda, b, ldb, &amp;beta, c, ldc)â€™</li>
  <li>CUDA error: device-side assert triggered</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">training_args</code> ë¥¼ ì„¤ì •í•œ í›„ <code class="language-plaintext highlighter-rouge">Trainer</code>ë¥¼ í†µí•´ ëª¨ë¸ì„ í•™ìŠµí•˜ë©´ ë©ë‹ˆë‹¤.<br />
<code class="language-plaintext highlighter-rouge">trainer.save_model(output_dir='')</code>ë¥¼ í†µí•´ <code class="language-plaintext highlighter-rouge">pytorch_model.bin</code>ì„ í¬í•¨í•˜ì—¬ ì—¬ëŸ¬ê°€ì§€ íŒŒì¼ë“¤ì´ ì €ì¥ì´ ë©ë‹ˆë‹¤.</p>

<h2 id="í—ˆê¹…í˜ì´ìŠ¤-ì—…ë¡œë“œ">í—ˆê¹…í˜ì´ìŠ¤ ì—…ë¡œë“œ</h2>
<p>ëª¨ë¸ í•™ìŠµì´ ì™„ë£Œë˜ë©´ output_dir ê²½ë¡œì— í•™ìŠµëœ ê²°ê³¼ë¬¼ë“¤ì´ ì €ì¥ë˜ì–´ìˆìŠµë‹ˆë‹¤.</p>

<p>ì´ ëª¨ë¸ë“¤ì„ í—ˆê¹…í˜ì´ìŠ¤ì— ì—…ë¡œë“œí•˜ê¸° ì „ì— í—ˆê¹…í˜ì´ìŠ¤ ê°€ì…ì„ ì™„ë£Œí•œ í›„ New Modelì„ í†µí•´ ë ˆí¬ì§€í† ë¦¬ë¥¼ ìƒì„±í•˜ê³  git clone í•´ì˜µë‹ˆë‹¤.</p>

<p>ì•„ê¹Œ output_dir ìœ„ì¹˜ì— ìˆëŠ” íŒŒì¼ë“¤ì„ cloneëœ ë””ë ‰í† ë¦¬ì— ì˜®ê¸´ í›„ì— git lfsë¥¼ í™œì„±í™” í•´ì•¼ í•©ë‹ˆë‹¤.</p>

<blockquote>
  <p>git lfsë€? ê¸°ì¡´ git ëª…ë ¹ì€ ìµœëŒ€ 10Mì„ ì´ˆê³¼í•˜ëŠ” íŒŒì¼ì„ ì›ê²© ë ˆí¬ì§€í† ë¦¬ì— ì—…ë¡œë“œ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. git lfsë¥¼ í†µí•´ í° íŒŒì¼ì„ ì˜®ê¸¸ ìˆ˜ ìˆê²Œë©ë‹ˆë‹¤.</p>
</blockquote>

<p>git lfsëŠ” <code class="language-plaintext highlighter-rouge">sudo apt-get install git lfs</code>ë¥¼ í†µí•´ git lfsë¥¼ ì„¤ì¹˜í•˜ê³  ì•„ê¹Œ cloneí•œ ë””ë ‰í† ë¦¬ì— ê°€ì„œ <code class="language-plaintext highlighter-rouge">git lfs install</code> ëª…ë ¹ì–´ë¥¼ í†µí•´ í•´ë‹¹ ë””ë ‰í† ë¦¬ê°€ git lfsë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.</p>

<p>ì´í›„ì—ëŠ” <code class="language-plaintext highlighter-rouge">git add .</code>, <code class="language-plaintext highlighter-rouge">git commit -m "message"</code>, <code class="language-plaintext highlighter-rouge">git push</code> ìˆœìœ¼ë¡œ ëª…ë ¹ì–´ë¥¼ ì¹˜ì‹œë©´ git lfsë¥¼ í†µí•´ ë ˆí¬ì§€í† ë¦¬ë¡œ ì—…ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.</p>

<h3 id="tokenizer_configjson">tokenizer_config.json</h3>
<p><code class="language-plaintext highlighter-rouge">tokenizer_config.json</code>ì€ í—ˆê¹…í˜ì´ìŠ¤ì˜ inference apië¥¼ ì´ìš©í•˜ëŠ”ë° í•„ìš”í•œ íŒŒì¼ì…ë‹ˆë‹¤.</p>

<p>ì´ íŒŒì¼ì„ ë³´ë©´ never_split ì´í›„ì— ì—¬ëŸ¬ê°€ì§€ í•­ëª©ë“¤ì´ ìˆì„ í…ë° ë‚˜ë¨¸ì§€ë¥¼ ë‚ ë¦¬ê³  í—ˆê¹…í˜ì´ìŠ¤ë¡œ ì—…ë¡œë“œ í•˜ì‹œë©´ inference apië¥¼ ì •ìƒì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.</p>

<p>ë˜í•œ, inference apiì˜ exampleì„ ë°”ê¾¸ê³  ì‹¶ë‹¤ë©´ READEME.mdì— ì•„ë˜ì™€ ê°™ì€ ê¸€ì„ ìƒë‹¨ì— ë„£ìœ¼ì‹œë©´ ë©ë‹ˆë‹¤.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---
language: ko
mask_token: "[MASK]"
widget:
  - text: ì‚°ì•… ìì „ê±° ê²½ê¸°ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ìƒˆë¡œìš´ [MASK] 1990ë…„ëŒ€ì— í™œì„±í™” ë˜ì—ˆë‹¤.
---
</code></pre></div></div>

:ET