I"K<h2 id="overview">Overview</h2>

<h3 id="conventional-dl-training-pipeline">Conventional DL Training Pipeline</h3>

<ul>
  <li>Data Engineering
    <ul>
      <li>일반적으로 Data Engineering은 Data Cleansing, Preprocessing, Feature Engineering, Select ML Algorihm, Set Hyperparameters 등의 일련을 거친다.</li>
      <li>Model Architecture와 Hyperparamter를 선택한 후 Train &amp; Evaluate를 진행하는데 성능이 잘 나오면 Hyperparameter tuning을 진행하고 성능이 나오지 않으면 다른 모델을 선택해서 반복한다.</li>
      <li>가장 큰 문제는 위의 과정을 사람이 한다.</li>
      <li>AutoML은 이 반복적인 과정에서 사람을 빼내는 것이 목표이다.</li>
    </ul>
  </li>
</ul>

<h3 id="automlhpo-hyperparameter-optimization의-문제-정의">AutoML(HPO: Hyperparameter Optimization)의 문제 정의</h3>

<ul>
  <li>$\lambda^{*} \in \text{arg}_{\lambda \in \Lambda}\min{L(A_{\lambda}, D_{train}, D_{valid})}$</li>
  <li>$\lambda$는 도메인 $\Lambda$에서의 ML 알고리즘 $A$이다.</li>
  <li>$L()$는 하이퍼파라미터 $\lambda$를 사용한 $A$의 로스를 정의한 것이다.</li>
  <li>HPO는 이 로스를 줄이는 하이퍼파라미터 $\lambda^{*}$를 찾는 문제를 말한다.</li>
</ul>

<h3 id="dl-model-configurationarchitecture-hyperparameter의-특징">DL model Configuration(Architecture, Hyperparameter)의 특징</h3>

<ul>
  <li>주요 타입 구분
    <ul>
      <li>Categorical : optimizer(Adam, SGD, …), module(Conv, Bottleneck, …)</li>
      <li>Continuous : learning rate, regularizer param</li>
      <li>Integer : batch_size, epochs</li>
    </ul>
  </li>
  <li>Conditional : configuration에 따라 search space가 달라질 수 있음
    <ul>
      <li>Optimizer의 sampling에 따라서 optimizer parameter의 종류, search space도 달라짐</li>
      <li>Module의 sample에 따라서 해당 module의 parameter의 종류, search space도 달라짐</li>
    </ul>
  </li>
</ul>

<h3 id="주어진-모델을-경량화하자-vs-새로운-경량-모델을-찾자">주어진 모델을 경량화하자 vs. 새로운 경량 모델을 찾자</h3>

<ul>
  <li>기존 가지고 있는 모델을 경량화 하는 기법 : Pruning, Tensor decomposition</li>
  <li>search를 통해서 경량 모델을 찾는 기법 : NAS(Neural Architecture Search), AutoML(Automated Machine Learning)</li>
</ul>

<h2 id="basic-concept">Basic concept</h2>

<h3 id="일반적인-automl-pipeline">일반적인 AutoML Pipeline</h3>

<ul>
  <li>Configuration $\lambda$(Backbone, Hyperparameters)</li>
  <li>Train with $\lambda$(Black box)</li>
  <li>Evaluate Objective $f(\lambda)$(Accuracy, Speed, Size, …)</li>
  <li>Blackbox Optimization $arg_\lambda \max{f(\lambda)}$</li>
</ul>

<h3 id="bayesian-optimizationwith-gaussian-process-regression">Bayesian Optimization(with Gaussian Process Regression)</h3>

<ul>
  <li>Evaluate까지는 일반적인 AutoML pipeline과 같다.</li>
  <li>Update Surrogate Function($f(\lambda)$의 regression model)</li>
  <li>Update Accquisition Function → 다음 configuration을 찾는다.</li>
  <li>Gaussian Process Regression 간단 설명
    <ul>
      <li>train data $(X, Y)$가 있고 우리는 $Y \approx f(X) + e$ 처럼 $Y$를 잘 설명할 수 있는 함수 $f$를 찾는 것이 목적이다.</li>
      <li>test data $(X_*, Y_*)$ 가 있을 때 우리는 $Y_* $ 를 제외한 나머지를 알고 있다. 우리는 $Y_*$ 는 $X, Y, X_*$ 와 연관이 있을 것이라는 가정을 통해  $X, Y, X_*$ 로 $Y_*$ 를 추정해야 한다. 연관에 대한 표현은 Kernel 함수 $K$ 로 한다.</li>
      <li>$f(x)$를 입력 $x$에서의 가능한 함수의 분포(Random variable)로 생각한다. 그리고 각 Random variable들이 Multivariate Gaussian distribution 관계에 있다고 가정한다.
        <ul>
          <li>함수들의 분포가 Multivariate Gaussian distribution을 따른다고 가정</li>
        </ul>
      </li>
      <li>
        <p>함수 f가 Gaussian process를 따른다.</p>

        <p><img src="https://drive.google.com/uc?export=view&amp;id=1q_m0cq4i2DWgudWytKe-SCxcabLP9Bmf" alt="" /></p>
      </li>
      <li>
        <p>Gaussian Identities(Gaussian의 marginal, conditional도 Gaussian)</p>

        <p><img src="https://drive.google.com/uc?export=view&amp;id=1Fk6MHQKINe0fMxa8-eMrBPk4ZRcxe5YG" alt="" /></p>
      </li>
    </ul>
  </li>
  <li>Surrogate Model(Function): f($\lambda$)의 Regression model
    <ul>
      <li>Objective $f(\lambda)$ 값을 예측하는 모델(지금까지 관측된 $f(\lambda)$들이 있을 때, 새로운 $\lambda^*$에 대한 objective $f(\lambda^*)$는 얼마일까?)</li>
      <li>Objective를 estimate하는 surrogate model을 학습, 다음 좋은 $\lambda$를 선택하는 기준으로 사용</li>
      <li>대표적인 Surrogate model로는 Gaussian Processing Regression(GPR) Model(Mean: 예측 f값, Var: uncertainty)</li>
    </ul>
  </li>
  <li>Acquisition Function: 다음은 어디를 trial하면 좋을까?
    <ul>
      <li>Surrogate model의 output으로부터, 다음 시도해보면 좋을 $\lambda$를 계산하는 함수</li>
      <li>Exploration vs. Exploitation(“불확실한 지점 vs. 알고있는 가장 좋은 곳”의 trade off)</li>
      <li>Acquisition function의 max지점을 다음 iteration에서 trial
        <ul>
          <li>가장 좋은 위치에서 가장 큰 불확실성을 가진 곳을 탐색</li>
          <li>Upper Confidence Bound(UCB) Aquisition function</li>
          <li>$\alpha_t = \mu_{t-1} + \kappa\sigma_{t-1}$</li>
          <li>$\mu$ : posterior mean(Exploitation), $\sigma$ : posterior variance(Exploration), $\kappa$ : hyperparameter(balance)</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="tree-structed-parzen-estimatortpe">Tree-structed Parzen Estimator(TPE)</h3>

<ul>
  <li>GP의 약점 :
    <ul>
      <li>High-dim($O(N^3)$)</li>
      <li>Conditional, continuous/discrete한 파라미터들의 혼재시 적용이 어려움 → 다른 테크닉이 필요</li>
    </ul>
  </li>
  <li>TPE : GPR($p(f|\lambda)$)과 다르게 $p(\lambda|f)$와 $p(\lambda)$를 계산</li>
  <li>TPE를 통한 다음 step의 $\lambda$ 계산 방법
    <ul>
      <li>현재까지 observation들을 특정 quantile(inverse CDF)로 구분 (예를들면 전체 중 75% bad, 25% good)</li>
      <li>KDE(Kernel density estimation)으로 good observations 분포(p(g)), bad observations의 분포(p(b))를 각각 추정</li>
      <li>p(g)/p(b)은 EI(Expected Improvement, aquisition function 중 하나)에 비례하므로 높은 값을 가지는 $\lambda$를 다음 step으로 설정</li>
    </ul>
  </li>
</ul>

<h2 id="further-studies">Further Studies</h2>

<ul>
  <li>가장 큰 문제는 대부분의 task에 대해서, 한 iteration에도 많은 시간이 걸림</li>
  <li>DL에서의 AutoML은 scalability 이슈가 더욱 대두됨</li>
  <li>주요 키워드
    <ul>
      <li>Hyperparameter Gradient Descent</li>
      <li>Meta-learning(Auto ‘AutoML’)</li>
      <li>Multi-fidelity optimization : Data의 subset만을 활용, 작은 epoch, RL을 활용한 적은 trial, Image Downsampling 등등</li>
    </ul>
  </li>
</ul>
:ET