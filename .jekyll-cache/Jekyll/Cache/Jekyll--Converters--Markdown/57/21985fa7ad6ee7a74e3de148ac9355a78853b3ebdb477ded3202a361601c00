I"hJ<blockquote>
  <p>이전 글에서 SequentialExecutor에서 CeleryExecutor로 변경하기 위해 삽질한 경험글입니다.</p>
</blockquote>

<h2 id="celeryexecutor">CeleryExecutor</h2>
<p>Celery는 Postgresql과 Mysql만 db로 사용하고 있어서 기존 sqlite를 postgresql로 바꾸는 작업을 진행했습니다. Mysql은 에러가 자주나서 Postgresql을 선택했습니다.<br />
먼저, <code class="language-plaintext highlighter-rouge">airflow db init</code>을 하게 되면 <code class="language-plaintext highlighter-rouge">AIRFLOW_HOME</code>에 <code class="language-plaintext highlighter-rouge">airflow.cfg</code>라는 설정 파일이 생성됩니다. 바꿔야 하는 설정은 다음과 같습니다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># port는 모두 기본포트를 사용하고 있어서 명시해줄 필요가 없었습니다.
</span><span class="n">executor</span> <span class="o">=</span> <span class="n">CeleryExecutor</span>
<span class="n">sql_alchemy_conn</span> <span class="o">=</span> <span class="n">postgresql</span><span class="o">+</span><span class="n">psycopg2</span><span class="p">:</span><span class="o">//</span><span class="nb">id</span><span class="p">:</span><span class="n">password</span><span class="o">@</span><span class="n">addr</span><span class="o">/</span><span class="n">dbname</span>
<span class="n">broker_url</span> <span class="o">=</span> <span class="n">amqp</span><span class="p">:</span><span class="o">//</span><span class="nb">id</span><span class="p">:</span><span class="n">password</span><span class="o">@</span><span class="n">addr</span><span class="o">/</span><span class="n">mqname</span>
<span class="n">result_backend</span> <span class="o">=</span> <span class="n">db</span><span class="o">+</span><span class="n">postgresql</span><span class="p">:</span><span class="o">//</span><span class="nb">id</span><span class="p">:</span><span class="n">password</span><span class="o">@</span><span class="n">addr</span><span class="o">/</span><span class="n">dbname</span>
</code></pre></div></div>
<p><code class="language-plaintext highlighter-rouge">broker_url</code>에는 보통 메시지 큐를 삽입하는데 RabbitMQ를 사용하기로 했습니다. 보통 Redis는 캐시, RabbitMQ는 메시지 큐로 사용한다고 합니다.</p>

<p>그렇다면, 도커를 추가로 올려야 할 것은 RabbitMQ, Postgresql입니다.</p>

<h2 id="rabbitmq-postgresql">RabbitMQ, Postgresql</h2>
<p>RabbitMQ와 Postgresql은 Docker Hub에 이미지파일이 있어서 latest버전으로 pull했습니다.</p>

<h3 id="rabbitmq-설정">RabbitMQ 설정</h3>
<p>RabbitMQ는 도커로 실행하면 자동으로 서버가 실행되도록 작성되어 있습니다. (CMD [“rabbitmq-server”])<br />
그러나, 여기서 airflow라는 유저와 airflow라는 가상호스트를 추가해야 합니다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># entrypoint.sh
</span><span class="n">rabbitmqctl</span> <span class="n">add_user</span> <span class="n">airflow</span> <span class="n">airflow</span>
<span class="n">rabbitmqctl</span> <span class="n">add_vhost</span> <span class="n">airflow</span>
<span class="n">rabbitmqctl</span> <span class="n">set_user_tags</span> <span class="n">airflow</span> <span class="n">airflow</span>
<span class="n">rabbitmqctl</span> <span class="n">set_permissions</span> <span class="o">-</span><span class="n">p</span> <span class="n">airflow</span> <span class="n">airflow</span> <span class="s">".*"</span> <span class="s">".*"</span> <span class="s">".*"</span>
</code></pre></div></div>
<p>dockerfile에서 CMD로 실행시켜버리면 rabbitmq 이미지의 CMD 명령어가 실행되지 않고 위의 명령어들이 실행되면서 <strong>rabbitmq 서버를 찾을 수 없다</strong>는 에러를 볼 수 있습니다.<br />
어쩔 수 없이 쉘 스크립트로 만들어서 컨테이너에서 쉘을 실행시키는 방법으로 해결했습니다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># dockerfile
</span><span class="n">FROM</span> <span class="n">rabbitmq</span><span class="p">:</span><span class="n">latest</span>

<span class="n">ADD</span> <span class="p">.</span><span class="o">/</span><span class="n">entrypoint</span><span class="p">.</span><span class="n">sh</span>
<span class="n">RUN</span> <span class="n">chmod</span> <span class="o">+</span><span class="n">x</span> <span class="n">entrypoint</span><span class="p">.</span><span class="n">sh</span>
</code></pre></div></div>

<h3 id="postgresql">Postgresql</h3>
<p>Postgresql은 미리 데이터베이스를 만들어둬야 합니다. 그래서 다음과 같은 sql 쿼리를 작성해서 컨테이너에서 실행할 수 있도록 작성했습니다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># entrypoint.sql
</span><span class="n">CREATE</span> <span class="n">DATABASE</span> <span class="n">airflow</span><span class="p">;</span>
<span class="n">CREATE</span> <span class="n">USER</span> <span class="n">airflow</span> <span class="n">WITH</span> <span class="n">PASSWORD</span> <span class="s">'1234'</span> <span class="n">SUPERUSER</span><span class="p">;</span>
</code></pre></div></div>

<p>dockerfile 또한 entrypoint.sql을 실행할 수 있도록 권한을 변경해주고 postgres를 실행할 수 있게 했습니다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># dockerfile
</span><span class="n">FROM</span> <span class="n">postgres</span><span class="p">:</span><span class="n">latest</span>

<span class="n">ADD</span> <span class="p">.</span><span class="o">/</span><span class="n">entrypoint</span><span class="p">.</span><span class="n">sql</span> <span class="p">.</span>
<span class="n">CMD</span> <span class="n">chmod</span> <span class="o">+</span><span class="n">x</span> <span class="n">entrypoint</span><span class="p">.</span><span class="n">sql</span> <span class="o">&amp;&amp;</span> \
    <span class="n">su</span> <span class="n">postgres</span>
</code></pre></div></div>
<p>이후에 컨테이너에서 <code class="language-plaintext highlighter-rouge">psql -U postgres -f entrypoint.sql</code>로 작성한 sql 쿼리를 실행할 수 있습니다.
쉘 스크립트 내에서 sql을 실행시킬 수 있는 방법이 있지만 아직 어려워서 사용하지 못했습니다.</p>

<h2 id="airflow">airflow</h2>
<p>위의 CeleryExecutor에서 바꿔야 할 설정파일들을 자동으로 적용되게 하고 싶었습니다. 스크립트에서 설정파일을 바꿀 수 있는 명렁어가 있는지 찾아보다가 <code class="language-plaintext highlighter-rouge">sed</code>를 찾게 되어 바로 적용했습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#!/bin/bash
</span><span class="n">cp</span> <span class="o">/</span><span class="n">redis</span><span class="o">/</span><span class="n">mydags</span><span class="p">.</span><span class="n">py</span> <span class="o">/</span><span class="n">dags</span>
<span class="n">cp</span> <span class="o">/</span><span class="n">redis</span><span class="o">/</span><span class="n">func</span><span class="p">.</span><span class="n">py</span> <span class="o">/</span><span class="n">dags</span>
<span class="n">cp</span> <span class="o">/</span><span class="n">redis</span><span class="o">/</span><span class="n">redisqueue</span><span class="p">.</span><span class="n">py</span> <span class="o">/</span><span class="n">dags</span>
<span class="n">cp</span> <span class="o">/</span><span class="n">redis</span><span class="o">/</span><span class="n">constant</span><span class="p">.</span><span class="n">py</span> <span class="o">/</span><span class="n">dags</span>

<span class="c1"># create airflow.cfg
</span><span class="n">airflow</span> <span class="n">db</span> <span class="n">init</span>

<span class="c1"># exampel=False, set celery worker
</span><span class="n">sed</span> <span class="o">-</span><span class="n">i</span> <span class="s">"s/load_examples = True/load_examples = False/g"</span> <span class="n">airflow</span><span class="p">.</span><span class="n">cfg</span>
<span class="n">sed</span> <span class="o">-</span><span class="n">i</span> <span class="s">"s/executor = SequentialExecutor/executor = CeleryExecutor/g"</span> <span class="n">airflow</span><span class="p">.</span><span class="n">cfg</span>
<span class="n">sed</span> <span class="o">-</span><span class="n">i</span> <span class="s">"s^sql_alchemy_conn = sqlite:///./airflow.db^sql_alchemy_conn = postgresql+psycopg2://postgres:1234@172.17.0.2/airflow^g"</span> <span class="n">airflow</span><span class="p">.</span><span class="n">cfg</span>
<span class="n">sed</span> <span class="o">-</span><span class="n">i</span> <span class="s">"s^broker_url = redis://redis:6379/0^broker_url = amqp://airflow:airflow@172.17.0.5/airflow^g"</span> <span class="n">airflow</span><span class="p">.</span><span class="n">cfg</span>
<span class="n">sed</span> <span class="o">-</span><span class="n">i</span> <span class="s">"s^result_backend = db+postgresql://postgres:airflow@postgres/airflow^result_backend = db+postgresql://postgres:1234@172.17.0.2:5432/airflow^g"</span> <span class="n">airflow</span><span class="p">.</span><span class="n">cfg</span>

<span class="c1"># create account
</span><span class="n">airflow</span> <span class="n">users</span> <span class="n">create</span> <span class="o">--</span><span class="n">username</span> <span class="n">admin</span> <span class="o">--</span><span class="n">password</span> <span class="mi">1234</span> <span class="o">--</span><span class="n">firstname</span> <span class="n">a</span> <span class="o">--</span><span class="n">lastname</span> <span class="n">b</span> <span class="o">--</span><span class="n">role</span> <span class="n">Admin</span> <span class="o">--</span><span class="n">email</span> <span class="n">smk6221</span><span class="o">@</span><span class="n">naver</span><span class="p">.</span><span class="n">com</span>

<span class="c1"># run airflow
</span><span class="n">airflow</span> <span class="n">celery</span> <span class="n">worker</span> <span class="o">-</span><span class="n">D</span>
<span class="n">airflow</span> <span class="n">celery</span> <span class="n">flower</span> <span class="o">-</span><span class="n">D</span>
<span class="n">airflow</span> <span class="n">scheduler</span> <span class="o">-</span><span class="n">D</span>
<span class="n">airflow</span> <span class="n">webserver</span> <span class="o">-</span><span class="n">p</span> <span class="mi">8080</span>
</code></pre></div></div>
<p><code class="language-plaintext highlighter-rouge">cp</code>명령어로 file sharing으로 로컬에서 작성한 파일들을 컨테이너로 옮기는 과정입니다.<br />
이후에 db 초기화를 진행하고 설정파일을 <code class="language-plaintext highlighter-rouge">sed</code>명렁어로 바꿔줍니다. 이때 주소는 바뀔 수 있어서 airflow 컨테이너를 가장 마지막에 올렸습니다.<br />
로그인할 계정을 만들어주고 celery, scheduler, server를 차례대로 실행시켜 줍니다. 웹서버를 제외한 나머지를 background로 돌리고 웹서버만 foreground로 돌리게했습니다.</p>

<h3 id="dag">DAG</h3>
<p>다음, mydags.py 내용을 수정했습니다. sqlite의 테이블이 있는지 확인하고 없으면 생성하는 태스크를 할 수 있도록 함수 추가와 오퍼레이터를 추가했습니다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># func.py
</span><span class="k">def</span> <span class="nf">create_table</span><span class="p">():</span>
    <span class="n">con</span> <span class="o">=</span> <span class="n">sqlite3</span><span class="p">.</span><span class="n">connect</span><span class="p">(</span><span class="s">'./dags/sqlite.db'</span><span class="p">)</span>
    <span class="n">con</span><span class="p">.</span><span class="n">execute</span><span class="p">(</span><span class="s">'create table if not exists logging (time, level, id)'</span><span class="p">)</span>
    <span class="n">con</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div></div>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># mydags.py
</span><span class="n">t2</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="s">'if_exists_table'</span><span class="p">,</span>
    <span class="n">python_callable</span><span class="o">=</span><span class="n">create_table</span><span class="p">,</span>
    <span class="n">depends_on_past</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">owner</span><span class="o">=</span><span class="s">'gooose'</span><span class="p">,</span>
    <span class="n">retries</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">retry_delay</span><span class="o">=</span><span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div></div>

<h2 id="결과">결과</h2>
<p>최종 그래프는 다음과 같습니다. 
<img src="https://drive.google.com/uc?export=view&amp;id=1Qtqbduiw72XpNNSeQeH7pGWufVc-VT1-" alt="" /><br />
collector들이 연두색 테두리를 가지고 있는데 RUNNING되고 있는 것을 나타내고 있으며 병렬처리되고 있음을 알 수 있습니다.<br />
추가적으로 collector들이 db에 접근하기 때문에 table lock이 필요한가?에 대해서 찾아봤는데 sqlite는 트랜잭션을 실행할 때 테이블을 잠가버리기 때문에 따로 구현할 필요는 없다고 합니다.</p>

<p><img src="https://drive.google.com/uc?export=view&amp;id=1dtOKXsliL3tkOZaqZ9WOmgbz05_8hXIP" alt="" /><br />
collector 하나의 log를 살펴본 이미지인데 에러가 아닌(check=0) 로그들이 문제없이 db로 들어가고 있습니다. 지금 출력이 2개씩 되고 있는것은 코드 작성에서 print가 두 번 실행되고 있기 때문입니다.</p>

<h2 id="회고">회고</h2>
<h3 id="도커">도커</h3>
<p>5개의 컨테이너를 하나씩 돌려보면서 docker-compose를 사용하는 이유를 알 수 있었습니다. 나중에 한 번 연습해보려고 합니다.<br />
그리고, 도커를 실행하면 바로 exit(0)되는 경우가 자주 있었는데 이건 도커에 대한 이해를 제대로 하지 못해서였습니다. 도커는 vmware나 virtual box가 아닌 가상 컨테이너에서 명령을 실행하는 도구로 인식해야 함을 알게 되었습니다.
그래서 명령을 다 실행하게되면 자동으로 도커가 stop되는 것이고 서버처럼 계속 돌아가고 있게 하려면 서버를 foreground로 구동해야 합니다. 컨테이너를 돌릴 때 while문으로 메시지(예를들면, “still alive…“)를 계속 출력하게 하는 방법도 있다고 합니다.<br />
마지막으로 RabbitMQ나 Postgres를 사용해보면서 dockerfile 마지막에 CMD로 쉘 스크립트를 실행시키려고 했지만 서버가 실행되지 않으면서 스크립트 명령어가 제대로 작동하지 않았습니다. 이유는 from으로 들어오는 이미지의 도커파일 마지막에 CMD로 서버를 실행시키는 명령이 있고 저의 dockerfile에서 CMD를 사용해버리면서 대체되어 버리기 때문입니다. 이것을 해결하는 방법은 아직 찾지 못했습니다.</p>

<h3 id="쉘-스크립트">쉘 스크립트</h3>
<p>부캠때도 많이 사용하지 않은 쉘 스크립트를 이번에 많이 사용하게 되었습니다. 아직 초보 수준이고 if문이나 다른 문법들을 공부할 필요를 느낄 수 있었습니다.<br />
특히 <code class="language-plaintext highlighter-rouge">sed</code>의 경우 모두 블로그에서 치환자(?)를 <code class="language-plaintext highlighter-rouge">/</code>로 많이 사용해서 치환할 문자열이 주소인 경우 너무 난감했습니다. 하나의 블로그에서 다른 치환자가 가능하다는 것을 알려줘서 주소가 들어간 경우 <code class="language-plaintext highlighter-rouge">^</code>로 사용할 수 있었습니다.</p>

<h3 id="에어플로우">에어플로우</h3>
<p>먼저, <code class="language-plaintext highlighter-rouge">bashOperator</code>의 경우 임시 폴더에서 실행되는 것을 알 수 있었습니다. 맥 기준 /var/private/…/…(확실하진 않지만 비슷한 경로입니다)와 같은 폴더에서 실행되어 환경변수 <code class="language-plaintext highlighter-rouge">AIRFLOW_HOME</code> 설정이 정말 중요하다는 것을 알 수 있었습니다. 도커파일에는 다른 것들이 들어가지 않아서 <code class="language-plaintext highlighter-rouge">.</code>으로 설정했지만 디렉토리 구분이 필요한 경우 환경변수 세팅이 중요해보입니다.<br />
다음, cron 표기인데 (초, 분, 시간, 일, 월, 년) 순으로 되어 있는 것을 몰라서 0/1 * * * *로 했다가 1초마다 갱신되는 지옥을 보았습니다. 나중에 수정해서 5분마다 갱신되도록 했습니다.</p>

<h2 id="reference">Reference</h2>
<ul>
  <li><a href="https://www.slideshare.net/YoungHeonKim1/airflow-workflow">https://www.slideshare.net/YoungHeonKim1/airflow-workflow</a></li>
  <li><a href="http://sanghun.xyz/2017/12/airflow-4.-celeryexecutor-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/">http://sanghun.xyz/2017/12/airflow-4.-celeryexecutor-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/</a></li>
  <li><a href="https://stackoverflow.com/questions/36822515/configuring-airflow-to-work-with-celeryexecutor">https://stackoverflow.com/questions/36822515/configuring-airflow-to-work-with-celeryexecutor</a></li>
  <li><a href="http://daplus.net/postgresql-%EC%99%B8%EB%B6%80%EC%97%90%EC%84%9C-%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88%EC%9D%98-postgresql%EC%97%90-%EC%97%B0%EA%B2%B0/">http://daplus.net/postgresql-%EC%99%B8%EB%B6%80%EC%97%90%EC%84%9C-%EB%8F%84%EC%BB%A4-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88%EC%9D%98-postgresql%EC%97%90-%EC%97%B0%EA%B2%B0/</a></li>
  <li><a href="https://forums.docker.com/t/unable-to-run-psql-inside-a-postgres-container/90623/7">https://forums.docker.com/t/unable-to-run-psql-inside-a-postgres-container/90623/7</a></li>
</ul>
:ET