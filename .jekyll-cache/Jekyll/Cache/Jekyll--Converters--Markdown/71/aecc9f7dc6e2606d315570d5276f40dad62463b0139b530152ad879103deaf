I":7<blockquote>
  <p>모델링을 하게되면 초기화를 신경쓰지 않게 되는데 어떤식으로 이루어지는지 잘 모르고 있었습니다.
그래서 Linear layer를 선언했을 때 weight와 bias를 어떻게 초기화하는지 알아보고자 합니다.</p>
</blockquote>

<h2 id="class-linear">Class Linear</h2>

<p><code class="language-plaintext highlighter-rouge">Linear</code> 레이어 모듈을 살펴보기 위해 pytorch 코드를 가져왔습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="n">__constants__</span> <span class="o">=</span> <span class="p">[</span><span class="s">'in_features'</span><span class="p">,</span> <span class="s">'out_features'</span><span class="p">]</span>
    <span class="n">in_features</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">out_features</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">weight</span><span class="p">:</span> <span class="n">Tensor</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
                <span class="n">bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">factory_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">'device'</span><span class="p">:</span> <span class="n">device</span><span class="p">,</span> <span class="s">'dtype'</span><span class="p">:</span> <span class="n">dtype</span><span class="p">}</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Linear</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">in_features</span> <span class="o">=</span> <span class="n">in_features</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">out_features</span> <span class="o">=</span> <span class="n">out_features</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span>
            <span class="n">torch</span><span class="p">.</span><span class="n">empty</span><span class="p">((</span><span class="n">out_features</span><span class="p">,</span> <span class="n">in_features</span><span class="p">),</span> <span class="o">**</span><span class="n">factory_kwargs</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">bias</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span>
                <span class="n">torch</span><span class="p">.</span><span class="n">empty</span><span class="p">(</span><span class="n">out_features</span><span class="p">,</span> <span class="o">**</span><span class="n">factory_kwargs</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="s">'bias'</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">reset_parameters</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">init</span><span class="p">.</span><span class="n">kaiming_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">fan_in</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">init</span><span class="p">.</span><span class="n">_calculate_fan_in_and_fan_out</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">weight</span><span class="p">)</span>
            <span class="n">bound</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">fan_in</span><span class="p">)</span> <span class="k">if</span> <span class="n">fan_in</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
            <span class="n">init</span><span class="p">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">bias</span><span class="p">,</span> <span class="o">-</span><span class="n">bound</span><span class="p">,</span> <span class="n">bound</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">F</span><span class="p">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">bias</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">extra_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="s">'in_features={}, out_features={}, bias={}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">in_features</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">out_features</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span>
        <span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Linear layer</code>를 선언하게 되면 <code class="language-plaintext highlighter-rouge">__init__()</code>함수에 의해 <code class="language-plaintext highlighter-rouge">self.weight</code>와 <code class="language-plaintext highlighter-rouge">self.bias</code>를 생성합니다.</p>

<p>이후 이 파라미터들은 <code class="language-plaintext highlighter-rouge">self.reset_parameters()</code>에 의해 초기화가 진행됩니다.</p>

<h2 id="reset-parameters">reset parameters()</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">init</span><span class="p">.</span><span class="n">kaiming_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
    <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">fan_in</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">init</span><span class="p">.</span><span class="n">_calculate_fan_in_and_fan_out</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">bound</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">fan_in</span><span class="p">)</span> <span class="k">if</span> <span class="n">fan_in</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="n">init</span><span class="p">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">bias</span><span class="p">,</span> <span class="o">-</span><span class="n">bound</span><span class="p">,</span> <span class="n">bound</span><span class="p">)</span>
</code></pre></div></div>

<p>먼저, <code class="language-plaintext highlighter-rouge">self.weight</code>는 <code class="language-plaintext highlighter-rouge">kaiming_unifrom</code>에 의해 초기화가 진행됩니다. kaiming initialize는 검색하시면 자세한 내용이 있기 때문에 넘어가겠습니다.</p>

<p>다음, <code class="language-plaintext highlighter-rouge">self.bias는</code> weight의 <code class="language-plaintext highlighter-rouge">bound</code>를 계산한 후 <code class="language-plaintext highlighter-rouge">unform(-bound, bound)</code>에 의해 초기화가 진행됩니다.</p>

<h3 id="initialize-bias">initialize Bias</h3>
<p><code class="language-plaintext highlighter-rouge">bias</code>를 <code class="language-plaintext highlighter-rouge">uniform(-bound, bound)</code>로 초기화하고 있기 때문에 다시 찾아봤는데 <a href="https://stackoverflow.com/questions/48529625/in-pytorch-how-are-layer-weights-and-biases-initialized-by-default">In PyTorch how are layer weights and biases initialized by default?</a>에서 bias는 <strong>LeCunn 초기화 방법</strong>을 사용한다고 합니다.</p>

<p>Lecunn 초기화 방법의 아이디어는 확률분포를 <code class="language-plaintext highlighter-rouge">fan_in</code>으로 조절하고자 하는 것이라고 합니다.</p>
<ul>
  <li>bound를 계산하기 전에 <code class="language-plaintext highlighter-rouge">_calculate_fan_in_and_fan_out()</code>이라는 함수를 통해 <code class="language-plaintext highlighter-rouge">fan_in</code>이라는 값을 계산하는데 input layer의 뉴런 수를 <code class="language-plaintext highlighter-rouge">fan_in</code>, output layer의 뉴런 수를 <code class="language-plaintext highlighter-rouge">fan_out</code>이라고 합니다.</li>
</ul>

<p>lecunn init 논문인 <strong>Efficient BackProp</strong>의 섹션 4.6을 보면 sqrt(1/fan_in)으로 표준편자를 정하고 평균은 0인 uniform하게 초기화합니다.</p>

<p>이렇게 <code class="language-plaintext highlighter-rouge">nn.Linear</code> 레이어의 weight는 kaiming, bias는 lecunn 초기화가 진행되어 <code class="language-plaintext highlighter-rouge">reset_parameters()</code>가 끝나게 됩니다.</p>

<h2 id="다른-초기화-방법들">다른 초기화 방법들</h2>

<p>초기화 방법들은 여러가지가 있고 torch의 모듈마다 초기화 방법이 달라집니다.</p>

<p>예를들면 embedding 레이어는 normal을 사용합니다.</p>

<p>다른 Xaiver, He 등의 여러가지 초기화 방법들 또한 사용가능합니다.</p>

<p>사용할때는 초기화를 신경쓰면서 사용하는 편은 아니지만 한번 코드 내부를 돌면서 이런식으로 진행하는구나 정도로 봐주시면 될 것 같습니다.</p>

<h2 id="reference">Reference</h2>
<ul>
  <li><a href="https://arxiv.org/abs/1502.01852v1">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</a></li>
  <li><a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf">Efficient BackProp</a></li>
  <li><a href="https://yeomko.tistory.com/40">갈아먹는 딥러닝 기초 [2] weight initialization</a></li>
  <li><a href="https://github.com/pytorch/pytorch/tree/v0.3.1/torch/nn/modules">torch/nn/modules</a></li>
  <li><a href="https://stackoverflow.com/questions/48529625/in-pytorch-how-are-layer-weights-and-biases-initialized-by-default">In PyTorch how are layer weights and biases initialized by default?</a></li>
</ul>
:ET