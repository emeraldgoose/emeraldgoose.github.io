I"‹<h2 id="long-short-term-memory-lstm">Long Short-Term Memory (LSTM)</h2>

<ul>
  <li>Original RNNì—ì„œì˜ Long term dependencyë¥¼ ê°œì„ í•œ ëª¨ë¸ì´ë‹¤.</li>
  <li>ë§¤ íƒ€ì„ìŠ¤í…ë§ˆë‹¤ ë³€í™”í•˜ëŠ” hidden state vectorë¥¼ ë‹¨ê¸°ê¸°ì–µì„ ë‹´ë‹¹í•˜ëŠ” ê¸°ì–µì†Œìë¡œ ë³¼ ìˆ˜ ìˆë‹¤.</li>
  <li>ë‹¨ê¸°ê¸°ì–µì„ ì´ ì‹œí€€ìŠ¤ê°€ íƒ€ì„ìŠ¤í…ë³„ë¡œ ì§„í–‰ë¨ì— ë”°ë¼ì„œ ë‹¨ê¸°ê¸°ì–µì„ ë³´ë‹¤ ê¸¸ê²Œ ê¸°ì–µí•  ìˆ˜ ìˆë„ë¡ ê°œì„ í•œ ëª¨ë¸ì´ë‹¤.</li>
  <li>LSTMì€ RNNê³¼ ë‹¬ë¦¬ ì´ì „ stateì—ì„œ ë‘ ê°€ì§€ì˜ ì •ë³´ê°€ ë“¤ì–´ì˜¤ëŠ”ë° $C_{t-1}$ì™€ $h_{t-1}$ì´ë‹¤.
    <ul>
      <li>$C_{t-1}$ì„ Cell stateë¼ ë¶€ë¥´ê³  $h_{t-1}$ì„ hidden state vectorë¼ í•œë‹¤.</li>
    </ul>
  </li>
  <li>
    <p>Long short-term memory</p>

    <p><img src="https://drive.google.com/uc?export=view&amp;id=1CohnbjI4kQSr2SldfOX3eEJmyz98ZKim" alt="" /></p>

    <ul>
      <li>i : Input gate</li>
      <li>f : Forget gate</li>
      <li>o : Output gate</li>
      <li>g : Gate gate</li>
      <li>WëŠ” $x$ì™€ $h$ë¥¼ concatí•œ í¬ê¸°ì™€ 4ê°œì˜ outputì˜ í¬ê¸°ë§Œí¼ì˜ ì‚¬ì´ì¦ˆë¥¼ ê°–ê²Œëœë‹¤.</li>
      <li>ì´í›„ì— sigmoid ê°’ì„ ê³±í•´ ì¼ì • ë¹„ìœ¨ì˜ ì •ë³´ë§Œ ê°–ë„ë¡ ê³„ì‚°í•´ì£¼ê³  tanhë¥¼ í†µí•´ í˜„ì¬ íƒ€ì„ìŠ¤í…ì—ì„œ ìœ ì˜ë¯¸í•œ ì •ë³´ë¡œ ë³€í™˜í•˜ê²Œ ëœë‹¤.</li>
    </ul>
  </li>
  <li>
    <p>Forget gate</p>

    <p><img src="https://drive.google.com/uc?export=view&amp;id=1AtU18zyX_52jI27o5tklVFQQZ-sEg7ed" alt="" width="400" /></p>

    <ul>
      <li>$f_t=\sigma(W_f\cdot [h_{t-1},x_t] + b_f)$</li>
      <li>ì´ì „ cell state vectorì˜ ê°’ $C_{t-1}$ê³¼ $f_t$ë¥¼ ê³±í•´ ì¼ë¶€ ì •ë³´ë¥¼ ìŠê²Œ í•œë‹¤.</li>
    </ul>
  </li>
  <li>Generate information to be added and cut it by input gate
    <ul>
      <li>$i_t = \sigma(W_i\cdot [h_{t-1},x_t] + b_i)$</li>
      <li>$\tilde{C_t}=tanh(W_C \cdot [h_{t-1},x_t] + b_C)$ â†’ -1ê³¼ 1ì‚¬ì´ì˜ ê°’</li>
    </ul>
  </li>
  <li>
    <p>Generate new cell state by adding current information to previous cell state</p>

    <p><img src="https://drive.google.com/uc?export=view&amp;id=1kn9T6ESwAWZBlsP6VNelcHPegWr1nK1Q" alt="" width="400" /></p>

    <ul>
      <li>$C_t = f_t \cdot C_{t-1} + i_t \cdot \tilde{C_t}$</li>
      <li>$\tilde{C}$ì™€ input gateë¥¼ ê³±í•˜ëŠ” ê²ƒì€ í•œë²ˆì˜ ì„ í˜•ë³€í™˜ë§Œìœ¼ë¡œ $C_{t-1}$ì˜ ë”í•´ì¤„ ì •ë³´ë¥¼ ë§Œë“¤ê¸°ê°€ ì–´ë ¤ìš´ ê²½ìš° ë”í•´ì£¼ê³ ì í•˜ëŠ” ê°’ë³´ë‹¤ ì¢€ ë” í° ê°’ë“¤ë¡œ êµ¬ì„±ëœ $\tilde{C}$ í˜¹ì€ Gate gateë¡œ ë§Œë“¤ì–´ ì¤€ í›„ ê·¸ ê°’ì—ì„œ dimensionë³„ë¡œ íŠ¹ì • ë¹„ìœ¨ë§Œí¼ì˜ ì •ë³´ë¥¼ ëœì–´ë‚´ì„œ  $C_t$ë¥¼ ë§Œë“¤ê¸° ìœ„í•¨ì´ë‹¤.</li>
    </ul>
  </li>
  <li>Generate hidden state by passing cell state to tanh and output gate</li>
  <li>
    <p>Pass this hidden state to next time step, and output or next layer if needed</p>

    <p><img src="https://drive.google.com/uc?export=view&amp;id=1LvQH_SdxIDYbw7MYA9tOr7qMRP3XOEnU" alt="" width="400" /></p>

    <ul>
      <li>$o_t = \sigma(W_o[h_{t-1},x_t] + b_o)$</li>
      <li>$h_t = o_t \cdot tanh(C_t)$
        <ul>
          <li>$0 â‰¤ o_t â‰¤ 1, -1 â‰¤ tanh(C_t) â‰¤ 1$</li>
          <li>hidden stateë¥¼ ë§Œë“¤ ë•Œì—ë„ dimension ë³„ë¡œ íŠ¹ì • ë¹„ìœ¨ë¡œ ì‘ê²Œ ë§Œë“¤ì–´ì„œ êµ¬ì„±ëœë‹¤.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="gated-recurrent-unitgru">Gated Recurrent Unit(GRU)</h2>

<ul>
  <li>GRUëŠ” ì ì€ ë©”ëª¨ë¦¬ì™€ ë¹ ë¥¸ ê³„ì‚°ì‹œê°„ì´ ê°€ëŠ¥í•˜ë„ë¡ ë§Œë“  ëª¨ë¸ì´ë‹¤.</li>
  <li>
    <p>LSTMì˜ cell state vectorì™€ hidden state vectorë¥¼ ì¼ì›í™”í•´ì„œ hidden state í•˜ë‚˜ë§Œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ GRUì˜ íŠ¹ì§•</p>

    <p><img src="https://drive.google.com/uc?export=view&amp;id=1fefitTJsa8D8tcGx3uKIrXL31MxH6_G9" alt="" width="400" /></p>

    <ul>
      <li>$z_t = \sigma(W_z \cdot [h_{t-1},x_t])$</li>
      <li>$r_t = \sigma(W_r \cdot [h_{t-1},x_t])$</li>
      <li>$\tilde{h_t} = tanh(W \cdot [r_t \cdot h_{t-1},x_t])$</li>
      <li>$h_t = (1 - z_t)\cdot h_{t-1} + z_t\cdot \tilde{h_t}$
        <ul>
          <li>$h_{t-1}$ì™€ $\tilde{h_t}$ ë‘ ì •ë³´ë¥¼ ë”í•˜ëŠ” ê²ƒì´ ì•„ë‹Œ ë‘ ì •ë³´ê°„ì˜ ê°€ì¤‘í‰ê· ì„ ë‚´ëŠ” í˜•íƒœë¡œ ê³„ì‚°ëœë‹¤.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Backpropagation in LSTM? GRU
    <ul>
      <li>
        <p>Uninterrupted gradient flow!</p>

        <p><img src="https://drive.google.com/uc?export=view&amp;id=1LVrUy6fcQeE1o8WP1Vh3_Y6a5gcn8GAb" alt="" width="1000" /></p>
      </li>
      <li>forget gateë¥¼ ê³±í•˜ëŠ” ê²ƒì´ ì•„ë‹Œ ë§ì…ˆìœ¼ë¡œ ê³„ì‚°í•˜ê¸° ë•Œë¬¸ì— gradient vanish / explosion problemì´ ì—†ì–´ì§„ë‹¤.</li>
      <li>ë§ì…ˆì—°ì‚°ì€ backpropì„ ìˆ˜í–‰í•  ë•Œ gradientë¥¼ ë³µì‚¬í•´ì£¼ëŠ” ì—°ì‚°ì´ ë˜ê³  ë”°ë¼ì„œ í•­ìƒ ë™ì¼í•œ $W_{hh}$ê°€ ê³±í•´ì§€ëŠ” Original RNNì— ë¹„í•´ ë©€ë¦¬ìˆëŠ” íƒ€ì„ìŠ¤í…ê¹Œì§€ Gradientë¥¼ í° ë³€í˜•ì—†ì´ ì „ë‹¬í•  ìˆ˜ ìˆë‹¤.</li>
      <li>ì´ë¥¼ í†µí•´ ê¸´ íƒ€ì„ìŠ¤í…ê°„ì— ì¡´ì¬í•˜ëŠ” Long term dependencyë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆê²Œ ëœë‹¤.</li>
    </ul>
  </li>
</ul>

<h2 id="summary-on-rnnlstmgru">Summary on RNN/LSTM/GRU</h2>

<ul>
  <li>RNNì€ ë‹¤ì–‘í•œ ê¸¸ì´ë¥¼ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ì‹œí€€ìŠ¤ ë°ì´í„°ì— íŠ¹í™”ëœ ìœ ì—°í•œ í˜•íƒœì˜ ë”¥ëŸ¬ë‹ ëª¨ë¸ êµ¬ì¡°ì´ë‹¤.</li>
  <li>Vanila RNN(Original RNN)ì€ êµ¬ì¡°ê°€ ê°„ë‹¨í•˜ì§€ë§Œ í•™ìŠµ ì‹œì— Gradient Vanishing/Explosion ë¬¸ì œê°€ ìˆì–´ì„œ ì‹¤ì œë¡œ ë§ì´ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤.</li>
  <li>LSTMì´ë‚˜ GRUë¥¼ ì‹¤ì œë¡œ ë§ì´ ì‚¬ìš©í•˜ê³  Cell state vector í˜¹ì€ hidden state vectorì—ì„œ ì—…ë°ì´íŠ¸í•˜ëŠ” ê³¼ì •ì´ ë§ì…ˆì´ê¸° ë•Œë¬¸ì— Long term dependencyë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆë‹¤.</li>
</ul>
:ET