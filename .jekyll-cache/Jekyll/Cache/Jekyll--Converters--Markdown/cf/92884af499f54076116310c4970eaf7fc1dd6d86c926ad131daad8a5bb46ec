I"i<p>python으로 Transformer 바닥부터 구현하기[1] (MultiHead-Attention, LayerNorm, GELU)</p>
:ET