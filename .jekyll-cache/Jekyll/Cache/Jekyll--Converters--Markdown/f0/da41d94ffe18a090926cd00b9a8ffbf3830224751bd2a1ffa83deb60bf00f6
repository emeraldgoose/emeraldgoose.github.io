I"–)<h2 id="motivation">Motivation</h2>
<blockquote>
  <p>ëª¨ê¸°ì—… ì½”ë”©í…ŒìŠ¤íŠ¸ì— íŒŒì´ì¬ ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œë§Œ MLPë¥¼ êµ¬í˜„í•˜ëŠ” ë¬¸ì œê°€ ë‚˜ì™”ë˜ ì ì´ ìˆìŠµë‹ˆë‹¤. ë‹¹ì‹œì— í•™ìŠµì´ ë˜ì§€ ì•Šì•„ ì½”ë”©í…ŒìŠ¤íŠ¸ì—ì„œ ë–¨ì–´ì¡Œì—ˆê³  êµ¬í˜„í•˜ì§€ ëª»í–ˆë˜ ê²ƒì´ ê³„ì† ìƒê°ë‚¬ì—ˆìŠµë‹ˆë‹¤.
numpyë¡œ êµ¬í˜„í•œ ì½”ë“œëŠ” ë§ì•˜ì§€ë§Œ numpyë„ ì‚¬ìš©í•˜ì§€ ì•Šê³  êµ¬í˜„í•œ ì½”ë“œëŠ” ë§ì´ ì—†ì—ˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ë„ì „í•´ë´¤ìŠµë‹ˆë‹¤.</p>
</blockquote>

<h2 id="ê³„íš">ê³„íš</h2>
<p>ë°ì´í„°ì…‹ì„ MNISTë¡œ ì¡ê³  MLPë¥¼ êµ¬í˜„í•˜ê³ ì í–ˆìŠµë‹ˆë‹¤. ì½”ë”©í…ŒìŠ¤íŠ¸ë•Œë„ ì…ë ¥ìœ¼ë¡œ MNISTì™€ ë¹„ìŠ·í•œ ê°’ì´ ë“¤ì–´ì™”ì—ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.</p>

<p>ë ˆì´ì–´ëŠ” ì´ 3ê°œë¡œ input -&gt; (Linear -&gt; Activation) -&gt; (Linear -&gt; Activation) -&gt; (Linear -&gt; Softmax) -&gt; output ìœ¼ë¡œ ìƒê°í•˜ê³  ê° ëª¨ë“ˆì„ êµ¬í˜„ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤.</p>

<p>ì²˜ìŒ ê³„íšì€ notebook íŒŒì¼ë¡œ ê° ëª¨ë“ˆì„ ë§Œë“¤ê³  ë§ˆì§€ë§‰ì— ì½”ë“œë¥¼ ëŒë ¤ë³´ëŠ” ì‹ìœ¼ë¡œ êµ¬ìƒí–ˆë‹¤ê°€ ì°¨ë¼ë¦¬ íŒ¨í‚¤ì§€ë¡œ ë§Œë“¤ì–´ì„œ torchì²˜ëŸ¼ ëª¨ë“ˆì„ import í•˜ëŠ”ê²ƒì´ ë” ê¹”ë”í•´ë³´ì˜€ìŠµë‹ˆë‹¤.</p>

<p>ê·¸ë ‡ê²Œ ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜¤ëŠ” dataset.py, ë ˆì´ì–´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” layers.py, ì˜µí‹°ë§ˆì§€ì–´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” optim.py, ê°ì¢… ê³„ì‚°ì— í•„ìš”í•œ í•¨ìˆ˜ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” utils.pyë¡œ ë‚˜ëˆ„ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.</p>

<h2 id="modules">Modules</h2>
<h3 id="linear-layer">Linear Layer</h3>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>class Linear:
  def __init__(self, in_features, out_features):
    squared_k = math.sqrt(1/in_features)
    self.weight = [[random.uniform(-squared_k,squared_k) for _ in range(out_features)] for _ in range(in_features)]
    self.bias = [[random.uniform(-squared_k,squared_k) for _ in range(out_features)]]
    self.X, self.Z = None, None # dz/dw = x, dz/db = 1, self.X = input, self.Z = output

  def __call__(self, inputs):
    self.X = inputs # (batch, in_f)
    mat = dot_numpy(inputs, self.weight) # (batch, out_f)
    self.Z = [[a+b for a,b in zip(mat[i],self.bias[0])] for i in range(len(mat))] # (batch, out_features)
    return self.Z

  def backward(self, dz):
    dw = dot_numpy(transpose(self.X), dz)
    db = [[sum([dz[i][j] for i in range(len(dz))])/len(dz) for j in range(len(dz[0]))]]
    return dw, db
</code></pre></div></div>

<h3 id="activation-function">Activation Function</h3>
<p>í™œì„±í™” í•¨ìˆ˜ë¡œëŠ” Softmax()ì™€ Sigmoid()ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ì²˜ìŒ ë”¥ëŸ¬ë‹ì„ ê³µë¶€í•˜ë©´ ê°€ì¥ ë§ì´ ë³´ê²Œ ë˜ëŠ” í•¨ìˆ˜ë“¤ì´ê³  MLPì— ì‚¬ìš©ë˜ê¸° ì‰¬ìš´ í•¨ìˆ˜ë“¤ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.</p>

<p>í™œì„±í™” í•¨ìˆ˜ë“¤ì€ í´ë˜ìŠ¤ë¡œ ì •ì˜ë˜ì–´ ìˆëŠ”ë° ì—­ì „íŒŒ(backpropagation)ë•Œ ê°ê° ì…ë ¥ê°’ì— ëŒ€í•´ ë¯¸ë¶„ê°’ì„ ì¶œë ¥í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.</p>

<p>ë¨¼ì €, Sigmoidí•¨ìˆ˜ëŠ” ë‹¤ìŒì˜ ë¯¸ë¶„ì‹ì„ ê°€ì§‘ë‹ˆë‹¤.</p>
<ul>
  <li>$fâ€™(x) = f(x)(1-f(x))$</li>
</ul>

<p>ë‹¤ìŒ, Softmaxí•¨ìˆ˜ëŠ” Cross Entropyì™€ í•¨ê»˜ ì“°ì¼ ë•Œ ë‹¤ìŒì˜ ë¯¸ë¶„ì‹ì„ ê°€ì§‘ë‹ˆë‹¤.</p>
<ul>
  <li>$y_i - t_i$</li>
  <li>$t$ëŠ” ì •ë‹µë ˆì´ë¸”ì˜ ì›í•«ì¸ì½”ë”©ëœ ë²¡í„°ë¥¼ ë§í•©ë‹ˆë‹¤.</li>
</ul>

<p>expì™€ ê´€ë ¨ëœ ìˆ˜ì‹ì— ë°˜ì˜¬ë¦¼í•˜ëŠ” í•¨ìˆ˜ê°€ ì ìš©ë˜ì–´ ìˆëŠ”ë° e^x í•¨ìˆ˜ì—ì„œ xê°€ ì¡°ê¸ˆë§Œ ì»¤ì ¸ë„ overflowê°€ ë°œìƒí•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì´ë¥¼ ì œì–´í•˜ê¸° ìœ„í•´ ì†Œìˆ˜ì  4ìë¦¬ê¹Œì§€ë§Œ ì‚¬ìš©í•˜ë„ë¡ 5ìë¦¬ì—ì„œ ë°˜ì˜¬ë¦¼ì‹œì¼°ìŠµë‹ˆë‹¤.</p>
<ul>
  <li>ë°œìƒí•œ ì—ëŸ¬ëŠ” <code class="language-plaintext highlighter-rouge">Overflow, (34, Numerical result out of range)</code> ì…ë‹ˆë‹¤.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Softmax</span><span class="p">:</span>
  <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="c1"># inputs = 2 dim
</span>    <span class="n">sum_</span> <span class="o">=</span> <span class="p">[</span>\
            <span class="nb">round</span><span class="p">(</span><span class="nb">sum</span><span class="p">([</span><span class="n">exp</span><span class="o">**</span><span class="nb">round</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">[</span><span class="n">j</span><span class="p">]]),</span> <span class="mi">4</span><span class="p">)</span> \
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">))]</span>
    <span class="k">return</span> <span class="p">[</span>\
            <span class="p">[</span><span class="nb">round</span><span class="p">(</span><span class="n">exp</span><span class="o">**</span><span class="nb">round</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="o">/</span><span class="n">sum_</span><span class="p">[</span><span class="n">j</span><span class="p">],</span><span class="mi">4</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">[</span><span class="n">j</span><span class="p">]]</span> \
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">))]</span>
    
  <span class="k">def</span> <span class="nf">deriv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">y_true</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)):</span> <span class="n">inputs</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">y_true</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">-=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">inputs</span>

<span class="k">class</span> <span class="nc">Sigmoid</span><span class="p">:</span>
  <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="n">r</span> <span class="o">=</span> <span class="p">[</span>\
         <span class="p">[</span><span class="nb">round</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="nb">round</span><span class="p">(</span><span class="n">exp</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="nb">round</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">4</span><span class="p">)),</span><span class="mi">4</span><span class="p">)),</span><span class="mi">4</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> \
         <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">))]</span>
    <span class="k">return</span> <span class="n">r</span>

  <span class="k">def</span> <span class="nf">deriv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span>\
            <span class="p">[</span><span class="nb">round</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]),</span><span class="mi">4</span><span class="p">)</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]))]</span> \
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))]</span>
</code></pre></div></div>

<h3 id="loss-function">Loss Function</h3>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<h3 id="optimizer">Optimizer</h3>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code></code></pre></div></div>

<p>##</p>

<h2 id="conclusion">Conclusion</h2>
<p>ë²¡í„° ê³„ì‚°ì´ë‚˜ ë‹¤ë¥¸ ìˆ˜ì‹ ê³„ì‚°ì— ë„ì›€ì´ ë˜ëŠ” numpy ì—†ì´ êµ¬í˜„í•˜ë ¤ê³  í•˜ë‹ˆ ì½”ë“œì—ì„œ ì‹¤ìˆ˜ë¥¼ ë§ì´ í–ˆìŠµë‹ˆë‹¤.</p>

<p>ê³„ì‚° ê²°ê³¼ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ torchë‚˜ numpyì— ìˆëŠ” ë˜‘ê°™ì€ í•¨ìˆ˜ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ì €ì˜ ì½”ë“œë¥¼ ë¶ˆëŸ¬ì™€ ê³„ì‚°ê²°ê³¼ê°€ ë§ëŠ”ì§€ ê³„ì† í™•ì¸í–ˆìŠµë‹ˆë‹¤.</p>

<h2 id="reference">Reference</h2>
<ul>
  <li><a href="http://taewan.kim/post/sigmoid_diff/">http://taewan.kim/post/sigmoid_diff/</a></li>
  <li><a href="https://ratsgo.github.io/deep%20learning/2017/10/02/softmax/">https://ratsgo.github.io/deep%20learning/2017/10/02/softmax/</a></li>
  <li></li>
</ul>
:ET