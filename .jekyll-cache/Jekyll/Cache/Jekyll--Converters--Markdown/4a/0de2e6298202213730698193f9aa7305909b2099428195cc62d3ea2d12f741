I"<h2 id="introduction-to-passage-retrieval">Introduction to Passage Retrieval</h2>

<h3 id="passage-retrieval">Passage Retrieval</h3>

<blockquote>
  <p>ì§ˆë¬¸(query)ì— ë§ëŠ” ë¬¸ì„œ(passage)ë¥¼ ì°¾ëŠ” ê²ƒ.</p>

</blockquote>

<h3 id="passage-retrieval-with-mrc">Passage Retrieval with MRC</h3>

<p>Open-domain Question Answering: ëŒ€ê·œëª¨ì˜ ë¬¸ì„œ ì¤‘ì—ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ ì°¾ê¸°</p>

<ul>
  <li>
    <p>Passage Retrievalê³¼ MRCë¥¼ ì´ì–´ì„œ 2-Stageë¡œ ë§Œë“¤ ìˆ˜ ìˆìŒ</p>

    <p><img src="https://drive.google.com/uc?export=view&amp;id=14iurFvUnXIiLZj_XEwNbh5M2ze3ZeDxV" alt="" /></p>
  </li>
</ul>

<h3 id="overview-of-passage-retrieval">Overview of Passage Retrieval</h3>

<p>Queryì™€ Passageë¥¼ ì„ë² ë”©í•œ ë’¤ ìœ ì‚¬ë„ë¡œ ë­í‚¹ì„ ë§¤ê¸°ê³ , ìœ ì‚¬ë„ê°€ ê°€ì¥ ë†’ì€ Passageë¥¼ ì„ íƒí•¨</p>

<p><img src="https://drive.google.com/uc?export=view&amp;id=1BE1hDFSaRXPx3aTVvuP5BRSe_NU1S210" alt="" /></p>

<p>ì§ˆë¬¸ì´ ë“¤ì–´ì™”ì„ ë•Œ, ì§ˆë¬¸ì„ ì–´ë–¤ vector spaceë¡œ ì„ë² ë”©í•˜ê³  ë§ˆì°¬ê°€ì§€ë¡œ Passage ë˜í•œ ê°™ì€ vector spaceì— ì„ë² ë”©í•œë‹¤. Passageì˜ ì„ë² ë”©ì€ ë¯¸ë¦¬ í•´ë†“ì•„ íš¨ìœ¨ì„±ì„ ë†’ì¸ë‹¤.<br />
ë‹¤ìŒ, ì¿¼ë¦¬ì™€ ë¬¸ì„œì˜ Similarityë¥¼ ì¸¡ì •í•˜ì—¬ Rankingì„ ë§¤ê¸°ê²Œ ëœë‹¤. ì´ë•Œ ScoreëŠ” nearest neighbor(ê³ ì°¨ì› spaceì—ì„œ ì„œë¡œì˜ ê±°ë¦¬ë¥¼ ì¸¡ì •)ì™€ inner product ë°©ë²•ì„ ì‚¬ìš©í•œë‹¤.</p>

<h2 id="passage-embedding-and-sparse-embedding">Passage Embedding and Sparse Embedding</h2>

<h3 id="passage-embedding">Passage Embedding</h3>

<blockquote>
  <p>êµ¬ì ˆ(Passage)ì„ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒ</p>

</blockquote>

<h3 id="passage-embedding-space">Passage Embedding Space</h3>

<blockquote>
  <p>Passage Embeddingì˜ ë²¡í„° ê³µê°„
ë²¡í„°í™”ëœ Passageë¥¼ ì´ìš©í•˜ì—¬ Passage ê°„ ìœ ì‚¬ë„ ë“±ì„ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ê³„ì‚°í•  ìˆ˜ ìˆìŒ</p>

</blockquote>

<h3 id="sparse-embedding-ì†Œê°œ">Sparse Embedding ì†Œê°œ</h3>

<ul>
  <li>Bag-of-Word(BoW)
    <ul>
      <li>BoWë¥¼ êµ¬ì„±í•˜ëŠ” ë°©ë²• â†’ n-gram
        <ul>
          <li>unigram (1-gram)</li>
          <li>bigram (2-gram)</li>
        </ul>
      </li>
      <li>Term valueë¥¼ ê²°ì •í•˜ëŠ” ë°©ë²•
        <ul>
          <li>Termì´ documentì— ë“±ì¥í•˜ëŠ”ì§€ ì•ˆí•˜ëŠ”ì§€ (binary)</li>
          <li>Termì´ ëª‡ë²ˆ ë“±ì¥í•˜ëŠ”ì§€ (term frequency), ë“±. (eg. TF-IDF)</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="sparse-embedding-íŠ¹ì§•">Sparse Embedding íŠ¹ì§•</h3>

<ol>
  <li>Dimension of embedding vector = number of terms
    <ol>
      <li>ë“±ì¥í•˜ëŠ” ë‹¨ì–´ê°€ ë§ì•„ì§ˆìˆ˜ë¡ ì¦ê°€</li>
      <li>N-gramì˜ nì´ ì»¤ì§ˆìˆ˜ë¡ ì¦ê°€</li>
    </ol>
  </li>
  <li>Term overlapì„ ì •í™•í•˜ê²Œ ì¡ì•„ ë‚´ì•¼ í•  ë•Œ ìœ ìš©</li>
  <li>ë°˜ë©´, ì˜ë¯¸(semantic)ê°€ ë¹„ìŠ·í•˜ì§€ë§Œ ë‹¤ë¥¸ ë‹¨ì–´ì¸ ê²½ìš° ë¹„êµê°€ ë¶ˆê°€</li>
</ol>

<h2 id="tf-idf">TF-IDF</h2>

<h3 id="tf-idf-term-frequency---inverse-document-frequency-ì†Œê°œ">TF-IDF (Term Frequency - Inverse Document Frequency) ì†Œê°œ</h3>

<ul>
  <li>Term Frequency (TF) : ë‹¨ì–´ì˜ ë“±ì¥ë¹ˆë„</li>
  <li>Inverse Document Frequency (IDF) : ë‹¨ì–´ê°€ ì œê³µí•˜ëŠ” ì •ë³´ì˜ ì–‘</li>
  <li>ex) It was the best of times
    <ul>
      <li>It, was, the, of : ìì£¼ ë“±ì¥í•˜ì§€ë§Œ ì œê³µí•˜ëŠ” ì •ë³´ì˜ ì–‘ì´ ì ìŒ</li>
      <li>best, times : ì¢€ ë” ë§ì€ ì •ë³´ë¥¼ ì œê³µ, ë¬¸ì„œì—ì„œ ë“±ì¥í•˜ëŠ” ì •ë„ê°€ ì ë‹¤ = ì¤‘ìš”í•œ ì •ë³´</li>
    </ul>
  </li>
</ul>

<h3 id="term-frequency-tf">Term Frequency (TF)</h3>

<blockquote>
  <p>í•´ë‹¹ ë¬¸ì„œ ë‚´ ë‹¨ì–´ì˜ ë“±ì¥ ë¹ˆë„</p>
</blockquote>

<ol>
  <li>Raw count</li>
  <li>Adjusted for doc length: raw count / num words (TF)</li>
  <li>Other variants: binary, log normalization, etc.</li>
</ol>

<h3 id="inverse-document-frequency-idf">Inverse Document Frequency (IDF)</h3>

<blockquote>
  <p>ë‹¨ì–´ê°€ ì œê³µí•˜ëŠ” ì •ë³´ì˜ ì–‘</p>
</blockquote>

<ul>
  <li>$IDF(t) = log\frac{N}{DF(t)}$</li>
  <li>Document Frequency (DF) = Term $t$ê°€ ë“±ì¥í•œ documentì˜ ê°œìˆ˜</li>
  <li>$N$ = ì´ documentì˜ ê°œìˆ˜</li>
  <li>ëª¨ë“  ë¬¸ì„œì— ë“±ì¥í•˜ëŠ” ë‹¨ì–´ì˜ ê²½ìš° N = DFì´ê¸° ë•Œë¬¸ì— logë¥¼ ì”Œì–´ì£¼ë©´ 0ì´ ëœë‹¤.</li>
</ul>

<h3 id="combine-tf--df">Combine TF &amp; DF</h3>

<p>TF-IDF($t$, $d$): TF-IDF for term $t$ in document $d$, $TF(t, d) \times IDF(t)$</p>

<ul>
  <li>â€˜aâ€™, â€˜theâ€™ ë“± ê´€ì‚¬ â†’ Low TF-IDF
    <ul>
      <li>TFëŠ” ë†’ì§€ë§Œ IDFê°€ 0ì— ê°€ê¹Œìš¸ ê²ƒ (ê±°ì˜ ëª¨ë“  documentì— ë“±ì¥ â†’ log(N/DF) = 0)</li>
    </ul>
  </li>
  <li>ìì£¼ ë“±ì¥í•˜ì§€ ì•ŠëŠ” ê³ ìœ ëª…ì‚¬ (ex. ì‚¬ëŒ ì´ë¦„, ì§€ëª… ë“±) â†’ High TF-IDF (IDFê°€ ì»¤ì§€ë©´ì„œ ì „ì²´ì ì¸ TF-IDFê°€ ì¦ê°€)</li>
</ul>

<h3 id="bm25">BM25</h3>

<blockquote>
  <p>TF-IDFì˜ ê°œë…ì„ ë°”íƒ•ìœ¼ë¡œ, ë¬¸ì„œì˜ ê¸¸ì´ê¹Œì§€ ê³ ë ¤í•˜ì—¬ ì ìˆ˜ë¥¼ ë§¤ê¹€</p>
</blockquote>

<ul>
  <li>TF ê°’ì— í•œê³„ë¥¼ ì§€ì •í•´ë‘ì–´ ì¼ì •í•œ ë²”ìœ„ë¥¼ ìœ ì§€í•˜ë„ë¡ í•¨</li>
  <li>í‰ê· ì ì¸ ë¬¸ì„œì˜ ê¸¸ì´ ë³´ë‹¤ ë” ì‘ì€ ë¬¸ì„œì—ì„œ ë‹¨ì–´ê°€ ë§¤ì¹­ëœ ê²½ìš° ê·¸ ë¬¸ì„œì— ëŒ€í•´ ê°€ì¤‘ì¹˜ ë¶€ì—¬</li>
  <li>ì‹¤ì œ ê²€ìƒ‰ì—”ì§„, ì¶”ì²œ ì‹œìŠ¤í…œ ë“±ì—ì„œ ì•„ì§ê¹Œì§€ë„ ë§ì´ ì‚¬ìš©ë˜ëŠ” ì•Œê³ ë¦¬ì¦˜</li>
</ul>

<p>$Score(D, Q) = \sum_{term \in Q} IDF(term) \cdot \frac{TFIDF(term, D) \cdot (k_1 + 1)}{TFIDF(term, D) + k_1 \cdot (1 - b + b \cdot \frac{\vert D \vert}{avgdl})}$</p>
:ET