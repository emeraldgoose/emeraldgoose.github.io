I"<h2 id="reference">Reference</h2>
<blockquote>
  <p>BPE 알고리즘에 대한 설명은 링크한 곳에 잘 설명되어 있습니다. 여기서는 참고한 곳의 내용을 바탕으로 구현방법에 대해 설명하겠습니다.</p>
</blockquote>

<blockquote>
  <p><a href="https://ratsgo.github.io/nlpbook/docs/preprocess/bpe/">https://ratsgo.github.io/nlpbook/docs/preprocess/bpe/</a></p>
</blockquote>

<h3 id="get-vocabulary">get vocabulary</h3>
<p>토크나이징을 위해 문서내에 등장한 단어의 등장횟수가 기록된 <code class="language-plaintext highlighter-rouge">dictionary</code>를 사용하여 단어 집합인 <code class="language-plaintext highlighter-rouge">vocabulary</code>를 만들어야 합니다.</p>

<script src="https://gist.github.com/emeraldgoose/26465d827bd585a22796ba0461b10014.js"></script>

<p>위 코드는 <code class="language-plaintext highlighter-rouge">dictionary</code>의 단어들을 구성하는 글자들만을 추출하여 <code class="language-plaintext highlighter-rouge">vocabulary</code>에 저장한 코드입니다. 알고리즘 내에서 <code class="language-plaintext highlighter-rouge">vocabulary</code>를 사용하고 다시 업데이트를 반복할 것입니다.</p>

<p>모든 단어에 대한 bigram 쌍을 <code class="language-plaintext highlighter-rouge">pairs</code>라는 딕셔너리에 저장하면서 횟수를 저장합니다.</p>

<script src="https://gist.github.com/emeraldgoose/c2726eaffd762b1498a689bf751745a7.js"></script>

<p><code class="language-plaintext highlighter-rouge">pairs</code>에서 가장 많이 등장한 순대로 정렬 후 가장 많은 단어를 <code class="language-plaintext highlighter-rouge">vocabulary</code>에 저장합니다.</p>

<script src="https://gist.github.com/emeraldgoose/79fc8c2d59f6647c4b8a2ef289c429ae.js"></script>

<p>여기까지의 과정을 반복합니다.</p>

<script src="https://gist.github.com/emeraldgoose/98cf430f0d69833753dc969b5b1560fd.js"></script>

<h3 id="tokenizing">tokenizing</h3>
<p>토크나이징을 하려면 <code class="language-plaintext highlighter-rouge">vocabulary</code>가 필요합니다.</p>

<script src="https://gist.github.com/emeraldgoose/200425885cfbf199eb560967cda36768.js"></script>

<p><code class="language-plaintext highlighter-rouge">&lt;unk&gt;</code> 토큰은 토크나이저가 <code class="language-plaintext highlighter-rouge">vocabulary</code>에 없는 단어를 대체할 때 사용합니다. 이런 문제를 OOV(Out of Vocabulary)라 하는데 여기서는 corpus의 크기가 크지 않아 발생합니다.</p>

<p>다시 돌아와서 위의 코드는 hugs를 h,u,g,s로 나누고 h,ug,s로 병합하는 과정이었습니다. 이 과정을 더 이상 병합하지 않을 때까지 반복하여 토크나이징을 수행합니다.</p>

<script src="https://gist.github.com/emeraldgoose/8e75ed76cec6574d11d34296861c4cbe.js"></script>

<p>이 코드를 함수로 정의하고 문장에 대해 토크나아징할 수 있습니다.</p>

<script src="https://gist.github.com/emeraldgoose/10c50f9835dae2d01d0aa0d56ac02991.js"></script>

<p>이렇게 BPE 알고리즘을 통해 subword를 분리할 수 있어 합성어를 사전에 포함하지 않아도 되는 장점이 있습니다. 또한, 사전에 단어가 포함되지 않아 발생하는 OOV(Out of vocabulary) 문제를 해결하는 방법이기도 합니다.</p>

<p>여기까지 BPE 토크나이징 기법을 python으로 구현해봤습니다.</p>
:ET