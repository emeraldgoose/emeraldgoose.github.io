I"õ&<h2 id="softmax">Softmax</h2>
<p>SoftmaxëŠ” ì…ë ¥ë°›ì€ ê°’ì„ í™•ë¥ ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. ì…ë ¥ ê°’ì„ 0ê³¼ 1ì‚¬ì´ì˜ í™•ë¥ ê°’ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì´í•©ì€ í•­ìƒ 1ì´ ë˜ëŠ” íŠ¹ì§•ì„ ê°€ì§‘ë‹ˆë‹¤. ì£¼ë¡œ ë”¥ëŸ¬ë‹ì—ì„œ ë§ˆì§€ë§‰ ì¶œë ¥ì¸µì˜ í™œì„±í™”í•¨ìˆ˜ë¡œ ì‚¬ìš©ë˜ì–´ ê° í´ë˜ìŠ¤ì— ì†í•  í™•ë¥ ì„ ê³„ì‚°í•˜ëŠ”ë° ì‚¬ìš©í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì§€ìˆ˜í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— í° ê°’ì— ëŒ€í•´ ì˜¤ë²„í”Œë¡œìš°ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

<h3 id="forward">Forward</h3>
<p>Softmaxì˜ ìˆ˜ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.</p>

<p>$\text{Softmax}(x_i) = \frac{e^{x_i}}{\sum_j e^{x_j}}$</p>

<p>ì´ ìˆ˜ì‹ì„ êµ¬í˜„í•œ ì½”ë“œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.</p>

<script src="https://gist.github.com/emeraldgoose/16326706b8cc37c31eb8da0ae27e97b1.js"></script>

<p>ìœ„ì™€ ê°™ì´ êµ¬í˜„í•œ ì´ìœ ëŠ” ì•ˆì •ì„±ë•Œë¬¸ì…ë‹ˆë‹¤. xê°’ì´ ë„ˆë¬´ í¬ë©´ ì˜¤ë²„í”Œë¡œìš°ê°€ ë°œìƒí•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ìµœëŒ€ê°’ì„ 0ìœ¼ë¡œ(<code class="language-plaintext highlighter-rouge">np.exp(x) = 1</code>) ë³´ì •í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. <code class="language-plaintext highlighter-rouge">np.exp(x)</code>ë¥¼ <code class="language-plaintext highlighter-rouge">np.exp(x - np.max(x))</code>ë¡œ êµ¬í˜„í•˜ë”ë¼ë„ ë³€í™”ëŸ‰ì€ ê°™ê¸° ë•Œë¬¸ì— ìµœì¢… ì†Œí”„íŠ¸ë§¥ìŠ¤ ê²°ê³¼ê°’ì€ ê°™ìŠµë‹ˆë‹¤.</p>

<h3 id="backward">Backward</h3>
<p>2ì°¨ì› ì…ë ¥ì„ ë°›ëŠ” Softmax í•¨ìˆ˜ë¥¼ ë¯¸ë¶„í•˜ëŠ” ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.</p>

<p>$\frac{\partial S(x_i)}{\partial x_k} = \frac{\partial}{\partial x_k} \frac{e^{x_i}}{\sum_j e^{x_j}} = \frac{(\frac{\partial}{\partial x_k}e^{x_i})\sum_j e^{x_j} - e^{x_i}(\frac{\partial}{\partial x_k}\sum_j e^{x_j})}{(\sum_j e^{x_j})^2}$</p>

<p>ì´ë•Œ, ë‹¤ìŒ ë‘ ê°€ì§€ë¥¼ ìƒê°í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

<p>1) $k = i$</p>

<p>$\frac{\partial}{\partial x_i} \frac{e^{x_i}}{\sum_j e^{x_j}} = \frac{e^{x_i} \sum_j e^{x_j} \ - \ e^{x_i} e^{x_i}} {(\sum_j e^{x_j})^2} = \frac{e^{x_i}(\sum_j e^{x_j} - e^{x_i})}{(\sum_j e^{x_j})^2} = \frac{e^{x_i}}{\sum_j e^{x_j}} (1 - \frac{e^{x_i}}{\sum_j e^{x_j}}) = S_{x_i}(1-S_{x_i})$</p>

<p>2) $k \neq i$</p>

<p>$\frac{\partial}{\partial x_i} \frac{e^{x_i}}{\sum_j e^{x_j}} = \frac{0 \ - \ e^{x_i} \ \frac{\partial}{\partial x_k}\sum_j e^{x_j}}{(\sum_j e^{x_j})^2} = \frac{- e^{x_i} e^{x_k}}{(\sum_j e^{x_j})^2} = - \frac{e^{x_i}}{\sum_j e^{x_j}} \ \frac{e^{x_k}}{\sum_j e^{x_j}} = -S_{x_i} \ S_{x_k}$</p>

<p>ë”°ë¼ì„œ Jacobian í–‰ë ¬ì´ ìƒì„±ë˜ê³  ì´ í–‰ë ¬ì´ Softmaxì˜ ê¸°ìš¸ê¸°ê°€ ë©ë‹ˆë‹¤.</p>

<p>$Jacobian = \begin{cases} 
S_{x_i}(1-S_{x_i}) &amp; i = k \\ 
-S_{x_i} S_{x_k} &amp; i \neq k 
\end{cases}$</p>

<p>Softmax í•¨ìˆ˜ì˜ ì…ë ¥ì— ëŒ€í•œ ê¸°ìš¸ê¸°ë¥¼ êµ¬í•˜ëŠ” ì½”ë“œëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.</p>

<script src="https://gist.github.com/emeraldgoose/a1bb6f44b227ca37a451612f68213223.js"></script>

<p><strong>ì¶• ë³€ê²½</strong></p>

<p>ì•„ë˜ì²˜ëŸ¼ ê³„ì‚°ì„ ìš©ì´í•˜ê²Œ í•˜ê¸° ìœ„í•´ ì¶•ì„ ë³€ê²½í•©ë‹ˆë‹¤. ì ìš©í•˜ê³ ì í•˜ëŠ” ì¶•ì„ ë§ˆì§€ë§‰ ì¶•ê³¼ ë°”ê¿”ì¤ë‹ˆë‹¤.</p>

<p>ì´ë•Œ <code class="language-plaintext highlighter-rouge">np.reshape</code>ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ì¶”ì²œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. <code class="language-plaintext highlighter-rouge">np.reshape</code>í•¨ìˆ˜ëŠ” ë°°ì—´ì˜ ì›ì†Œ ìˆœì„œë¥¼ ê³ ë ¤í•˜ì§€ ì•Šê³  ëª¨ì–‘ë§Œ ë³€ê²½í•©ë‹ˆë‹¤. ë¬¼ë¦¬ì  ì—°ì†ì„±ì„ ë³´ì¥í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ì €ì¥í•œ ì •ë³´ê°€ ë’¤í‹€ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ <code class="language-plaintext highlighter-rouge">np.transpose</code>ë¥¼ ì‚¬ìš©í•´ ë¬¼ë¦¬ì ì¸ ì—°ì†ì„±ì„ ë³´ì¡´í•˜ë©´ì„œ ì¶•ë§Œ ë°”ê¿”ì£¼ê²Œ í•©ë‹ˆë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">transposed_axes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">dz</span><span class="p">.</span><span class="n">ndim</span><span class="p">))</span>
<span class="n">transposed_axes</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">dim</span><span class="p">],</span> <span class="n">transposed_axes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">transposed_axes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">transposed_axes</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">dim</span><span class="p">]</span>
<span class="n">transposed_dout</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">dz</span><span class="p">,</span> <span class="n">transposed_axes</span><span class="p">)</span>
<span class="n">transposed_softmax</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">output</span><span class="p">,</span> <span class="n">transposed_axes</span><span class="p">)</span>
<span class="n">transposed_dx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">dx</span><span class="p">,</span> <span class="n">transposed_axes</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Jacobian í–‰ë ¬ê³¼ dzì˜ í–‰ë ¬ê³±</strong>
ë‹¤ìŒ, softmax ê°’ì„ ì´ìš©í•´ ëŒ€ê°í–‰ë ¬(<code class="language-plaintext highlighter-rouge">np.diagflat</code>)ì„ êµ¬í•˜ê³  $S^2$ ê°’ì„ ë¹¼ì„œ Jacobian í–‰ë ¬ì„ ë§Œë“  ë’¤ ì¶•ì´ ë³€í™˜ëœ dzì™€ ê³±í•´ì¤ë‹ˆë‹¤. 
ë§ˆì§€ë§‰ì€ ì¶•ì„ ì›ìƒíƒœë¡œ ëŒë ¤ì¤ë‹ˆë‹¤.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="n">ndindex</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">transposed_softmax</span><span class="p">[</span><span class="n">idx</span><span class="p">].</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">jacobian</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">diagflat</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">s</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">transposed_dx</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">jacobian</span><span class="p">,</span> <span class="n">transposed_dout</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>

<span class="n">dx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">transposed_dx</span><span class="p">,</span> <span class="n">transposed_axes</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="crossentropyloss">CrossEntropyLoss</h2>
<p>CrossEntropyLossëŠ” ëª¨ë¸ì´ ì˜ˆì¸¡í•œ í™•ë¥ ë¶„í¬ì™€ ë°ì´í„°ì˜ í™•ë¥ ë¶„í¬ê°„ ì°¨ì´ë¥¼ ì¤„ì´ë„ë¡ ìœ ë„í•˜ëŠ” ì†ì‹¤í•¨ìˆ˜ì…ë‹ˆë‹¤.</p>

<p>êµì°¨ ì—”íŠ¸ë¡œí”¼ì˜ ìˆ˜ì‹ì€ $H(p,q) = \sum p(x) log(q(x))$ì´ê³  $p(x)$ëŠ” ì‹¤ì œ ì‚¬ê±´ì˜ í™•ë¥  ë¶„í¬, $q(x)$ëŠ” ëª¨ë¸ì´ ì˜ˆì¸¡í•œ í™•ë¥ ë¶„í¬ë¥¼ ë§í•©ë‹ˆë‹¤.</p>

<p>$p(x)log(q(x))$ëŠ” ì‹¤ì œ í™•ë¥  $p(x)$ê°€ ë†’ì€ ì‚¬ê±´ $x$ì— ëŒ€í•´ ëª¨ë¸ì´ ì˜ˆì¸¡í•œ í™•ë¥  $q(x)$ê°€ ë‚®ê²Œ ì˜ˆì¸¡ëœë‹¤ë©´, ì´ ê³±ì˜ ê°’ì´ ì»¤ì§€ê²Œ ë©ë‹ˆë‹¤. 
ì—¬ê¸°ì— ìŒìˆ˜ë¥¼ ì·¨í–ˆê¸° ë•Œë¬¸ì— ëª¨ë¸ì´ ì˜ëª» ì˜ˆì¸¡í•  ìˆ˜ë¡ êµì°¨ ì—”íŠ¸ë¡œí”¼ê°€ ì»¤ì ¸ ì‹¤ì œ í™•ë¥ ë¶„í¬ì™€ ì˜ˆì¸¡ í™•ë¥ ë¶„í¬ì˜ ì°¨ì´ê°€ í¬ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•˜ê²Œ ë©ë‹ˆë‹¤.</p>

<h3 id="forward-1">Forward</h3>
<p>CrossEntropyLossì˜ ìˆ˜ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.</p>

<p>$L = - \sum_{i=1}^c y_i log(p(x_i))$</p>

<p>$y_i$ëŠ” ì‹¤ì œ ë°ì´í„°ì˜ One-hot encodingì´ê³  $p(x_i)$ëŠ” $\text{Softmax}(x_i)$ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.</p>

<script src="https://gist.github.com/emeraldgoose/8917e4f3ab587bb59e53828cc8004b81.js"></script>

<h3 id="backward-1">Backward</h3>
<p>$y$ëŠ” ì •ë‹µ ë ˆì´ë¸”ì¸ ê²½ìš° 1, ì•„ë‹ˆë©´ 0ì˜ ê°’ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.</p>

<p>ë”°ë¼ì„œ kê°€ ì •ë‹µ ë ˆì´ë¸”ì¸ ê²½ìš° $L = - \sum_{i=1}^c y_i log(p(x_i)) = -log(p(x_k))$ë¡œ ìœ ë„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

<p>ì´ë•Œ, ê¸°ìš¸ê¸°ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ìœ ë„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

<p>$\frac{\partial L}{\partial x_i} = \frac{\partial}{\partial x_i}(- log p(x_k)) = - \frac{1}{p(x_k)}\frac{\partial p(x_k)}{\partial x_i}$</p>

<p>1) ì •ë‹µì¸ ê²½ìš°, $i = k$</p>

<p>$\frac{\partial p(x_k)}{\partial x_k} = p(x_k)(1 - p(x_k)) \rightarrow -\frac{1}{p(x_k)} p(x_k)(1 - p(x_k)) = -(1 - p(x_k)) = p(x_k) - 1 = p(x_i) - 1$</p>

<p>2) ì •ë‹µì´ ì•„ë‹Œ ê²½ìš°, $i \neq k$</p>

<p>$\frac{\partial p(x_k)}{\partial x_k} = -p(x_k)p(x_i) \rightarrow -\frac{1}{p(x_k)} -p(x_k)p(x_i) = p(x_i) = p(x_i) - 0$</p>

<p>ìœ ë„ëœ ì‹ì„ ì‚´í´ë³´ë©´ $p(x_i)$ì— ì •ë‹µì¸ ê²½ìš° 1, ì •ë‹µì´ ì•„ë‹Œ ê²½ìš° 0ì„ ë¹¼ì£¼ê³  ìˆìœ¼ë¯€ë¡œ $y$ë¡œ ì¹˜í™˜í•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ, CrossEntropyLossì˜ ê¸°ìš¸ê¸°ëŠ” $p(x_i) - y_i$ì…ë‹ˆë‹¤.</p>

<script src="https://gist.github.com/emeraldgoose/139b6199df3edfa26a078bfb20712645.js"></script>

:ET