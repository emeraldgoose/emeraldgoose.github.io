I"W<h2 id="introduction-to-odqa">Introduction to ODQA</h2>

<h3 id="linking-mrc-and-retrieval-open-domain-question-answering-odqa">Linking MRC and Retrieval: Open-domain Question Answering (ODQA)</h3>

<blockquote>
  <p>MRC: 지문이 주어진 상황에서 질의응답
ODQA: 지문이 따로 주어지지 않음. 방대한 World Knowledge에 기반해서 질의응답</p>
</blockquote>

<ul>
  <li>Modern search engines: 연관문서 뿐만 아니라 질문의 답을 같이 제공</li>
</ul>

<h3 id="history-of-odqa">History of ODQA</h3>

<p>Text retrieval conference (TREC) - QA Tracks (1999-2007): 연관문서만 반환하는 information retrieval (IR)에서 더 나아가서, short answer with support 형태가 목표<br />
Question processing + Passage retrieval + Answering processing</p>

<ol>
  <li>Question processing
    <ol>
      <li>Query formulation: 질문으로부터 키워드를 선택 / Answering type selection (ex. LOCATION: country)</li>
    </ol>
  </li>
  <li>Passage retrieval
    <ol>
      <li>기존의 IR 방법을 활용해서 연관된 document를 뽑고, passage 단위로 자른 후 선별</li>
      <li>Named entity / Passage 내 question 단어의 개수 등과 같은 hand-crafted features 활용</li>
    </ol>
  </li>
  <li>Answering processing
    <ol>
      <li>Hand-crafted features와 heuristic을 활용한 classifier</li>
      <li>주어진 question과 선별된 passage들 내에서 답을 선택</li>
    </ol>
  </li>
</ol>

<h2 id="retriever-reader-approach">Retriever-Reader Approach</h2>

<h3 id="retriever-reader-접근방식">Retriever-Reader 접근방식</h3>

<ul>
  <li>Retriever : 데이터베이스에서 관련있는 문서를 검색(search)함
    <ul>
      <li>입력 : 문서셋(document corpus), 질문(query)</li>
      <li>출력 : 관련성 높은 문서(document)</li>
    </ul>
  </li>
  <li>Reader : 검색된 문서에서 질문에 해당하는 답을 찾아냄
    <ul>
      <li>입력 : Retrieved된 문서(document), 질문(query)</li>
      <li>출력 : 답변(answer)</li>
    </ul>
  </li>
</ul>

<h3 id="학습단계">학습단계</h3>

<ul>
  <li>Retriever
    <ul>
      <li>TF-IDF, BM25 → 학습 없음</li>
      <li>Dense → 학습 있음</li>
    </ul>
  </li>
  <li>Reader
    <ul>
      <li>SQuAD와 같은 MRC 데이터셋으로 학습</li>
      <li>학습데이터를 추가하기 위해서 Distant supervision 활용</li>
    </ul>
  </li>
</ul>

<h3 id="distant-supervision">Distant supervision</h3>

<p>질문-답변만 있는 데이터셋 (CuratedTREC, WebQuestions, WikiMovies)에서 MRC 학습 데이터를 만들기 위해 Supporting document가 필요함</p>

<ol>
  <li>위키피디아에서 Retriever를 이용해 관련성 높은 문서를 검색</li>
  <li>너무 짧거나 긴 문서, 질문의 고유명사를 포함하지 않는 등 부적합한 문서 제거</li>
  <li>answer가 exact match로 들어있지 않은 문서 제거</li>
  <li>남은 문서 중에 질문과 연관성이 가장 높은 단락을 supporting evidence로 사용함</li>
</ol>

<h3 id="inference">Inference</h3>

<ul>
  <li>Retriever가 질문과 가장 관련성 높은 5개 문서 출력</li>
  <li>Reader는 5개 문서를 읽고 답변 예측</li>
  <li>Reader가 예측한 답변 중 가장 score가 높은 것을 최종 답으로 사용함</li>
</ul>

<h2 id="issue--recent-approach">Issue &amp; Recent Approach</h2>

<h3 id="different-granularities-of-text-of-indexing-time">Different granularities of text of indexing time</h3>

<p>위키피디아에서 각 Passage의 단위를 문서, 단락, 또는 문장으로 정의할지 정해야 함.</p>

<ul>
  <li>Article : 5.08 million</li>
  <li>Paragraph : 29.5 million</li>
  <li>Sentence : 75.9 million</li>
</ul>

<p>Retriever 단계에서 몇개(top-k)의 문서를 넘길지 정해야 함. Granularity에 따라 k가 다를 수 밖에 없음<br />
(e.g. article → k=5, paragraph → k=29, sentence → k=78)</p>

<h3 id="single-passage-training-vs-multi-passage-training">Single-passage training vs. Multi-passage training</h3>

<ul>
  <li>Single Passage : 현재 우리는 k개의 passages들을 reader가 각각 확인하고 특정 answer span에 대한 예측점수를 나타냄. 그리고 이 중 가장 높은 점수를 가진 answer span을 고르도록 함
    <ul>
      <li>이 경우 각 retrieved passages들에 대한 직접적인 비교라고 볼 수 없음</li>
      <li>따로 reader 모델이 보는게 아니라 전체를 한 번에 보면 어떨까?</li>
    </ul>
  </li>
  <li>Multi Passage : retrieved passages 전체를 하나의 passage로 취급하고 reader 모델이 그 안에서 answer span하나를 찾도록 함
    <ul>
      <li>문서가 너무 길어지므로 GPU에 더 많은 메모리를 할당해야 함</li>
      <li>처리해야하는 연산량이 많아짐</li>
    </ul>
  </li>
</ul>

<h3 id="importance-of-each-passage">Importance of each passage</h3>

<p>Retriever 모델에서 추출된 top-k passage들의 retrieved score를 reader모델에 전달<br />
최근에는 passage의 retrieved score와 reader가 각 passages들을 읽고 내놓은 answer의 score를 합하여 최종 출력을 내고 있다.</p>
:ET